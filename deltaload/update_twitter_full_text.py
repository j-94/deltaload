#!/usr/bin/env python3
"""
Script to update full_text field for Twitter bookmarks using the new TweetProcessor.

This script processes all Twitter bookmarks and updates their full_text field
with rich, standardized markdown content generated by the TweetProcessor.
"""

import os
import json
import logging
import argparse
from pathlib import Path
from datetime import datetime
from tools.tweet_processor import TweetProcessor

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s.%(msecs)03d %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("update_twitter_full_text.log")
    ]
)
logger = logging.getLogger(__name__)

def load_bookmarks(bookmark_file):
    """Load bookmarks from JSON file."""
    try:
        with open(bookmark_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Error loading bookmarks from {bookmark_file}: {str(e)}")
        return None

def save_bookmarks(bookmarks, output_file):
    """Save bookmarks to JSON file."""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(bookmarks, f, indent=2, ensure_ascii=False)
        logger.info(f"Saved updated bookmarks to {output_file}")
        return True
    except Exception as e:
        logger.error(f"Error saving bookmarks to {output_file}: {str(e)}")
        return False

def update_twitter_bookmarks(bookmarks, processor, dry_run=False):
    """
    Update Twitter bookmarks with enhanced full_text field.
    
    Args:
        bookmarks: List of bookmark objects
        processor: Initialized TweetProcessor
        dry_run: If True, don't actually update bookmarks
        
    Returns:
        Tuple of (updated_count, error_count, skipped_count)
    """
    updated_count = 0
    error_count = 0
    skipped_count = 0
    
    for i, bookmark in enumerate(bookmarks):
        # Only process Twitter bookmarks
        source = bookmark.get('source', '')
        if source not in ('twitter', 'twitter_like'):
            skipped_count += 1
            continue
        
        url = bookmark.get('url', '')
        if not url or 'twitter.com' not in url and 'x.com' not in url:
            logger.warning(f"Skipping bookmark {i}: No valid Twitter URL")
            skipped_count += 1
            continue
        
        logger.info(f"Processing bookmark {i}: {url}")
        
        try:
            # Process the URL
            result = processor.process_tweet_url(url)
            
            if result['status'] == 'success':
                # Update the bookmark
                bookmark['full_text'] = result['full_text']
                bookmark['markdown'] = result['markdown']
                
                # Update metadata if needed
                if 'metadata' in result and result['metadata']:
                    # Preserve existing metadata and merge
                    if 'metadata' not in bookmark:
                        bookmark['metadata'] = {}
                    
                    # Add tweet-specific metadata
                    bookmark['metadata']['tweet_processed'] = datetime.now().isoformat()
                    
                    # Add author info if available
                    if 'author' in result['metadata']:
                        bookmark['metadata']['author'] = result['metadata']['author']
                    
                    # Add metrics if available
                    if 'metrics' in result['metadata']:
                        bookmark['metadata']['tweet_metrics'] = result['metadata']['metrics']
                    
                    # Add thread info if it's a thread
                    if result.get('is_thread', False):
                        bookmark['metadata']['is_thread'] = True
                        bookmark['metadata']['thread_size'] = result['metadata'].get('thread', {}).get('total_tweets', 0)
                
                logger.info(f"Successfully updated bookmark {i}")
                updated_count += 1
            else:
                logger.error(f"Failed to process bookmark {i}: {result.get('error', 'Unknown error')}")
                error_count += 1
        
        except Exception as e:
            logger.error(f"Error processing bookmark {i}: {str(e)}")
            error_count += 1
    
    return updated_count, error_count, skipped_count

def main():
    """Main function."""
    parser = argparse.ArgumentParser(description="Update full_text field for Twitter bookmarks")
    parser.add_argument("--input", "-i", required=True, help="Input bookmarks JSON file")
    parser.add_argument("--output", "-o", help="Output bookmarks JSON file (defaults to input file)")
    parser.add_argument("--dry-run", "-d", action="store_true", help="Don't actually update bookmarks")
    parser.add_argument("--cache-dir", "-c", default="./data", help="Cache directory path")
    
    args = parser.parse_args()
    
    # Default output to input if not specified
    if not args.output:
        args.output = args.input
    
    # Load bookmarks
    bookmarks = load_bookmarks(args.input)
    if not bookmarks:
        logger.error("Failed to load bookmarks. Exiting.")
        return 1
    
    logger.info(f"Loaded {len(bookmarks)} bookmarks from {args.input}")
    
    # Initialize processor
    processor = TweetProcessor(cache_dir=args.cache_dir)
    
    # Update bookmarks
    updated_count, error_count, skipped_count = update_twitter_bookmarks(
        bookmarks, processor, args.dry_run
    )
    
    logger.info(f"Processing completed: {updated_count} updated, {error_count} errors, {skipped_count} skipped")
    
    # Save updated bookmarks
    if not args.dry_run:
        if args.output == args.input:
            # Create backup
            backup_file = f"{args.input}.bak.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            try:
                import shutil
                shutil.copy2(args.input, backup_file)
                logger.info(f"Created backup of original file at {backup_file}")
            except Exception as e:
                logger.error(f"Failed to create backup: {str(e)}")
        
        success = save_bookmarks(bookmarks, args.output)
        if success:
            logger.info(f"Successfully saved {len(bookmarks)} bookmarks to {args.output}")
        else:
            logger.error(f"Failed to save bookmarks to {args.output}")
            return 1
    else:
        logger.info("Dry run - no changes were saved")
    
    return 0

if __name__ == "__main__":
    exit(main()) 