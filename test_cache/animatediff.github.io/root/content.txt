Methodology

With the advance of text-to-image models (e.g., Stable Diffusion) and corresponding personalization techniques (e.g., LoRA and DreamBooth), it is possible for everyone to manifest their imagination into high-quality images with an affordable cost. Subsequently, there is a great demand for image animation techniques to further combine generated stationary images with motion dynamics. In this project, we propose an effective framework to animate most of existing personalized text-to-image models once for all, saving the efforts in model-specific tuning.

At the core of the proposed framework is to append a newly-initialized motion modeling module to the frozen based text-to-image model, and train it on video clips thereafter to distill a reasonable motion prior. Once trained, by simply injecting this motion modeling module, all personalized versions derived from the same base one readily become text-driven models that produce diverse and personalized animated images.

![Image 3](https://animatediff.github.io/figs/framework.jpg)

Gallery

Here we demonstrate best-quality animations generated by models injected with the motion modeling module in our framework.  
Click to play the following animations.

Model: [ToonYou](https://civitai.com/models/30240/toonyou)

Model: [Counterfeit V3.0](https://civitai.com/models/4468/counterfeit-v30)

Model: [Realistic Vision V2.0](https://civitai.com/models/4201/realistic-vision-v20)

Model: [majicMIX Realistic](https://civitai.com/models/43331/majicmix-realistic)

Model: [RCNZ Cartoon](https://civitai.com/models/66347/rcnz-cartoon-3d)

Model: [RCNZ Cartoon](https://civitai.com/models/66347/rcnz-cartoon-3d)

Model: [TUSUN](https://civitai.com/models/33194/pallass-catmanul-lora)

Model: [FilmVelvia](https://civitai.com/models/33208/filmgirl-film-grain-lora-and-loha)

Model: [GHIBLI Background](https://civitai.com/models/54233/ghiblibackground)

Model: [InkStyle](https://civitai.com/models/73305/zyd232s-ink-style)

Supplement

Here we show results using the same prompt with the same model, demonstrating that our method dose not break the diversity of the original model. Click to play the following animations.

Model: [ToonYou](https://civitai.com/models/30240/toonyou)

Model: [Lyriel](https://civitai.com/models/22922/lyriel)

BibTeX

```
 @misc{guo2023animatediff,  
    title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},  
    author={Yuwei Guo and Ceyuan Yang and Anyi Rao and Zhengyang Liang and Yaohui Wang and Yu Qiao and Maneesh Agrawala and Dahua Lin and Bo Dai},  
    booktitle={arXiv preprint arxiv:2307.04725},  
    year={2023},  
    archivePrefix={arXiv},  
    primaryClass={cs.CV}  
  } 
```