EvalPlus Leaderboard
===============

ğŸ† EvalPlus Leaderboard ğŸ†
==========================

### EvalPlus evaluates AI Coders with rigorous tests.  

ğŸ“¢ News: Beyond correctness, how's their code efficiency? Checkout [ğŸš€EvalPerf](https://evalplus.github.io/evalperf.html)!

[![Image 5: github](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/evalplus/evalplus) [![Image 6: paper](https://img.shields.io/badge/Paper-NeurIPS'23-a55fed.svg?style=for-the-badge)](https://openreview.net/forum?id=1qvx610Cu7)

 HumanEval  MBPP  Average

âš¡EvalPlus Testsâš¡

| # | Model | pass@1 |
| --- | --- | --- |
| 1 | ğŸ¥‡ [O1 Preview (Sept 2024)](https://platform.openai.com/docs/models/)âœ¨ | âš¡89 |
| 2 | ğŸ¥ˆ [O1 Mini (Sept 2024)](https://platform.openai.com/docs/models/)âœ¨ | âš¡89 |
| 3 | ğŸ¥‰ [Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)âœ¨ | âš¡87.2 |
| 4 | [GPT 4o (Aug 2024)](https://platform.openai.com/docs/models/)âœ¨ | âš¡87.2 |
| 5 | [DeepSeek-V3 (Nov 2024)](https://huggingface.co/deepseek-ai/DeepSeek-V3)âœ¨ | âš¡86.6 |
| 6 | [GPT-4-Turbo (April 2024)](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)âœ¨ | âš¡86.6 |
| 7 | [DeepSeek-V2.5 (Nov 2024)](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)âœ¨ | âš¡83.5 |
| 8 | [GPT 4o Mini (July 2024)](https://platform.openai.com/docs/models/)âœ¨ | âš¡83.5 |
| 9 | [DeepSeek-Coder-V2-Instruct](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct)âœ¨ | âš¡82.3 |
| 10 | [Claude Sonnet 3.5 (June 2024)](https://platform.openai.com/docs/models/)âœ¨ | âš¡81.7 |
| 11 | [GPT-4-Turbo (Nov 2023)](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)âœ¨ | âš¡81.7 |
| 12 | [Grok Beta](https://x.ai/blog/grok-2)âœ¨ | âš¡80.5 |
| 13 | [Gemini 1.5 Pro 002](https://ai.google.dev/)âœ¨ | âš¡79.3 |
| 14 | [GPT-4 (May 2023)](https://openai.com/research/gpt-4)âœ¨ | âš¡79.3 |
| 15 | [CodeQwen1.5-7B-Chat](https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat)âœ¨ | âš¡78.7 |
| 16 | [OpenCoder-8B-Instruct](https://huggingface.co/infly/OpenCoder-8B-Instruct)âœ¨ | âš¡77.4 |
| 17 | [claude-3-opus (Mar 2024)](https://www.anthropic.com/news/claude-3-family)âœ¨ | âš¡77.4 |
| 18 | [Gemini 1.5 Flash 002](https://ai.google.dev/)âœ¨ | âš¡75.6 |
| 19 | [DeepSeek-Coder-33B-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct)âœ¨ | âš¡75 |
| 20 | [Codestral-22B-v0.1](https://huggingface.co/mistralai/Codestral-22B-v0.1)âœ¨ | âš¡73.8 |
| 21 | [OpenCodeInterpreter-DS-33B](https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-33B)âœ¨ğŸ’™ | âš¡73.8 |
| 22 | [WizardCoder-33B-V1.1](https://huggingface.co/WizardLM/WizardCoder-33B-V1.1)âœ¨ | âš¡73.2 |
| 23 | [Artigenz-Coder-DS-6.7B](https://huggingface.co/Artigenz/Artigenz-Coder-DS-6.7B)âœ¨ | âš¡72.6 |
| 24 | [Llama3-70B-instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct)âœ¨ | âš¡72 |
| 25 | [Mixtral-8x22B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1)âœ¨ | âš¡72 |
| 26 | [OpenCodeInterpreter-DS-6.7B](https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-6.7B)âœ¨ğŸ’™ | âš¡72 |
| 27 | [speechless-codellama-34B-v2.0](https://huggingface.co/uukuguy/speechless-codellama-34b-v2.0)âœ¨ğŸ’™ | âš¡72 |
| 28 | [DeepSeek-Coder-6.7B-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct)âœ¨ | âš¡71.3 |
| 29 | [DeepSeek-Coder-7B-instruct-v1.5](https://huggingface.co/deepseek-ai/deepseek-coder-7b-instruct-v1.5)âœ¨ | âš¡71.3 |
| 30 | [Magicoder-S-DS-6.7B](https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B)âœ¨ğŸ’™ | âš¡71.3 |
| 31 | [starchat2-15b-v0.1](https://huggingface.co/HuggingFaceH4/starchat2-15b-v0.1)âœ¨ğŸ’š | âš¡71.3 |
| 32 | [GPT-3.5-Turbo (Nov 2023)](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)âœ¨ | âš¡70.7 |
| 33 | [code-millenials-34B](https://huggingface.co/budecosystem/code-millenials-34b)âœ¨ | âš¡70.7 |
| 34 | [databricks/dbrx-instruct](https://huggingface.co/databricks/dbrx-instruct)âœ¨ | âš¡70.1 |
| 35 | [WaveCoder-Ultra-6.7B](https://huggingface.co/microsoft/wavecoder-ultra-6.7b)âœ¨ | âš¡69.5 |
| 36 | [XwinCoder-34B](https://huggingface.co/Xwin-LM/XwinCoder-34B)âœ¨ | âš¡69.5 |
| 37 | [claude-3-haiku (Mar 2024)](https://www.anthropic.com/news/claude-3-family)âœ¨ | âš¡68.9 |
| 38 | [Magicoder-S-CL-7B](https://huggingface.co/ise-uiuc/Magicoder-S-CL-7B)âœ¨ğŸ’™ | âš¡67.7 |
| 39 | [OpenChat-3.5-7B-0106](https://huggingface.co/openchat/openchat-3.5-0106)âœ¨ğŸ’™ | âš¡67.7 |
| 40 | [Phind-CodeLlama-34B-v2](https://huggingface.co/Phind/Phind-CodeLlama-34B-v2) | âš¡67.1 |
| 41 | [GPT-3.5 (May 2023)](https://openai.com/blog/chatgpt)âœ¨ | âš¡66.5 |
| 42 | [CodeLlama-70B-Instruct](https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf)âœ¨ | âš¡65.9 |
| 43 | [WhiteRabbitNeo-33B-v1](https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-33B-v1)âœ¨ | âš¡65.9 |
| 44 | [speechless-coder-ds-6.7B](https://huggingface.co/uukuguy/speechless-coder-ds-6.7b)âœ¨ğŸ’™ | âš¡65.9 |
| 45 | [WizardCoder-Python-34B-V1.0](https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0)âœ¨ | âš¡64.6 |
| 46 | [claude-3-sonnet (Mar 2024)](https://www.anthropic.com/news/claude-3-family)âœ¨ | âš¡64 |
| 47 | [Llama3.1-8B-instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)âœ¨ | âš¡62.8 |
| 48 | [speechless-starcoder2-15b](https://huggingface.co/uukuguy/speechless-starcoder2-15b)âœ¨ğŸ’š | âš¡62.8 |
| 49 | [Mistral Large (Mar 2024)](https://mistral.ai/news/mistral-large/)âœ¨ | âš¡62.2 |
| 50 | [claude-2 (Mar 2024)](https://www.anthropic.com/news/claude-2)âœ¨ | âš¡61.6 |
| 51 | [Gemini Pro 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)âœ¨ | âš¡61 |
| 52 | [DeepSeek-Coder-1.3B-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct)âœ¨ | âš¡60.4 |
| 53 | [starcoder2-15b-instruct-v0.1](https://huggingface.co/bigcode/starcoder2-15b-instruct-v0.1)âœ¨ğŸ’š | âš¡60.4 |
| 54 | [Code-290k-6.7B-Instruct](https://huggingface.co/ajibawa-2023/Code-290k-6.7B-Instruct)âœ¨ğŸ’™ | âš¡59.7 |
| 55 | [Qwen1.5-72B-Chat](https://huggingface.co/Qwen/Qwen1.5-72B-Chat)âœ¨ | âš¡59.1 |
| 56 | [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)âœ¨ | âš¡59.1 |
| 57 | [dolphin-2.6-mixtral-8x7b](https://huggingface.co/cognitivecomputations/dolphin-2.6-mixtral-8x7b)âœ¨ğŸ’™ | âš¡57.3 |
| 58 | [Command-R+](https://huggingface.co/CohereForAI/c4ai-command-r-plus)âœ¨ | âš¡56.7 |
| 59 | [Llama3-8B-instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)âœ¨ | âš¡56.7 |
| 60 | [Gemini Pro 1.0](https://deepmind.google/technologies/gemini/)âœ¨ | âš¡55.5 |
| 61 | [Code-13B](https://huggingface.co/ajibawa-2023/Code-13B)âœ¨ğŸ’™ | âš¡52.4 |
| 62 | [codegemma-7b-it](https://huggingface.co/google/codegemma-7b-it)âœ¨ | âš¡51.8 |
| 63 | [speechless-starcoder2-7b](https://huggingface.co/uukuguy/speechless-starcoder2-7b)âœ¨ğŸ’š | âš¡51.8 |
| 64 | [CodeLlama-70B](https://huggingface.co/codellama/CodeLlama-70b-Python-hf) | âš¡50.6 |
| 65 | [WizardCoder-15B-V1.0](https://huggingface.co/WizardLM/WizardCoder-15B-V1.0)âœ¨ | âš¡50.6 |
| 66 | [claude-instant-1 (Mar 2024)](https://www.anthropic.com/news/releasing-claude-instant-1-2)âœ¨ | âš¡50.6 |
| 67 | [speechless-coding-7B-16k-tora](https://huggingface.co/uukuguy/speechless-coding-7b-16k-tora)âœ¨ğŸ’™ | âš¡50.6 |
| 68 | [Code-33B](https://huggingface.co/ajibawa-2023/Code-33B)âœ¨ğŸ’™ | âš¡49.4 |
| 69 | [OpenHermes-2.5-Code-290k-13B](https://huggingface.co/ajibawa-2023/OpenHermes-2.5-Code-290k-13B)âœ¨ğŸ’™ | âš¡48.8 |
| 70 | [CodeQwen1.5-7B](https://huggingface.co/Qwen/CodeQwen1.5-7B) | âš¡45.7 |
| 71 | [WizardCoder-Python-7B-V1.0](https://huggingface.co/WizardLM/WizardCoder-Python-7B-V1.0)âœ¨ | âš¡45.1 |
| 72 | [phi-2-2.7B](https://huggingface.co/microsoft/phi-2) | âš¡45.1 |
| 73 | [DeepSeek-Coder-33B-base](https://huggingface.co/deepseek-ai/deepseek-coder-33b-base) | âš¡44.5 |
| 74 | [CodeLlama-34B](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/amp/) | âš¡43.9 |
| 75 | [Mistral-codealpaca-7B](https://huggingface.co/Nondzu/Mistral-7B-codealpaca-lora)ğŸ’™ | âš¡42.1 |
| 76 | [MistralHermes-CodePro-7B-v1](https://huggingface.co/beowolx/MistralHermes-CodePro-7B-v1)âœ¨ğŸ’™ | âš¡42.1 |
| 77 | [codegemma-7b](https://huggingface.co/google/codegemma-7b) | âš¡41.5 |
| 78 | [speechless-code-mistral-7B-v1.0](https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0)âœ¨ğŸ’™ | âš¡41.5 |
| 79 | [DeepSeek-Coder-6.7B-base](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base) | âš¡39.6 |
| 80 | [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)âœ¨ | âš¡39.6 |
| 81 | [CodeLlama-13B](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/amp/) | âš¡38.4 |
| 82 | [StarCoder2-15B](https://huggingface.co/bigcode/starcoder2-15b)ğŸ’š | âš¡37.8 |
| 83 | [SOLAR-10.7B-Instruct-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0)âœ¨ğŸ’™ | âš¡37.2 |
| 84 | [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)âœ¨ | âš¡36 |
| 85 | [CodeLlama-7B](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/amp/) | âš¡35.4 |
| 86 | [gemma-1.1-7b-it](https://huggingface.co/google/gemma-1.1-7b-it)âœ¨ | âš¡35.4 |
| 87 | [xDAN-L1-Chat-RL-v1-7B](https://huggingface.co/xDAN-AI/xDAN-L1-Chat-RL-v1)âœ¨ğŸ’™ | âš¡32.9 |
| 88 | [Python-Code-13B](https://huggingface.co/ajibawa-2023/Python-Code-13B)âœ¨ğŸ’™ | âš¡30.5 |
| 89 | [StarCoder2-7B](https://huggingface.co/bigcode/starcoder2-7b)ğŸ’š | âš¡29.9 |
| 90 | [Llama3-8B-base](https://huggingface.co/meta-llama/Meta-Llama-3-8B) | âš¡29.3 |
| 91 | [StarCoder-15B](https://huggingface.co/bigcode/starcoder)ğŸ’š | âš¡29.3 |
| 92 | [gemma-7b](https://huggingface.co/google/gemma-7b) | âš¡28.7 |
| 93 | [CodeGen-16B](https://arxiv.org/abs/2203.13474)ğŸ’š | âš¡28 |
| 94 | [StarCoder2-3B](https://huggingface.co/bigcode/starcoder2-3b)ğŸ’š | âš¡27.4 |
| 95 | [CodeT5+-16B](https://blog.salesforceairesearch.com/codet5/)ğŸ’š | âš¡26.8 |
| 96 | [CodeGen-6B](https://arxiv.org/abs/2203.13474)ğŸ’š | âš¡25.6 |
| 97 | [DeepSeek-Coder-1.3B-base](https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-base) | âš¡25.6 |
| 98 | [stable-code-3B](https://huggingface.co/stabilityai/stable-code-3b)ğŸ’š | âš¡25.6 |
| 99 | [gemma-7b-it](https://huggingface.co/google/gemma-7b-it)âœ¨ | âš¡25 |
| 100 | [CodeT5+-6B](https://blog.salesforceairesearch.com/codet5/)ğŸ’š | âš¡24.4 |
| 101 | [Mistral-7B](https://mistral.ai/news/announcing-mistral-7b/) | âš¡23.8 |
| 102 | [Zephyr Î²-7B](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)ğŸ’™ | âš¡23.2 |
| 103 | [CodeGen-2B](https://arxiv.org/abs/2203.13474)ğŸ’š | âš¡22.6 |
| 104 | [CodeT5+-2B](https://blog.salesforceairesearch.com/codet5/)ğŸ’š | âš¡22 |
| 105 | [StarCoderBase-7B](https://huggingface.co/bigcode/starcoderbase-7b)ğŸ’š | âš¡21.3 |
| 106 | [codegemma-2b](https://huggingface.co/google/codegemma-2b) | âš¡20.7 |
| 107 | [gemma-2b](https://huggingface.co/google/gemma-2b) | âš¡20.7 |
| 108 | [CodeGen2-7B](https://arxiv.org/abs/2305.02309)ğŸ’š | âš¡17.7 |
| 109 | [gemma-1.1-2b-it](https://huggingface.co/google/gemma-1.1-2b-it)âœ¨ | âš¡17.7 |
| 110 | [CodeGen2-16B](https://arxiv.org/abs/2305.02309)ğŸ’š | âš¡16.5 |
| 111 | [StarCoderBase-3B](https://huggingface.co/bigcode/starcoderbase-3b)ğŸ’š | âš¡15.9 |
| 112 | [Vicuna-13B](https://lmsys.org/blog/2023-03-30-vicuna/)ğŸ’™ | âš¡15.9 |
| 113 | [gemma-2b-it](https://huggingface.co/google/gemma-2b-it)âœ¨ | âš¡15.2 |
| 114 | [SantaCoder-1.1B](https://arxiv.org/abs/2301.03988)ğŸ’š | âš¡14 |
| 115 | [CodeGen2-3B](https://arxiv.org/abs/2305.02309)ğŸ’š | âš¡12.8 |
| 116 | [InCoder-6.7B](https://arxiv.org/abs/2204.05999)ğŸ’š | âš¡12.2 |
| 117 | [StarCoderBase-1B](https://huggingface.co/bigcode/starcoderbase-1b)ğŸ’š | âš¡12.2 |
| 118 | [Vicuna-7B](https://lmsys.org/blog/2023-03-30-vicuna/)ğŸ’™ | âš¡11.6 |
| 119 | [GPT-J-6B](https://www.eleuther.ai/artifacts/gpt-j)ğŸ’š | âš¡11 |
| 120 | [InCoder-1.3B](https://arxiv.org/abs/2204.05999)ğŸ’š | âš¡11 |
| 121 | [CodeGen2-1B](https://arxiv.org/abs/2305.02309)ğŸ’š | âš¡9.1 |
| 122 | [GPT-Neo-2.7B](https://www.eleuther.ai/artifacts/gpt-neo)ğŸ’š | âš¡6.7 |
| 123 | [PolyCoder-2.7B](https://github.com/VHellendoorn/Code-LMs)ğŸ’š | âš¡6.1 |
| 124 | [StableLM-7B](https://huggingface.co/stabilityai/stablelm-base-alpha-7b) | âš¡2.4 |
| 125 | [zyte-1B](https://huggingface.co/aihub-app/zyte-1B)âœ¨ğŸ’™ | âš¡1.8 |

Base Tests

| # | Model | pass@1 |
| --- | --- | --- |
| 1 | ğŸ¥‡ [O1 Preview (Sept 2024)](https://platform.openai.com/docs/models/)âœ¨ | 96.3 |
| 2 | ğŸ¥ˆ [O1 Mini (Sept 2024)](https://platform.openai.com/docs/models/)âœ¨ | 96.3 |
| 3 | ğŸ¥‰ [GPT 4o (Aug 2024)](https://platform.openai.com/docs/models/)âœ¨ | 92.7 |
| 4 | [Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)âœ¨ | 92.1 |
| 5 | [DeepSeek-V3 (Nov 2024)](https://huggingface.co/deepseek-ai/DeepSeek-V3)âœ¨ | 91.5 |
| 6 | [DeepSeek-V2.5 (Nov 2024)](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)âœ¨ | 90.2 |
| 7 | [GPT-4-Turbo (April 2024)](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)âœ¨ | 90.2 |
| 8 | [Gemini 1.5 Pro 002](https://ai.google.dev/)âœ¨ | 89 |
| 9 | [Grok Beta](https://x.ai/blog/grok-2)âœ¨ | 88.4 |
| 10 | [GPT 4o Mini (July 2024)](https://platform.openai.com/docs/models/)âœ¨ | 88.4 |
| 11 | [GPT-4 (May 2023)](https://openai.com/research/gpt-4)âœ¨ | 88.4 |
| 12 | [Claude Sonnet 3.5 (June 2024)](https://platform.openai.com/docs/models/)âœ¨ | 87.2 |
| 13 | [DeepSeek-Coder-V2-Instruct](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct)âœ¨ | 85.4 |
| 14 | [GPT-4-Turbo (Nov 2023)](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)âœ¨ | 85.4 |
| 15 | [CodeQwen1.5-7B-Chat](https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat)âœ¨ | 83.5 |
| 16 | [claude-3-opus (Mar 2024)](https://www.anthropic.com/news/claude-3-family)âœ¨ | 82.9 |
| 17 | [Gemini 1.5 Flash 002](https://ai.google.dev/)âœ¨ | 82.3 |
| 18 | [OpenCoder-8B-Instruct](https://huggingface.co/infly/OpenCoder-8B-Instruct)âœ¨ | 81.7 |
| 19 | [DeepSeek-Coder-33B-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct)âœ¨ | 81.1 |
| 20 | [Codestral-22B-v0.1](https://huggingface.co/mistralai/Codestral-22B-v0.1)âœ¨ | 79.9 |
| 21 | [WizardCoder-33B-V1.1](https://huggingface.co/WizardLM/WizardCoder-33B-V1.1)âœ¨ | 79.9 |
| 22 | [OpenCodeInterpreter-DS-33B](https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-33B)âœ¨ğŸ’™ | 79.3 |
| 23 | [Llama3-70B-instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct)âœ¨ | 77.4 |
| 24 | [OpenCodeInterpreter-DS-6.7B](https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-6.7B)âœ¨ğŸ’™ | 77.4 |
| 25 | [speechless-codellama-34B-v2.0](https://huggingface.co/uukuguy/speechless-codellama-34b-v2.0)âœ¨ğŸ’™ | 77.4 |
| 26 | [GPT-3.5-Turbo (Nov 2023)](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)âœ¨ | 76.8 |
| 27 | [Magicoder-S-DS-6.7B](https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B)âœ¨ğŸ’™ | 76.8 |
| 28 | [claude-3-haiku (Mar 2024)](https://www.anthropic.com/news/claude-3-family)âœ¨ | 76.8 |
| 29 | [Mixtral-8x22B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1)âœ¨ | 76.2 |
| 30 | [Artigenz-Coder-DS-6.7B](https://huggingface.co/Artigenz/Artigenz-Coder-DS-6.7B)âœ¨ | 75.6 |
| 31 | [DeepSeek-Coder-7B-instruct-v1.5](https://huggingface.co/deepseek-ai/deepseek-coder-7b-instruct-v1.5)âœ¨ | 75.6 |
| 32 | [XwinCoder-34B](https://huggingface.co/Xwin-LM/XwinCoder-34B)âœ¨ | 75.6 |
| 33 | [WaveCoder-Ultra-6.7B](https://huggingface.co/microsoft/wavecoder-ultra-6.7b)âœ¨ | 75 |
| 34 | [databricks/dbrx-instruct](https://huggingface.co/databricks/dbrx-instruct)âœ¨ | 75 |
| 35 | [DeepSeek-Coder-6.7B-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct)âœ¨ | 74.4 |
| 36 | [code-millenials-34B](https://huggingface.co/budecosystem/code-millenials-34b)âœ¨ | 74.4 |
| 37 | [starchat2-15b-v0.1](https://huggingface.co/HuggingFaceH4/starchat2-15b-v0.1)âœ¨ğŸ’š | 73.8 |
| 38 | [GPT-3.5 (May 2023)](https://openai.com/blog/chatgpt)âœ¨ | 73.2 |
| 39 | [WizardCoder-Python-34B-V1.0](https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0)âœ¨ | 73.2 |
| 40 | [OpenChat-3.5-7B-0106](https://huggingface.co/openchat/openchat-3.5-0106)âœ¨ğŸ’™ | 72.6 |
| 41 | [CodeLlama-70B-Instruct](https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf)âœ¨ | 72 |
| 42 | [WhiteRabbitNeo-33B-v1](https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-33B-v1)âœ¨ | 72 |
| 43 | [Phind-CodeLlama-34B-v2](https://huggingface.co/Phind/Phind-CodeLlama-34B-v2) | 71.3 |
| 44 | [speechless-coder-ds-6.7B](https://huggingface.co/uukuguy/speechless-coder-ds-6.7b)âœ¨ğŸ’™ | 71.3 |
| 45 | [Magicoder-S-CL-7B](https://huggingface.co/ise-uiuc/Magicoder-S-CL-7B)âœ¨ğŸ’™ | 70.7 |
| 46 | [claude-3-sonnet (Mar 2024)](https://www.anthropic.com/news/claude-3-family)âœ¨ | 70.7 |
| 47 | [Llama3.1-8B-instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)âœ¨ | 69.5 |
| 48 | [Mistral Large (Mar 2024)](https://mistral.ai/news/mistral-large/)âœ¨ | 69.5 |
| 49 | [claude-2 (Mar 2024)](https://www.anthropic.com/news/claude-2)âœ¨ | 69.5 |
| 50 | [Qwen1.5-72B-Chat](https://huggingface.co/Qwen/Qwen1.5-72B-Chat)âœ¨ | 68.3 |
| 51 | [Gemini Pro 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)âœ¨ | 68.3 |
| 52 | [starcoder2-15b-instruct-v0.1](https://huggingface.co/bigcode/starcoder2-15b-instruct-v0.1)âœ¨ğŸ’š | 67.7 |
| 53 | [speechless-starcoder2-15b](https://huggingface.co/uukuguy/speechless-starcoder2-15b)âœ¨ğŸ’š | 67.1 |
| 54 | [DeepSeek-Coder-1.3B-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct)âœ¨ | 65.9 |
| 55 | [Code-290k-6.7B-Instruct](https://huggingface.co/ajibawa-2023/Code-290k-6.7B-Instruct)âœ¨ğŸ’™ | 64.6 |
| 56 | [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)âœ¨ | 64.6 |
| 57 | [Command-R+](https://huggingface.co/CohereForAI/c4ai-command-r-plus)âœ¨ | 64 |
| 58 | [dolphin-2.6-mixtral-8x7b](https://huggingface.co/cognitivecomputations/dolphin-2.6-mixtral-8x7b)âœ¨ğŸ’™ | 64 |
| 59 | [Gemini Pro 1.0](https://deepmind.google/technologies/gemini/)âœ¨ | 63.4 |
| 60 | [Llama3-8B-instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)âœ¨ | 61.6 |
| 61 | [codegemma-7b-it](https://huggingface.co/google/codegemma-7b-it)âœ¨ | 60.4 |
| 62 | [claude-instant-1 (Mar 2024)](https://www.anthropic.com/news/releasing-claude-instant-1-2)âœ¨ | 57.3 |
| 63 | [WizardCoder-15B-V1.0](https://huggingface.co/WizardLM/WizardCoder-15B-V1.0)âœ¨ | 56.7 |
| 64 | [Code-13B](https://huggingface.co/ajibawa-2023/Code-13B)âœ¨ğŸ’™ | 56.1 |
| 65 | [speechless-starcoder2-7b](https://huggingface.co/uukuguy/speechless-starcoder2-7b)âœ¨ï¿½ï¿½ï¿½ | 56.1 |
| 66 | [CodeLlama-70B](https://huggingface.co/codellama/CodeLlama-70b-Python-hf) | 55.5 |
| 67 | [Code-33B](https://huggingface.co/ajibawa-2023/Code-33B)âœ¨ğŸ’™ | 54.9 |
| 68 | [speechless-coding-7B-16k-tora](https://huggingface.co/uukuguy/speechless-coding-7b-16k-tora)âœ¨ğŸ’™ | 54.9 |
| 69 | [OpenHermes-2.5-Code-290k-13B](https://huggingface.co/ajibawa-2023/OpenHermes-2.5-Code-290k-13B)âœ¨ğŸ’™ | 54.3 |
| 70 | [CodeLlama-34B](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/amp/) | 51.8 |
| 71 | [CodeQwen1.5-7B](https://huggingface.co/Qwen/CodeQwen1.5-7B) | 51.8 |
| 72 | [DeepSeek-Coder-33B-base](https://huggingface.co/deepseek-ai/deepseek-coder-33b-base) | 51.2 |
| 73 | [WizardCoder-Python-7B-V1.0](https://huggingface.co/WizardLM/WizardCoder-Python-7B-V1.0)âœ¨ | 50.6 |
| 74 | [phi-2-2.7B](https://huggingface.co/microsoft/phi-2) | 49.4 |
| 75 | [Mistral-codealpaca-7B](https://huggingface.co/Nondzu/Mistral-7B-codealpaca-lora)ğŸ’™ | 48.2 |
| 76 | [speechless-code-mistral-7B-v1.0](https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0)âœ¨ğŸ’™ | 48.2 |
| 77 | [DeepSeek-Coder-6.7B-base](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base) | 47.6 |
| 78 | [MistralHermes-CodePro-7B-v1](https://huggingface.co/beowolx/MistralHermes-CodePro-7B-v1)âœ¨ğŸ’™ | 47.6 |
| 79 | [StarCoder2-15B](https://huggingface.co/bigcode/starcoder2-15b)ğŸ’š | 46.3 |
| 80 | [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)âœ¨ | 45.1 |
| 81 | [codegemma-7b](https://huggingface.co/google/codegemma-7b) | 44.5 |
| 82 | [SOLAR-10.7B-Instruct-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0)âœ¨ğŸ’™ | 43.3 |
| 83 | [CodeLlama-13B](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/amp/) | 42.7 |
| 84 | [gemma-1.1-7b-it](https://huggingface.co/google/gemma-1.1-7b-it)âœ¨ | 42.7 |
| 85 | [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)âœ¨ | 42.1 |
| 86 | [xDAN-L1-Chat-RL-v1-7B](https://huggingface.co/xDAN-AI/xDAN-L1-Chat-RL-v1)âœ¨ğŸ’™ | 40.2 |
| 87 | [CodeLlama-7B](https://about.fb.com/news/2023/08/code-llama-ai-for-coding/amp/) | 37.8 |
| 88 | [StarCoder2-7B](https://huggingface.co/bigcode/starcoder2-7b)ğŸ’š | 35.4 |
| 89 | [gemma-7b](https://huggingface.co/google/gemma-7b) | 35.4 |
| 90 | [StarCoder-15B](https://huggingface.co/bigcode/starcoder)ğŸ’š | 34.1 |
| 91 | [Llama3-8B-base](https://huggingface.co/meta-llama/Meta-Llama-3-8B) | 33.5 |
| 92 | [CodeGen-16B](https://arxiv.org/abs/2203.13474)ğŸ’š | 32.9 |
| 93 | [Python-Code-13B](https://huggingface.co/ajibawa-2023/Python-Code-13B)âœ¨ğŸ’™ | 32.9 |
| 94 | [CodeT5+-16B](https://blog.salesforceairesearch.com/codet5/)ğŸ’š | 31.7 |
| 95 | [StarCoder2-3B](https://huggingface.co/bigcode/starcoder2-3b)ğŸ’š | 31.7 |
| 96 | [Zephyr Î²-7B](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)ğŸ’™ | 30 |
| 97 | [CodeGen-6B](https://arxiv.org/abs/2203.13474)ğŸ’š | 29.3 |
| 98 | [CodeT5+-6B](https://blog.salesforceairesearch.com/codet5/)ğŸ’š | 29.3 |
| 99 | [stable-code-3B](https://huggingface.co/stabilityai/stable-code-3b)ğŸ’š | 29.3 |
| 100 | [DeepSeek-Coder-1.3B-base](https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-base) | 28.7 |
| 101 | [Mistral-7B](https://mistral.ai/news/announcing-mistral-7b/) | 28.7 |
| 102 | [gemma-7b-it](https://huggingface.co/google/gemma-7b-it)âœ¨ | 28.7 |
| 103 | [codegemma-2b](https://huggingface.co/google/codegemma-2b) | 26.8 |
| 104 | [CodeT5+-2B](https://blog.salesforceairesearch.com/codet5/)ğŸ’š | 25 |
| 105 | [gemma-2b](https://huggingface.co/google/gemma-2b) | 25 |
| 106 | [CodeGen-2B](https://arxiv.org/abs/2203.13474)ğŸ’š | 24.4 |
| 107 | [StarCoderBase-7B](https://huggingface.co/bigcode/starcoderbase-7b)ğŸ’š | 24.4 |
| 108 | [gemma-1.1-2b-it](https://huggingface.co/google/gemma-1.1-2b-it)âœ¨ | 22.6 |
| 109 | [CodeGen2-16B](https://arxiv.org/abs/2305.02309)ğŸ’š | 19.5 |
| 110 | [CodeGen2-7B](https://arxiv.org/abs/2305.02309)ğŸ’š | 18.3 |
| 111 | [StarCoderBase-3B](https://huggingface.co/bigcode/starcoderbase-3b)ğŸ’š | 17.7 |
| 112 | [gemma-2b-it](https://huggingface.co/google/gemma-2b-it)âœ¨ | 17.7 |
| 113 | [Vicuna-13B](https://lmsys.org/blog/2023-03-30-vicuna/)ğŸ’™ | 17.1 |
| 114 | [CodeGen2-3B](https://arxiv.org/abs/2305.02309)ğŸ’š | 15.9 |
| 115 | [InCoder-6.7B](https://arxiv.org/abs/2204.05999)ğŸ’š | 15.9 |
| 116 | [SantaCoder-1.1B](https://arxiv.org/abs/2301.03988)ğŸ’š | 14.6 |
| 117 | [StarCoderBase-1B](https://huggingface.co/bigcode/starcoderbase-1b)ğŸ’š | 14.6 |
| 118 | [GPT-J-6B](https://www.eleuther.ai/artifacts/gpt-j)ğŸ’š | 12.2 |
| 119 | [InCoder-1.3B](https://arxiv.org/abs/2204.05999)ğŸ’š | 12.2 |
| 120 | [Vicuna-7B](https://lmsys.org/blog/2023-03-30-vicuna/)ğŸ’™ | 11.6 |
| 121 | [CodeGen2-1B](https://arxiv.org/abs/2305.02309)ğŸ’š | 11 |
| 122 | [GPT-Neo-2.7B](https://www.eleuther.ai/artifacts/gpt-neo)ğŸ’š | 7.9 |
| 123 | [PolyCoder-2.7B](https://github.com/VHellendoorn/Code-LMs)ğŸ’š | 6.1 |
| 124 | [StableLM-7B](https://huggingface.co/stabilityai/stablelm-base-alpha-7b) | 2.4 |
| 125 | [zyte-1B](https://huggingface.co/aihub-app/zyte-1B)âœ¨ğŸ’™ | 2.4 |

### ğŸ“ Notes

1.  Evaluated using [HumanEval+](https://github.com/evalplus/humanevalplus_release) version 0.1.10; [MBPP+](https://github.com/evalplus/mbppplus_release) version 0.2.0.
2.  Models are ranked according to pass@1 using greedy decoding. Setup details can be found [here](https://github.com/evalplus/evalplus/blob/master/codegen/model.py).
3.  âœ¨ marks models evaluated using a chat setting, while others perform direct code completion.
4.  Both MBPP and MBPP+ referred in our leaderboard use a subset (399 tasks) of hand-verified problems from MBPP-sanitized (427 tasks), to make sure the programming task is well-formed (e.g., test\_list is not wrong).
5.  Model providers have the responsibility to avoid data contamination. Models trained on close data can be affected by contamination.
6.  ğŸ’š means open weights and open data. ğŸ’™ means open weights and open SFT data, but the base model is not data-open. What does this imply? ğŸ’šğŸ’™ models open-source the data such that one can concretely reason about contamination.
7.  "Size" here is the amount of activated model weight during inference.

### ğŸ¤— More Leaderboards

In addition to EvalPlus leaderboards, it is recommended to comprehensively understand LLM coding ability through a diverse set of benchmarks and leaderboards, such as:

1.  [BigCodeBench](https://bigcode-bench.github.io/)
2.  [Big Code Models Leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard)
3.  [Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
4.  [CrossCodeEval](https://github.com/amazon-science/cceval)
5.  [ClassEval](https://fudanselab-classeval.github.io/)
6.  [CRUXEval](https://crux-eval.github.io/leaderboard.html)
7.  [Code Lingua](https://codetlingua.github.io/leaderboard.html)
8.  [Evo-Eval](https://evo-eval.github.io/)
9.  [EffiBench](https://huggingface.co/spaces/EffiBench/effibench-leaderboard)
10.  [HumanEval.jl - Julia version HumanEval with EvalPlus test cases](https://github.com/01-ai/HumanEval.jl)
11.  [LiveCodeBench](https://livecodebench.github.io/leaderboard.html)
12.  [MHPP](https://sparksofagi.github.io/MHPP/)
13.  [NaturalCodeBench](https://github.com/THUDM/NaturalCodeBench)
14.  [RepoBench](https://github.com/Leolty/repobench)
15.  [SWE-bench](https://www.swebench.com/)
16.  [TabbyML Leaderboard](https://leaderboard.tabbyml.com/)
17.  [TestEval](https://llm4softwaretesting.github.io/)