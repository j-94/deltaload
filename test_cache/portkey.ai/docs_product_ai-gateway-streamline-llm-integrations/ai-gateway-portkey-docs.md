---
title: AI Gateway - Portkey Docs
description: The world's fastest AI Gateway with advanced routing & integrated Guardrails.
url: https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations
timestamp: 2025-01-20T15:50:56.223Z
domain: portkey.ai
path: docs_product_ai-gateway-streamline-llm-integrations
---

# AI Gateway - Portkey Docs


The world's fastest AI Gateway with advanced routing & integrated Guardrails.


## Content

[​](https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations#features)

Features
------------------------------------------------------------------------------------------------

[Universal API ------------- Use any of the supported models with a universal API (REST and SDKs)](https://portkey.ai/docs/product/ai-gateway/universal-api)[Cache (Simple & Semantic) ------------------------- Save costs and decrease latencies by using a cache](https://portkey.ai/docs/product/ai-gateway/cache-simple-and-semantic)[Fallbacks --------- Fallback between providers and models for resilience](https://portkey.ai/docs/product/ai-gateway/fallbacks)[Conditional Routing ------------------- Route to different targets based on custom conditional checks](https://portkey.ai/docs/product/ai-gateway/conditional-routing)[Multimodality ------------- Use vision, audio, image generation, and more models](https://portkey.ai/docs/product/ai-gateway/multimodal-capabilities)[Automatic Retries ----------------- Setup automatic retry strategies](https://portkey.ai/docs/product/ai-gateway/automatic-retries)[Load Balancing -------------- Load balance between various API Keys to counter rate-limits](https://portkey.ai/docs/product/ai-gateway/load-balancing)[Canary Testing -------------- Canary test new models in production](https://portkey.ai/docs/product/ai-gateway/canary-testing)[Virtual Keys ------------ Manage AI provider keys and auth in a secure vault](https://portkey.ai/docs/product/ai-gateway/virtual-keys)[Request Timeout --------------- Easily handle unresponsive LLM requests](https://portkey.ai/docs/product/ai-gateway/request-timeouts)[Budget Limits ------------- Set usage limits based on costs incurred or tokens used](https://portkey.ai/docs/product/ai-gateway/virtual-keys/budget-limits)[Rate Limits ----------- Set hourly, daily, or per minute rate limits on requests or tokens sent](https://portkey.ai/docs/product/ai-gateway/rate-limits)

[​](https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations#using-the-gateway)

Using the Gateway
------------------------------------------------------------------------------------------------------------------

The various gateway strategies are implemented using Gateway configs. You can read more about configs below.

[Configs -------](https://portkey.ai/docs/product/ai-gateway/configs)

[​](https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations#open-source)

Open Source
------------------------------------------------------------------------------------------------------

We’ve open sourced our battle-tested AI gateway to the community. You can run it locally with a single command:

```
npx @portkey-ai/gateway
```

[**Contribute here**](https://github.com/portkey-ai/gateway).

While you’re here, why not [give us a star](https://git.new/ai-gateway-docs)? It helps us a lot!

You can also [self-host](https://github.com/Portkey-AI/gateway/blob/main/docs/installation-deployments.md) the gateway and then connect it to Portkey. Please reach out on [hello@portkey.ai](mailto:hello@portkey.ai) and we’ll help you set this up!

## Metadata

```json
{
  "title": "AI Gateway - Portkey Docs",
  "description": "The world's fastest AI Gateway with advanced routing & integrated Guardrails.",
  "url": "https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations",
  "content": "[​](https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations#features)\n\nFeatures\n------------------------------------------------------------------------------------------------\n\n[Universal API ------------- Use any of the supported models with a universal API (REST and SDKs)](https://portkey.ai/docs/product/ai-gateway/universal-api)[Cache (Simple & Semantic) ------------------------- Save costs and decrease latencies by using a cache](https://portkey.ai/docs/product/ai-gateway/cache-simple-and-semantic)[Fallbacks --------- Fallback between providers and models for resilience](https://portkey.ai/docs/product/ai-gateway/fallbacks)[Conditional Routing ------------------- Route to different targets based on custom conditional checks](https://portkey.ai/docs/product/ai-gateway/conditional-routing)[Multimodality ------------- Use vision, audio, image generation, and more models](https://portkey.ai/docs/product/ai-gateway/multimodal-capabilities)[Automatic Retries ----------------- Setup automatic retry strategies](https://portkey.ai/docs/product/ai-gateway/automatic-retries)[Load Balancing -------------- Load balance between various API Keys to counter rate-limits](https://portkey.ai/docs/product/ai-gateway/load-balancing)[Canary Testing -------------- Canary test new models in production](https://portkey.ai/docs/product/ai-gateway/canary-testing)[Virtual Keys ------------ Manage AI provider keys and auth in a secure vault](https://portkey.ai/docs/product/ai-gateway/virtual-keys)[Request Timeout --------------- Easily handle unresponsive LLM requests](https://portkey.ai/docs/product/ai-gateway/request-timeouts)[Budget Limits ------------- Set usage limits based on costs incurred or tokens used](https://portkey.ai/docs/product/ai-gateway/virtual-keys/budget-limits)[Rate Limits ----------- Set hourly, daily, or per minute rate limits on requests or tokens sent](https://portkey.ai/docs/product/ai-gateway/rate-limits)\n\n[​](https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations#using-the-gateway)\n\nUsing the Gateway\n------------------------------------------------------------------------------------------------------------------\n\nThe various gateway strategies are implemented using Gateway configs. You can read more about configs below.\n\n[Configs -------](https://portkey.ai/docs/product/ai-gateway/configs)\n\n[​](https://portkey.ai/docs/product/ai-gateway-streamline-llm-integrations#open-source)\n\nOpen Source\n------------------------------------------------------------------------------------------------------\n\nWe’ve open sourced our battle-tested AI gateway to the community. You can run it locally with a single command:\n\n```\nnpx @portkey-ai/gateway\n```\n\n[**Contribute here**](https://github.com/portkey-ai/gateway).\n\nWhile you’re here, why not [give us a star](https://git.new/ai-gateway-docs)? It helps us a lot!\n\nYou can also [self-host](https://github.com/Portkey-AI/gateway/blob/main/docs/installation-deployments.md) the gateway and then connect it to Portkey. Please reach out on [hello@portkey.ai](mailto:hello@portkey.ai) and we’ll help you set this up!",
  "usage": {
    "tokens": 655
  }
}
```
