LLM EXPLORER
Dark Theme 
Â Â LLM Â List Â Â Â LLM Hosting Â Â Â LLM Leaderboards Â Â Â Blog Â Â Â Newsfeed Â Â Â Advertise
Bagel DPO 7B V0.1 GGUF by TheBloke
 Â Â»Â  All LLMs Â Â»Â  TheBloke Â Â»Â  Bagel DPO 7B V0.1 GGUF Â Â URL Share it on   
Â Â 124 Â Â 
Base model:jondurbin/bagel-dpo... Base model:quantized:jondurbin... Â Â Conversational Â Â Dataset:ai2 arc Dataset:allenai/ultrafeedback ... Â Â Dataset:boolq Â Â Dataset:cais/mmlu Â Â Dataset:cakiki/rosetta-code Â Â Dataset:codeparrot/apps Â Â Dataset:datasets/winogrande Â Â Dataset:drop Â Â Dataset:facebook/belebele Â Â Dataset:intel/orca dpo pairs Dataset:jondurbin/cinematika-v... Dataset:jondurbin/truthy-dpo-v... Â Â Dataset:lmsys/lmsys-chat-1m Dataset:migtissera/synthia-v1.... Dataset:muennighoff/natural-in... Â Â Dataset:nvidia/helpsteer Â Â Dataset:open-orca/slimorca Â Â Dataset:openbookqa Â Â Dataset:piqa Â Â Dataset:spider Â Â Dataset:squad v2 Â Â Dataset:tiger-lab/mathinstruct Â Â Dataset:unalignment/spicy-3.1 Dataset:unalignment/toxic-dpo-... Dataset:vezora/tested-22k-pyth... Â Â Gguf Â Â Mistral Â Â Quantized Â Â Region:us
Model Card on HF ðŸ¤—: https://huggingface.co/TheBloke/bagel-dpo-7B-v0.1-GGUFÂ 
Bagel DPO 7B V0.1 GGUF Benchmarks
LLME Score:Â 
0.15914
nn.n% â€” How the model compares to the reference models: Anthropic Sonnet 3.5 ("so35"), GPT-4o ("gpt4o") or GPT-4 ("gpt4").
Â What is the LLM Explorer Rank (Score)
Bagel DPO 7B V0.1 GGUF Parameters and Internals
Model TypeÂ 	
mistral

Additional NotesÂ 	
The model uses a mixture of prompt formats (Vicuna, Llama-2, Alpaca, and a variant of ChatML).

Training DetailsÂ 	
Data Sources:	
ai2_arc, unalignment/spicy-3.1, codeparrot/apps, facebook/belebele, boolq, jondurbin/cinematika-v0.1, drop, lmsys/lmsys-chat-1m, TIGER-Lab/MathInstruct, cais/mmlu, Muennighoff/natural-instructions, openbookqa, piqa, Vezora/Tested-22k-Python-Alpaca, cakiki/rosetta-code, Open-Orca/SlimOrca, spider, squad_v2, migtissera/Synthia-v1.3, datasets/winogrande, nvidia/HelpSteer, Intel/orca_dpo_pairs, unalignment/toxic-dpo-v0.1, jondurbin/truthy-dpo-v0.1, allenai/ultrafeedback_binarized_cleaned

Methodology:	
The model is fine-tuned using a combination of supervised fine-tuning (SFT) and direct preference optimization (DPO) data. Data deduplication and decontamination techniques are applied.

Context Length:	
4096

Input OutputÂ 	
Input Format:	
Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: {prompt} ### Response:
LLM Name	Bagel DPO 7B V0.1 GGUF
Repository ðŸ¤—	https://huggingface.co/TheBloke/bagel-dpo-7B-v0.1-GGUFÂ 
Model Name	Bagel DPO 7B v0.1
Model Creator	Jon Durbin
Base Model(s)	Â Â jondurbin/bagel-dpo-7b-v0.1 Â Â jondurbin/bagel-dpo-7b-v0.1
Model Size	7b
Required VRAM	3.1â€¯GB
Updated	2025-01-20
Maintainer	TheBloke
Model Type	mistral
Model Files	Â Â 3.1 GB Â Â 3.8 GB Â Â 3.5 GB Â Â 3.2 GB Â Â 4.1 GB Â Â 4.4 GB Â Â 4.1 GB Â Â 5.0 GB Â Â 5.1 GB Â Â 5.0 GB Â Â 5.9 GB Â Â 7.7 GB
GGUF Quantization	Yes
Quantization Type	gguf
Model Architecture	AutoModel
License	apache-2.0
Best Alternatives to Bagel DPO 7B V0.1 GGUF
Best Alternatives
	
ContextÂ /Â RAM
	
Downloads
	
Likes

Pixel	8K / 4.4â€‰GB	28	0
Mistral 7B Instruct V0.3 GGUF	0K / 1.6â€‰GB	1782801	74
Qwen2 7B Instruct GGUF	0K / 1.9â€‰GB	1702751	11
WizardLM 2 7B GGUF	0K / 2.7â€‰GB	1719699	75
Deepthink Reasoning 7B GGUF	0K / 4.7â€‰GB	1579	10
QwQ LCoT 7B Instruct GGUF	0K / 4.7â€‰GB	692	8
Conversely Mistral 7B	0K / 0.2â€‰GB	31	0
Mistral 7B Instruct V0.3 GGUF	0K / 2.7â€‰GB	56986	9
Mistral 7B Instruct V0.2 GGUF	0K / 3.1â€‰GB	90738	412
CleverBoi 7B V2	0K / 0.1â€‰GB	149	0
Note: green Score (e.g. "73.2") means that the model is better than TheBloke/bagel-dpo-7B-v0.1-GGUF.
ExpandÂ Â 
Rank the Bagel DPO 7B V0.1 GGUF Capabilities

ðŸ†˜Â Have you tried this model? Rate its performance. This feedback would greatly assist ML community in identifying the most suitable model for their needs. Your contribution really does make a difference! ðŸŒŸ

Instruction Following and Task AutomationÂ Â 	
	   
Factuality and Completeness of KnowledgeÂ Â 	
	   
Censorship and AlignmentÂ Â 	
	   
Data Analysis and Insight GenerationÂ Â 	
	   
Text GenerationÂ Â 	
	   
Text Summarization and Feature ExtractionÂ Â 	
	   
Code GenerationÂ Â 	
	   
Multi-Language Support and TranslationÂ Â 	
	   
ExpandÂ Â 
What open-source LLMs or SLMs are you in search of? 41636 in total.
Â Â Â Search
Email us: info@extractum.io. Our Privacy PolicyÂ Â | Terms and ConditionsÂ Â | Suggest an improvement.
Our Social Media â†’Â Â    
Original data from HuggingFace, OpenCompass and various public git repos.
Release v20241227
Â Â Support LLM Explorer