---
title: Paper page - AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web
  Tutorials
description: Join the discussion on this paper page
url: https://huggingface.co/papers/2412.09605
timestamp: 2025-01-20T16:19:05.136Z
domain: huggingface.co
path: papers_2412.09605
---

# Paper page - AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web
  Tutorials


Join the discussion on this paper page


## Content

Paper page - AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials
===============

 [![Image 32: Hugging Face's logo](https://huggingface.co/front/assets/huggingface_logo-noborder.svg) Hugging Face](https://huggingface.co/)

*   [Models](https://huggingface.co/models)
*   [Datasets](https://huggingface.co/datasets)
*   [Spaces](https://huggingface.co/spaces)
*   [Posts](https://huggingface.co/posts)
*   [Docs](https://huggingface.co/docs)
*   [Enterprise](https://huggingface.co/enterprise)
*   [Pricing](https://huggingface.co/pricing)

*   * * *
    
*   [Log In](https://huggingface.co/login)
*   [Sign Up](https://huggingface.co/join)

[Papers](https://huggingface.co/papers)

arxiv:2412.09605

AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials
===========================================================================

Published on Dec 12, 2024

¬∑ Submitted by [![Image 33](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg) ranpox](https://huggingface.co/ranpox) on Dec 13, 2024

 [Upvote 28](https://huggingface.co/login?next=%2Fpapers%2F2412.09605)

*   [![Image 34](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg)](https://huggingface.co/ranpox "ranpox")
*   [![Image 35](https://huggingface.co/avatars/39408a394f0b558b10844b7a4946a8e9.svg)](https://huggingface.co/xy961218 "xy961218")
*   [![Image 36](https://cdn-avatars.huggingface.co/v1/production/uploads/669ca7e678115e16bdfc9bfc/pku8NvQKqfNQACRqm1YrW.jpeg)](https://huggingface.co/ludunjie "ludunjie")
*   [![Image 37](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PWp43VsXeltiPifGxGwrn.jpeg)](https://huggingface.co/ZeonLap "ZeonLap")
*   [![Image 38](https://cdn-avatars.huggingface.co/v1/production/uploads/1636263880877-noauth.jpeg)](https://huggingface.co/tianbaoxiexxx "tianbaoxiexxx")
*   [![Image 39](https://cdn-avatars.huggingface.co/v1/production/uploads/62c6981c9db11473f08b0c87/PKnnQ1SOrMuB4vf2cDDdG.jpeg)](https://huggingface.co/addf400 "addf400")
*   [![Image 40](https://cdn-avatars.huggingface.co/v1/production/uploads/656832dfbd65fd41ee7aa8cd/HHkyetTqNq1wIBPipzjQA.jpeg)](https://huggingface.co/kugwzk "kugwzk")
*   [![Image 41](https://huggingface.co/avatars/ae2f122bb93a7e024b5ee9cf217d7e3d.svg)](https://huggingface.co/zhang0628 "zhang0628")
*   +20

Authors:

 ![Image 42](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg) [Yiheng Xu](https://huggingface.co/ranpox) ,

 ![Image 43](https://cdn-avatars.huggingface.co/v1/production/uploads/669ca7e678115e16bdfc9bfc/pku8NvQKqfNQACRqm1YrW.jpeg) [Dunjie Lu](https://huggingface.co/ludunjie) ,

 ![Image 44](https://huggingface.co/avatars/bc0737bf4481433b669433facf6ce6f4.svg) [Zhennan Shen](https://huggingface.co/5456es) ,

 ![Image 45](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PWp43VsXeltiPifGxGwrn.jpeg) [Junli Wang](https://huggingface.co/ZeonLap) ,

 ![Image 46](https://cdn-avatars.huggingface.co/v1/production/uploads/656832dfbd65fd41ee7aa8cd/HHkyetTqNq1wIBPipzjQA.jpeg) [Zekun Wang](https://huggingface.co/kugwzk) ,

Yuchen Mao ,

 ![Image 47](https://huggingface.co/avatars/c87c273ca628dbcddccbf1ee19b2ce33.svg) [Caiming Xiong](https://huggingface.co/cxiong) ,

Tao Yu

Abstract
--------

Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality GUI agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.

[View arXiv page](https://arxiv.org/abs/2412.09605) [View PDF](https://arxiv.org/pdf/2412.09605) [Add to collection](https://huggingface.co/login?next=%2Fpapers%2F2412.09605)

### Community

 ![Image 48](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg) [ranpox](https://huggingface.co/ranpox)Paper author Paper submitter [Dec 13, 2024](https://huggingface.co/papers/2412.09605#675bd05a065c05f943b1ea70)

[https://agenttrek.github.io/](https://agenttrek.github.io/)

üöÄ

4

4

+

Reply

 ![Image 49](https://cdn-avatars.huggingface.co/v1/production/uploads/1674830754237-63d3e0e8ff1384ce6c5dd17d.jpeg) [librarian-bot](https://huggingface.co/librarian-bot)[Dec 14, 2024](https://huggingface.co/papers/2412.09605#675ce0c11bdf6700768b9754)

This is an automated message from the [Librarian Bot](https://huggingface.co/librarian-bots). I found the following papers similar to this paper.

The following papers were recommended by the Semantic Scholar API

*   [Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction](https://huggingface.co/papers/2412.04454) (2024)
*   [AutoGLM: Autonomous Foundation Agents for GUIs](https://huggingface.co/papers/2411.00820) (2024)
*   [Ponder&Press: Advancing Visual GUI Agent towards General Computer Control](https://huggingface.co/papers/2412.01268) (2024)
*   [Large Language Model-Brained GUI Agents: A Survey](https://huggingface.co/papers/2411.18279) (2024)
*   [OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning](https://huggingface.co/papers/2410.18963) (2024)
*   [ShowUI: One Vision-Language-Action Model for GUI Visual Agent](https://huggingface.co/papers/2411.17465) (2024)
*   [One STEP at a time: Language Agents are Stepwise Planners](https://huggingface.co/papers/2411.08432) (2024)

Please give a thumbs up to this comment if you found it helpful!

If you want recommendations for any Paper on Hugging Face checkout [this](https://huggingface.co/spaces/librarian-bots/recommend_similar_papers) Space

You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: ```

[@librarian-bot](https://huggingface.co/librarian-bot)
	 recommend
```

üëç

1

1

‚ù§Ô∏è

1

1

+

Reply

EditPreview

Upload images, audio, and videos by dragging in the text input, pasting, or clicking here.

Tap or paste here to upload images

Comment¬∑ [Sign up](https://huggingface.co/join?next=%2Fpapers%2F2412.09605) or [log in](https://huggingface.co/login?next=%2Fpapers%2F2412.09605) to comment

 [Upvote 28](https://huggingface.co/login?next=%2Fpapers%2F2412.09605)

*   [![Image 50](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg)](https://huggingface.co/ranpox "ranpox")
*   [![Image 51](https://huggingface.co/avatars/39408a394f0b558b10844b7a4946a8e9.svg)](https://huggingface.co/xy961218 "xy961218")
*   [![Image 52](https://cdn-avatars.huggingface.co/v1/production/uploads/669ca7e678115e16bdfc9bfc/pku8NvQKqfNQACRqm1YrW.jpeg)](https://huggingface.co/ludunjie "ludunjie")
*   [![Image 53](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PWp43VsXeltiPifGxGwrn.jpeg)](https://huggingface.co/ZeonLap "ZeonLap")
*   [![Image 54](https://cdn-avatars.huggingface.co/v1/production/uploads/1636263880877-noauth.jpeg)](https://huggingface.co/tianbaoxiexxx "tianbaoxiexxx")
*   [![Image 55](https://cdn-avatars.huggingface.co/v1/production/uploads/62c6981c9db11473f08b0c87/PKnnQ1SOrMuB4vf2cDDdG.jpeg)](https://huggingface.co/addf400 "addf400")
*   [![Image 56](https://cdn-avatars.huggingface.co/v1/production/uploads/656832dfbd65fd41ee7aa8cd/HHkyetTqNq1wIBPipzjQA.jpeg)](https://huggingface.co/kugwzk "kugwzk")
*   [![Image 57](https://huggingface.co/avatars/ae2f122bb93a7e024b5ee9cf217d7e3d.svg)](https://huggingface.co/zhang0628 "zhang0628")
*   [![Image 58](https://huggingface.co/avatars/0ff600c18fb0a6f42fa09b442edb097b.svg)](https://huggingface.co/Xinyuan626 "Xinyuan626")
*   [![Image 59](https://cdn-avatars.huggingface.co/v1/production/uploads/620783f24e28382272337ba4/zkUveQPNiDfYjgGhuFErj.jpeg)](https://huggingface.co/Tommy930 "Tommy930")
*   [![Image 60](https://cdn-avatars.huggingface.co/v1/production/uploads/1635314457124-5f32b2367e583543386214d9.jpeg)](https://huggingface.co/averoo "averoo")
*   [![Image 61](https://huggingface.co/avatars/bc0737bf4481433b669433facf6ce6f4.svg)](https://huggingface.co/5456es "5456es")
*   +16

Models citing this paper 0
--------------------------

No model linking this paper

Cite arxiv.org/abs/2412.09605 in a model README.md to link it from this page.

Datasets citing this paper 0
----------------------------

No dataset linking this paper

Cite arxiv.org/abs/2412.09605 in a dataset README.md to link it from this page.

### Spaces citing this paper 0

No Space linking this paper

Cite arxiv.org/abs/2412.09605 in a Space README.md to link it from this page.

Collections including this paper 7
----------------------------------

[#### UI Agent Collection a collection of algorithmic agents for user interfaces/interactions and program synthesis ‚Ä¢ 240 items ‚Ä¢ Updated 1 day ago ‚Ä¢ 42](https://huggingface.co/collections/yihaopeng/ui-agent-665fac501140dbe4562da21c)

[#### Awesome Computer Use Agents Collection https://github.com/ranpox/awesome-computer-use ‚Ä¢ 25 items ‚Ä¢ Updated Dec 18, 2024 ‚Ä¢ 8](https://huggingface.co/collections/ranpox/awesome-computer-use-agents-675272db99b478caa1034283)

[#### GUI agents Collection A collection of papers on GUI agents ‚Ä¢ 3 items ‚Ä¢ Updated Dec 14, 2024 ‚Ä¢ 5](https://huggingface.co/collections/thomwolf/gui-agents-675d54f9e907322a10f1cfae)

[#### Synthetic Data and Self-Improvement Collection 53 items ‚Ä¢ Updated 4 days ago ‚Ä¢ 4](https://huggingface.co/collections/kaizuberbuehler/synthetic-data-and-self-improvement-6626bb59e6563660470aefcb)

[Browse 7 collections that include this paper](https://huggingface.co/collections?paper=2412.09605)

System theme

Company

[TOS](https://huggingface.co/terms-of-service) [Privacy](https://huggingface.co/privacy) [About](https://huggingface.co/huggingface) [Jobs](https://apply.workable.com/huggingface/)[](https://huggingface.co/)

Website

[Models](https://huggingface.co/models) [Datasets](https://huggingface.co/datasets) [Spaces](https://huggingface.co/spaces) [Pricing](https://huggingface.co/pricing) [Docs](https://huggingface.co/docs)

## Metadata

```json
{
  "title": "Paper page - AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web\n  Tutorials",
  "description": "Join the discussion on this paper page",
  "url": "https://huggingface.co/papers/2412.09605",
  "content": "Paper page - AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials\n===============\n\n [![Image 32: Hugging Face's logo](https://huggingface.co/front/assets/huggingface_logo-noborder.svg) Hugging Face](https://huggingface.co/)\n\n*   [Models](https://huggingface.co/models)\n*   [Datasets](https://huggingface.co/datasets)\n*   [Spaces](https://huggingface.co/spaces)\n*   [Posts](https://huggingface.co/posts)\n*   [Docs](https://huggingface.co/docs)\n*   [Enterprise](https://huggingface.co/enterprise)\n*   [Pricing](https://huggingface.co/pricing)\n\n*   * * *\n    \n*   [Log In](https://huggingface.co/login)\n*   [Sign Up](https://huggingface.co/join)\n\n[Papers](https://huggingface.co/papers)\n\narxiv:2412.09605\n\nAgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials\n===========================================================================\n\nPublished on Dec 12, 2024\n\n¬∑ Submitted by [![Image 33](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg) ranpox](https://huggingface.co/ranpox) on Dec 13, 2024\n\n [Upvote 28](https://huggingface.co/login?next=%2Fpapers%2F2412.09605)\n\n*   [![Image 34](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg)](https://huggingface.co/ranpox \"ranpox\")\n*   [![Image 35](https://huggingface.co/avatars/39408a394f0b558b10844b7a4946a8e9.svg)](https://huggingface.co/xy961218 \"xy961218\")\n*   [![Image 36](https://cdn-avatars.huggingface.co/v1/production/uploads/669ca7e678115e16bdfc9bfc/pku8NvQKqfNQACRqm1YrW.jpeg)](https://huggingface.co/ludunjie \"ludunjie\")\n*   [![Image 37](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PWp43VsXeltiPifGxGwrn.jpeg)](https://huggingface.co/ZeonLap \"ZeonLap\")\n*   [![Image 38](https://cdn-avatars.huggingface.co/v1/production/uploads/1636263880877-noauth.jpeg)](https://huggingface.co/tianbaoxiexxx \"tianbaoxiexxx\")\n*   [![Image 39](https://cdn-avatars.huggingface.co/v1/production/uploads/62c6981c9db11473f08b0c87/PKnnQ1SOrMuB4vf2cDDdG.jpeg)](https://huggingface.co/addf400 \"addf400\")\n*   [![Image 40](https://cdn-avatars.huggingface.co/v1/production/uploads/656832dfbd65fd41ee7aa8cd/HHkyetTqNq1wIBPipzjQA.jpeg)](https://huggingface.co/kugwzk \"kugwzk\")\n*   [![Image 41](https://huggingface.co/avatars/ae2f122bb93a7e024b5ee9cf217d7e3d.svg)](https://huggingface.co/zhang0628 \"zhang0628\")\n*   +20\n\nAuthors:\n\n ![Image 42](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg) [Yiheng Xu](https://huggingface.co/ranpox) ,\n\n ![Image 43](https://cdn-avatars.huggingface.co/v1/production/uploads/669ca7e678115e16bdfc9bfc/pku8NvQKqfNQACRqm1YrW.jpeg) [Dunjie Lu](https://huggingface.co/ludunjie) ,\n\n ![Image 44](https://huggingface.co/avatars/bc0737bf4481433b669433facf6ce6f4.svg) [Zhennan Shen](https://huggingface.co/5456es) ,\n\n ![Image 45](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PWp43VsXeltiPifGxGwrn.jpeg) [Junli Wang](https://huggingface.co/ZeonLap) ,\n\n ![Image 46](https://cdn-avatars.huggingface.co/v1/production/uploads/656832dfbd65fd41ee7aa8cd/HHkyetTqNq1wIBPipzjQA.jpeg) [Zekun Wang](https://huggingface.co/kugwzk) ,\n\nYuchen Mao ,\n\n ![Image 47](https://huggingface.co/avatars/c87c273ca628dbcddccbf1ee19b2ce33.svg) [Caiming Xiong](https://huggingface.co/cxiong) ,\n\nTao Yu\n\nAbstract\n--------\n\nGraphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality GUI agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.\n\n[View arXiv page](https://arxiv.org/abs/2412.09605) [View PDF](https://arxiv.org/pdf/2412.09605) [Add to collection](https://huggingface.co/login?next=%2Fpapers%2F2412.09605)\n\n### Community\n\n ![Image 48](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg) [ranpox](https://huggingface.co/ranpox)Paper author Paper submitter [Dec 13, 2024](https://huggingface.co/papers/2412.09605#675bd05a065c05f943b1ea70)\n\n[https://agenttrek.github.io/](https://agenttrek.github.io/)\n\nüöÄ\n\n4\n\n4\n\n+\n\nReply\n\n ![Image 49](https://cdn-avatars.huggingface.co/v1/production/uploads/1674830754237-63d3e0e8ff1384ce6c5dd17d.jpeg) [librarian-bot](https://huggingface.co/librarian-bot)[Dec 14, 2024](https://huggingface.co/papers/2412.09605#675ce0c11bdf6700768b9754)\n\nThis is an automated message from the [Librarian Bot](https://huggingface.co/librarian-bots). I found the following papers similar to this paper.\n\nThe following papers were recommended by the Semantic Scholar API\n\n*   [Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction](https://huggingface.co/papers/2412.04454) (2024)\n*   [AutoGLM: Autonomous Foundation Agents for GUIs](https://huggingface.co/papers/2411.00820) (2024)\n*   [Ponder&Press: Advancing Visual GUI Agent towards General Computer Control](https://huggingface.co/papers/2412.01268) (2024)\n*   [Large Language Model-Brained GUI Agents: A Survey](https://huggingface.co/papers/2411.18279) (2024)\n*   [OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning](https://huggingface.co/papers/2410.18963) (2024)\n*   [ShowUI: One Vision-Language-Action Model for GUI Visual Agent](https://huggingface.co/papers/2411.17465) (2024)\n*   [One STEP at a time: Language Agents are Stepwise Planners](https://huggingface.co/papers/2411.08432) (2024)\n\nPlease give a thumbs up to this comment if you found it helpful!\n\nIf you want recommendations for any Paper on Hugging Face checkout [this](https://huggingface.co/spaces/librarian-bots/recommend_similar_papers) Space\n\nYou can directly ask Librarian Bot for paper recommendations by tagging it in a comment: ```\n\n[@librarian-bot](https://huggingface.co/librarian-bot)\n\t recommend\n```\n\nüëç\n\n1\n\n1\n\n‚ù§Ô∏è\n\n1\n\n1\n\n+\n\nReply\n\nEditPreview\n\nUpload images, audio, and videos by dragging in the text input, pasting, or clicking here.\n\nTap or paste here to upload images\n\nComment¬∑ [Sign up](https://huggingface.co/join?next=%2Fpapers%2F2412.09605) or [log in](https://huggingface.co/login?next=%2Fpapers%2F2412.09605) to comment\n\n [Upvote 28](https://huggingface.co/login?next=%2Fpapers%2F2412.09605)\n\n*   [![Image 50](https://cdn-avatars.huggingface.co/v1/production/uploads/1620447944896-601d29ab913ad3afd7b7ddb8.jpeg)](https://huggingface.co/ranpox \"ranpox\")\n*   [![Image 51](https://huggingface.co/avatars/39408a394f0b558b10844b7a4946a8e9.svg)](https://huggingface.co/xy961218 \"xy961218\")\n*   [![Image 52](https://cdn-avatars.huggingface.co/v1/production/uploads/669ca7e678115e16bdfc9bfc/pku8NvQKqfNQACRqm1YrW.jpeg)](https://huggingface.co/ludunjie \"ludunjie\")\n*   [![Image 53](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PWp43VsXeltiPifGxGwrn.jpeg)](https://huggingface.co/ZeonLap \"ZeonLap\")\n*   [![Image 54](https://cdn-avatars.huggingface.co/v1/production/uploads/1636263880877-noauth.jpeg)](https://huggingface.co/tianbaoxiexxx \"tianbaoxiexxx\")\n*   [![Image 55](https://cdn-avatars.huggingface.co/v1/production/uploads/62c6981c9db11473f08b0c87/PKnnQ1SOrMuB4vf2cDDdG.jpeg)](https://huggingface.co/addf400 \"addf400\")\n*   [![Image 56](https://cdn-avatars.huggingface.co/v1/production/uploads/656832dfbd65fd41ee7aa8cd/HHkyetTqNq1wIBPipzjQA.jpeg)](https://huggingface.co/kugwzk \"kugwzk\")\n*   [![Image 57](https://huggingface.co/avatars/ae2f122bb93a7e024b5ee9cf217d7e3d.svg)](https://huggingface.co/zhang0628 \"zhang0628\")\n*   [![Image 58](https://huggingface.co/avatars/0ff600c18fb0a6f42fa09b442edb097b.svg)](https://huggingface.co/Xinyuan626 \"Xinyuan626\")\n*   [![Image 59](https://cdn-avatars.huggingface.co/v1/production/uploads/620783f24e28382272337ba4/zkUveQPNiDfYjgGhuFErj.jpeg)](https://huggingface.co/Tommy930 \"Tommy930\")\n*   [![Image 60](https://cdn-avatars.huggingface.co/v1/production/uploads/1635314457124-5f32b2367e583543386214d9.jpeg)](https://huggingface.co/averoo \"averoo\")\n*   [![Image 61](https://huggingface.co/avatars/bc0737bf4481433b669433facf6ce6f4.svg)](https://huggingface.co/5456es \"5456es\")\n*   +16\n\nModels citing this paper 0\n--------------------------\n\nNo model linking this paper\n\nCite arxiv.org/abs/2412.09605 in a model README.md to link it from this page.\n\nDatasets citing this paper 0\n----------------------------\n\nNo dataset linking this paper\n\nCite arxiv.org/abs/2412.09605 in a dataset README.md to link it from this page.\n\n### Spaces citing this paper 0\n\nNo Space linking this paper\n\nCite arxiv.org/abs/2412.09605 in a Space README.md to link it from this page.\n\nCollections including this paper 7\n----------------------------------\n\n[#### UI Agent Collection a collection of algorithmic agents for user interfaces/interactions and program synthesis ‚Ä¢ 240 items ‚Ä¢ Updated 1 day ago ‚Ä¢ 42](https://huggingface.co/collections/yihaopeng/ui-agent-665fac501140dbe4562da21c)\n\n[#### Awesome Computer Use Agents Collection https://github.com/ranpox/awesome-computer-use ‚Ä¢ 25 items ‚Ä¢ Updated Dec 18, 2024 ‚Ä¢ 8](https://huggingface.co/collections/ranpox/awesome-computer-use-agents-675272db99b478caa1034283)\n\n[#### GUI agents Collection A collection of papers on GUI agents ‚Ä¢ 3 items ‚Ä¢ Updated Dec 14, 2024 ‚Ä¢ 5](https://huggingface.co/collections/thomwolf/gui-agents-675d54f9e907322a10f1cfae)\n\n[#### Synthetic Data and Self-Improvement Collection 53 items ‚Ä¢ Updated 4 days ago ‚Ä¢ 4](https://huggingface.co/collections/kaizuberbuehler/synthetic-data-and-self-improvement-6626bb59e6563660470aefcb)\n\n[Browse 7 collections that include this paper](https://huggingface.co/collections?paper=2412.09605)\n\nSystem theme\n\nCompany\n\n[TOS](https://huggingface.co/terms-of-service) [Privacy](https://huggingface.co/privacy) [About](https://huggingface.co/huggingface) [Jobs](https://apply.workable.com/huggingface/)[](https://huggingface.co/)\n\nWebsite\n\n[Models](https://huggingface.co/models) [Datasets](https://huggingface.co/datasets) [Spaces](https://huggingface.co/spaces) [Pricing](https://huggingface.co/pricing) [Docs](https://huggingface.co/docs)",
  "usage": {
    "tokens": 3530
  }
}
```
