3D Machine Learning

In recent years, tremendous amount of progress is being made in the field of 3D Machine Learning, which is an interdisciplinary field that fuses computer vision, computer graphics and machine learning. This repo is derived from my study notes and will be used as a place for triaging new research papers.

I'll use the following icons to differentiate 3D representations:

*   üì∑ Multi-view Images
*   üëæ Volumetric
*   üé≤ Point Cloud
*   üíé Polygonal Mesh
*   üíä Primitive-based

To find related papers and their relationships, check out [Connected Papers](https://www.connectedpapers.com/), which provides a neat way to visualize the academic field in a graph representation.

Get Involved
------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#get-involved)

To contribute to this Repo, you may add content through pull requests or open an issue to let me know.

‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê  
We have also created a Slack workplace for people around the globe to ask questions, share knowledge and facilitate collaborations. Together, I'm sure we can advance this field as a collaborative effort. Join the community with [this link](https://join.slack.com/t/3d-machine-learning/shared_invite/zt-4hsgj8zb-G6OKrBcc17QBB9ppYETgCQ).  
‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê ‚≠ê

Table of Contents
-----------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#table-of-contents)

*   [Courses](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#courses)
*   [Datasets](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#datasets)
    *   [3D Models](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d_models)
    *   [3D Scenes](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d_scenes)
*   [3D Pose Estimation](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#pose_estimation)
*   [Single Object Classification](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#single_classification)
*   [Multiple Objects Detection](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#multiple_detection)
*   [Scene/Object Semantic Segmentation](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#segmentation)
*   [3D Geometry Synthesis/Reconstruction](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d_synthesis)
    *   [Parametric Morphable Model-based methods](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d_synthesis_model_based)
    *   [Part-based Template Learning methods](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d_synthesis_template_based)
    *   [Deep Learning Methods](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d_synthesis_dl_based)
*   [Texture/Material Analysis and Synthesis](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#material_synthesis)
*   [Style Learning and Transfer](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#style_transfer)
*   [Scene Synthesis/Reconstruction](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#scene_synthesis)
*   [Scene Understanding](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#scene_understanding)

Available Courses
-----------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#available-courses)

[Stanford CS231A: Computer Vision-From 3D Reconstruction to Recognition (Winter 2018)](http://web.stanford.edu/class/cs231a/)

[UCSD CSE291-I00: Machine Learning for 3D Data (Winter 2018)](https://cse291-i.github.io/index.html)

[Stanford CS468: Machine Learning for 3D Data (Spring 2017)](http://graphics.stanford.edu/courses/cs468-17-spring/)

[MIT 6.838: Shape Analysis (Spring 2017)](http://groups.csail.mit.edu/gdpgroup/6838_spring_2017.html)

[Princeton COS 526: Advanced Computer Graphics (Fall 2010)](https://www.cs.princeton.edu/courses/archive/fall10/cos526/syllabus.php)

[Princeton CS597: Geometric Modeling and Analysis (Fall 2003)](https://www.cs.princeton.edu/courses/archive/fall03/cs597D/)

[Geometric Deep Learning](http://geometricdeeplearning.com/)

[Paper Collection for 3D Understanding](https://www.cs.princeton.edu/courses/archive/spring15/cos598A/cos598A.html#Estimating)

[CreativeAI: Deep Learning for Graphics](https://geometry.cs.ucl.ac.uk/workshops/creativeai/)

Datasets
--------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#datasets)

To see a survey of RGBD datasets, check out Michael Firman's [collection](http://www.michaelfirman.co.uk/RGBDdatasets/index.html) as well as the associated paper, [RGBD Datasets: Past, Present and Future](https://arxiv.org/pdf/1604.00999.pdf). Point Cloud Library also has a good dataset [catalogue](https://pointclouds.org/).

### 3D Models

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d-models)

**Princeton Shape Benchmark (2003)** [\[Link\]](http://shape.cs.princeton.edu/benchmark/)  
1,814 models collected from the web in .OFF format. Used to evaluating shape-based retrieval and analysis algorithms.

[![Image 697](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Princeton%20Shape%20Benchmark%20(2003).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Princeton%20Shape%20Benchmark%20(2003).jpeg)

**Dataset for IKEA 3D models and aligned images (2013)** [\[Link\]](http://ikea.csail.mit.edu/)  
759 images and 219 models including Sketchup (skp) and Wavefront (obj) files, good for pose estimation.

[![Image 698](https://camo.githubusercontent.com/68a842a9d1eee70c84081a3c53969ca15c5f73e714690acdb4ba4b1eef95d169/687474703a2f2f696b65612e637361696c2e6d69742e6564752f7765625f696d672f696b65615f6f626a6563742e706e67)](https://camo.githubusercontent.com/68a842a9d1eee70c84081a3c53969ca15c5f73e714690acdb4ba4b1eef95d169/687474703a2f2f696b65612e637361696c2e6d69742e6564752f7765625f696d672f696b65615f6f626a6563742e706e67)

**Open Surfaces: A Richly Annotated Catalog of Surface Appearance (SIGGRAPH 2013)** [\[Link\]](http://opensurfaces.cs.cornell.edu/)  
OpenSurfaces is a large database of annotated surfaces created from real-world consumer photographs. Our annotation framework draws on crowdsourcing to segment surfaces from photos, and then annotate them with rich surface properties, including material, texture and contextual information.

[![Image 699](https://camo.githubusercontent.com/10f3731c5db7f4e34df980da07cf964d469fc4d33aa35fd28d965ecee0571dae/687474703a2f2f6f70656e73757266616365732e63732e636f726e656c6c2e6564752f7374617469632f696d672f746561736572342d7765622e6a7067)](https://camo.githubusercontent.com/10f3731c5db7f4e34df980da07cf964d469fc4d33aa35fd28d965ecee0571dae/687474703a2f2f6f70656e73757266616365732e63732e636f726e656c6c2e6564752f7374617469632f696d672f746561736572342d7765622e6a7067)

**PASCAL3D+ (2014)** [\[Link\]](http://cvgl.stanford.edu/projects/pascal3d.html)  
12 categories, on average 3k+ objects per category, for 3D object detection and pose estimation.

[![Image 700](https://camo.githubusercontent.com/c9f11e7c292664c852327eb2598e2c33cdfce0fe3d957dcc9d0709e153f26e56/687474703a2f2f6376676c2e7374616e666f72642e6564752f70726f6a656374732f70617363616c33642b2f70617363616c33642e706e67)](https://camo.githubusercontent.com/c9f11e7c292664c852327eb2598e2c33cdfce0fe3d957dcc9d0709e153f26e56/687474703a2f2f6376676c2e7374616e666f72642e6564752f70726f6a656374732f70617363616c33642b2f70617363616c33642e706e67)

**ModelNet (2015)** [\[Link\]](http://modelnet.cs.princeton.edu/#)  
127915 3D CAD models from 662 categories  
ModelNet10: 4899 models from 10 categories  
ModelNet40: 12311 models from 40 categories, all are uniformly orientated

[![Image 701](https://camo.githubusercontent.com/8ccf53052eb7189f83c3c0e96605e5c78002a69dc1414dde21709f8dbb2fe44c/687474703a2f2f3364766973696f6e2e7072696e6365746f6e2e6564752f70726f6a656374732f323031342f4d6f64656c4e65742f7468756d626e61696c2e6a7067)](https://camo.githubusercontent.com/8ccf53052eb7189f83c3c0e96605e5c78002a69dc1414dde21709f8dbb2fe44c/687474703a2f2f3364766973696f6e2e7072696e6365746f6e2e6564752f70726f6a656374732f323031342f4d6f64656c4e65742f7468756d626e61696c2e6a7067)

**ShapeNet (2015)** [\[Link\]](https://www.shapenet.org/)  
3Million+ models and 4K+ categories. A dataset that is large in scale, well organized and richly annotated.  
ShapeNetCore [\[Link\]](http://shapenet.cs.stanford.edu/shrec16/): 51300 models for 55 categories.

[![Image 702](https://camo.githubusercontent.com/699cba60b39c081e78b64b7cac7a0b3e0db0f2a544be730899e527539297c752/687474703a2f2f6d73617676612e6769746875622e696f2f66696c65732f73686170656e65742e706e67)](https://camo.githubusercontent.com/699cba60b39c081e78b64b7cac7a0b3e0db0f2a544be730899e527539297c752/687474703a2f2f6d73617676612e6769746875622e696f2f66696c65732f73686170656e65742e706e67)

**A Large Dataset of Object Scans (2016)** [\[Link\]](http://redwood-data.org/3dscan/index.html)  
10K scans in RGBD + reconstructed 3D models in .PLY format.

[![Image 703](https://camo.githubusercontent.com/37e82426f7e068bd560fdc32f2ce5ea468dcf2d0bf8d628f2f5b7b0618a4967b/687474703a2f2f726564776f6f642d646174612e6f72672f33647363616e2f696d672f7465617365722e6a7067)](https://camo.githubusercontent.com/37e82426f7e068bd560fdc32f2ce5ea468dcf2d0bf8d628f2f5b7b0618a4967b/687474703a2f2f726564776f6f642d646174612e6f72672f33647363616e2f696d672f7465617365722e6a7067)

**ObjectNet3D: A Large Scale Database for 3D Object Recognition (2016)** [\[Link\]](http://cvgl.stanford.edu/projects/objectnet3d/)  
100 categories, 90,127 images, 201,888 objects in these images and 44,147 3D shapes.  
Tasks: region proposal generation, 2D object detection, joint 2D detection and 3D object pose estimation, and image-based 3D shape retrieval

[![Image 704](https://camo.githubusercontent.com/ddeeb24a27faa2bfbb78cc9a0341669bd0e3439ed5d5cedd6f6465efcb68ffd3/687474703a2f2f6376676c2e7374616e666f72642e6564752f70726f6a656374732f6f626a6563746e657433642f4f626a6563744e657433442e706e67)](https://camo.githubusercontent.com/ddeeb24a27faa2bfbb78cc9a0341669bd0e3439ed5d5cedd6f6465efcb68ffd3/687474703a2f2f6376676c2e7374616e666f72642e6564752f70726f6a656374732f6f626a6563746e657433642f4f626a6563744e657433442e706e67)

**Thingi10K: A Dataset of 10,000 3D-Printing Models (2016)** [\[Link\]](https://ten-thousand-models.appspot.com/)  
10,000 models from featured ‚Äúthings‚Äù on thingiverse.com, suitable for testing 3D printing techniques such as structural analysis , shape optimization, or solid geometry operations.

[![Image 705](https://camo.githubusercontent.com/f71c1f460a770742bc534d4737f7f42feb32edf47e90d7160bc3c28ee9a71c71/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44526278576e71586b4145454830672e6a70673a6c61726765)](https://camo.githubusercontent.com/f71c1f460a770742bc534d4737f7f42feb32edf47e90d7160bc3c28ee9a71c71/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44526278576e71586b4145454830672e6a70673a6c61726765)

**ABC: A Big CAD Model Dataset For Geometric Deep Learning** [\[Link\]](https://cs.nyu.edu/~zhongshi/publication/abc-dataset/)[\[Paper\]](https://arxiv.org/abs/1812.06216)  
This work introduce a dataset for geometric deep learning consisting of over 1 million individual (and high quality) geometric models, each associated with accurate ground truth information on the decomposition into patches, explicit sharp feature annotations, and analytic differential properties.

[![Image 706](https://camo.githubusercontent.com/1fe73eb682338b94c70ac2eaae08d2745964b19099c4c5df734a805457539497/68747470733a2f2f63732e6e79752e6564752f7e7a686f6e677368692f696d672f6162632d646174617365742e706e67)](https://camo.githubusercontent.com/1fe73eb682338b94c70ac2eaae08d2745964b19099c4c5df734a805457539497/68747470733a2f2f63732e6e79752e6564752f7e7a686f6e677368692f696d672f6162632d646174617365742e706e67)

üé≤ **ScanObjectNN: A New Benchmark Dataset and Classification Model on Real-World Data (ICCV 2019)** [\[Link\]](https://hkust-vgd.github.io/scanobjectnn/)  
This work introduce ScanObjectNN, a new real-world point cloud object dataset based on scanned indoor scene data. The comprehensive benchmark in this work shows that this dataset poses great challenges to existing point cloud classification techniques as objects from real-world scans are often cluttered with background and/or are partial due to occlusions. Three key open problems for point cloud object classification are identified, and a new point cloud classification neural network that achieves state-of-the-art performance on classifying objects with cluttered background is proposed.

[![Image 707](https://camo.githubusercontent.com/3f6b50f985894cae8965360c351c3bbe1b4e1aeaba1fc370eb8faed106ada0f9/68747470733a2f2f686b7573742d7667642e6769746875622e696f2f7363616e6f626a6563746e6e2f696d616765732f6f626a656374735f7465617365722e706e67)](https://camo.githubusercontent.com/3f6b50f985894cae8965360c351c3bbe1b4e1aeaba1fc370eb8faed106ada0f9/68747470733a2f2f686b7573742d7667642e6769746875622e696f2f7363616e6f626a6563746e6e2f696d616765732f6f626a656374735f7465617365722e706e67)

**VOCASET: Speech-4D Head Scan Dataset (2019(** [\[Link\]](https://voca.is.tue.mpg.de/)[\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/510/paper_final.pdf)  
[VOCASET](https://voca.is.tue.mpg.de/), is a 4D face dataset with about 29 minutes of 4D scans captured at 60 fps and synchronized audio. The dataset has 12 subjects and 480 sequences of about 3-4 seconds each with sentences chosen from an array of standard protocols that maximize phonetic diversity.

[![Image 708](https://github.com/TimoBolkart/voca/raw/master/gif/vocaset.gif)](https://github.com/TimoBolkart/voca/blob/master/gif/vocaset.gif)

**3D-FUTURE: 3D FUrniture shape with TextURE (2020)** [\[Link\]](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future?spm=5176.14208320.0.0.66293cf7asRnrR)  
[3D-FUTURE](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-future) contains 20,000+ clean and realistic synthetic scenes in 5,000+ diverse rooms, which include 10,000+ unique high quality 3D instances of furniture with high resolution informative textures developed by professional designers.

[![Image 709](https://camo.githubusercontent.com/d065bb4d72cfef68d1c592a48e04dc15abc390c64d6688df7c1e8f3a21f3a75a/68747470733a2f2f696d672e616c6963646e2e636f6d2f7466732f544231485453667a347631674b306a535a464658586230735858612d313939392d313033372e706e67)](https://camo.githubusercontent.com/d065bb4d72cfef68d1c592a48e04dc15abc390c64d6688df7c1e8f3a21f3a75a/68747470733a2f2f696d672e616c6963646e2e636f6d2f7466732f544231485453667a347631674b306a535a464658586230735858612d313939392d313033372e706e67)

**Fusion 360 Gallery Dataset (2020)** [\[Link\]](https://github.com/AutodeskAILab/Fusion360GalleryDataset)[\[Paper\]](https://arxiv.org/abs/2010.02392)  
The [Fusion 360 Gallery Dataset](https://github.com/AutodeskAILab/Fusion360GalleryDataset) contains rich 2D and 3D geometry data derived from parametric CAD models. The Reconstruction Dataset provides sequential construction sequence information from a subset of simple 'sketch and extrude' designs. The Segmentation Dataset provides a segmentation of 3D models based on the CAD modeling operation, including B-Rep format, mesh, and point cloud.

[![Image 710](https://raw.githubusercontent.com/AutodeskAILab/Fusion360GalleryDataset/master/docs/images/reconstruction_teaser.jpg)](https://raw.githubusercontent.com/AutodeskAILab/Fusion360GalleryDataset/master/docs/images/reconstruction_teaser.jpg) [![Image 711](https://raw.githubusercontent.com/AutodeskAILab/Fusion360GalleryDataset/master/docs/images/segmentation_example.jpg)](https://raw.githubusercontent.com/AutodeskAILab/Fusion360GalleryDataset/master/docs/images/segmentation_example.jpg)

**Mechanical Components Benchmark (2020)**[\[Link\]](https://mechanical-components.herokuapp.com/)[\[Paper\]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630171.pdf)  
[MCB](https://mechanical-components.herokuapp.com/) is a large-scale dataset of 3D objects of mechanical components. It has a total number of 58,696 mechanical components with 68 classes.

[![Image 712](https://camo.githubusercontent.com/f6957e1a202b3a1cee232062850e901926a20a4348c1ed3b0c33d936e87f43e9/68747470733a2f2f6d656368616e6963616c2d636f6d706f6e656e74732e6865726f6b756170702e636f6d2f7374617469632f696d672f6d61696e5f6669677572652e706e67)](https://camo.githubusercontent.com/f6957e1a202b3a1cee232062850e901926a20a4348c1ed3b0c33d936e87f43e9/68747470733a2f2f6d656368616e6963616c2d636f6d706f6e656e74732e6865726f6b756170702e636f6d2f7374617469632f696d672f6d61696e5f6669677572652e706e67)

**Combinatorial 3D Shape Dataset (2020)** [\[Link\]](https://github.com/POSTECH-CVLab/Combinatorial-3D-Shape-Generation)[\[Paper\]](https://arxiv.org/abs/2004.07414)  
[Combinatorial 3D Shape Dataset](https://github.com/POSTECH-CVLab/Combinatorial-3D-Shape-Generation) is composed of 406 instances of 14 classes. Each object in our dataset is considered equivalent to a sequence of primitive placement. Compared to other 3D object datasets, our proposed dataset contains an assembling sequence of unit primitives. It implies that we can quickly obtain a sequential generation process that is a human assembling mechanism. Furthermore, we can sample valid random sequences from a given combinatorial shape after validating the sampled sequences. To sum up, the characteristics of our combinatorial 3D shape dataset are (i) combinatorial, (ii) sequential, (iii) decomposable, and (iv) manipulable.

[![Image 713](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/combinatorial_3d_shape_dataset.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/combinatorial_3d_shape_dataset.png)

### 3D Scenes

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d-scenes)

**NYU Depth Dataset V2 (2012)** [\[Link\]](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)  
1449 densely labeled pairs of aligned RGB and depth images from Kinect video sequences for a variety of indoor scenes.

[![Image 714](https://camo.githubusercontent.com/99cb8491153427271c489a942b93ec85686ab4b1ee0c656d0415040abe8c1984/68747470733a2f2f63732e6e79752e6564752f7e73696c6265726d616e2f696d616765732f6e79755f64657074685f76325f6c6162656c65642e6a7067)](https://camo.githubusercontent.com/99cb8491153427271c489a942b93ec85686ab4b1ee0c656d0415040abe8c1984/68747470733a2f2f63732e6e79752e6564752f7e73696c6265726d616e2f696d616765732f6e79755f64657074685f76325f6c6162656c65642e6a7067)

**SUNRGB-D 3D Object Detection Challenge** [\[Link\]](http://rgbd.cs.princeton.edu/challenge.html)  
19 object categories for predicting a 3D bounding box in real world dimension  
Training set: 10,355 RGB-D scene images, Testing set: 2860 RGB-D images

[![Image 715](https://camo.githubusercontent.com/664be2b18e6929ffc00d8e0609df0f8fd61f10ecdf68489865e9a3c73ea6d6ba/687474703a2f2f726762642e63732e7072696e6365746f6e2e6564752f3364626f782e706e67)](https://camo.githubusercontent.com/664be2b18e6929ffc00d8e0609df0f8fd61f10ecdf68489865e9a3c73ea6d6ba/687474703a2f2f726762642e63732e7072696e6365746f6e2e6564752f3364626f782e706e67)

**SceneNN (2016)** [\[Link\]](http://www.scenenn.net/)  
100+ indoor scene meshes with per-vertex and per-pixel annotation.

[![Image 716](https://camo.githubusercontent.com/f6da17c3a3419265fcf67f982e97c40572f1e0db6157b00551042803b47ac91e/68747470733a2f2f63646e2d616b2e662e73742d686174656e612e636f6d2f696d616765732f666f746f6c6966652f722f726f626f6e6368752f32303137303631312f32303137303631313135353632352e706e67)](https://camo.githubusercontent.com/f6da17c3a3419265fcf67f982e97c40572f1e0db6157b00551042803b47ac91e/68747470733a2f2f63646e2d616b2e662e73742d686174656e612e636f6d2f696d616765732f666f746f6c6966652f722f726f626f6e6368752f32303137303631312f32303137303631313135353632352e706e67)

**ScanNet (2017)** [\[Link\]](http://www.scan-net.org/)  
An RGB-D video dataset containing 2.5 million views in more than 1500 scans, annotated with 3D camera poses, surface reconstructions, and instance-level semantic segmentations.

[![Image 717](https://camo.githubusercontent.com/17d7c30998142e5a84f46822585f937aaa5908b4b531e3c854638c034d28b98b/687474703a2f2f7777772e7363616e2d6e65742e6f72672f696d672f616e6e6f746174696f6e732e706e67)](https://camo.githubusercontent.com/17d7c30998142e5a84f46822585f937aaa5908b4b531e3c854638c034d28b98b/687474703a2f2f7777772e7363616e2d6e65742e6f72672f696d672f616e6e6f746174696f6e732e706e67)

**Matterport3D: Learning from RGB-D Data in Indoor Environments (2017)** [\[Link\]](https://niessner.github.io/Matterport/)  
10,800 panoramic views (in both RGB and depth) from 194,400 RGB-D images of 90 building-scale scenes of private rooms. Instance-level semantic segmentations are provided for region (living room, kitchen) and object (sofa, TV) categories.

[![Image 718](https://camo.githubusercontent.com/b11cb91ce6ab32dc63255b17e98d48544a45a08037ae049d27378faef7f27aba/68747470733a2f2f6e696573736e65722e6769746875622e696f2f4d6174746572706f72742f7465617365722e706e67)](https://camo.githubusercontent.com/b11cb91ce6ab32dc63255b17e98d48544a45a08037ae049d27378faef7f27aba/68747470733a2f2f6e696573736e65722e6769746875622e696f2f4d6174746572706f72742f7465617365722e706e67)

**SUNCG: A Large 3D Model Repository for Indoor Scenes (2017)** [\[Link\]](http://suncg.cs.princeton.edu/)  
The dataset contains over 45K different scenes with manually created realistic room and furniture layouts. All of the scenes are semantically annotated at the object level.

[![Image 719](https://camo.githubusercontent.com/a784f1f0069ba50bd916b5cd6fa3354ef06a71c9b163bdbbb98f6fc306314288/687474703a2f2f73756e63672e63732e7072696e6365746f6e2e6564752f666967757265732f646174615f66756c6c2e706e67)](https://camo.githubusercontent.com/a784f1f0069ba50bd916b5cd6fa3354ef06a71c9b163bdbbb98f6fc306314288/687474703a2f2f73756e63672e63732e7072696e6365746f6e2e6564752f666967757265732f646174615f66756c6c2e706e67)

**MINOS: Multimodal Indoor Simulator (2017)** [\[Link\]](https://github.com/minosworld/minos)  
MINOS is a simulator designed to support the development of multisensory models for goal-directed navigation in complex indoor environments. MINOS leverages large datasets of complex 3D environments and supports flexible configuration of multimodal sensor suites. MINOS supports SUNCG and Matterport3D scenes.

[![Image 720](https://camo.githubusercontent.com/4dd0efc46afb59eef41bafc1d0a80337a0334212e3abb9cd2caa2488439ddba4/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031372f31322f4d494e4f532e6a7067)](https://camo.githubusercontent.com/4dd0efc46afb59eef41bafc1d0a80337a0334212e3abb9cd2caa2488439ddba4/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031372f31322f4d494e4f532e6a7067)

**Facebook House3D: A Rich and Realistic 3D Environment (2017)** [\[Link\]](https://github.com/facebookresearch/House3D)  
House3D is a virtual 3D environment which consists of 45K indoor scenes equipped with a diverse set of scene types, layouts and objects sourced from the SUNCG dataset. All 3D objects are fully annotated with category labels. Agents in the environment have access to observations of multiple modalities, including RGB images, depth, segmentation masks and top-down 2D map views.

[![Image 721](https://user-images.githubusercontent.com/1381301/33509559-87c4e470-d6b7-11e7-8266-27c940d5729a.jpg)](https://user-images.githubusercontent.com/1381301/33509559-87c4e470-d6b7-11e7-8266-27c940d5729a.jpg)

**HoME: a Household Multimodal Environment (2017)** [\[Link\]](https://home-platform.github.io/)  
HoME integrates over 45,000 diverse 3D house layouts based on the SUNCG dataset, a scale which may facilitate learning, generalization, and transfer. HoME is an open-source, OpenAI Gym-compatible platform extensible to tasks in reinforcement learning, language grounding, sound-based navigation, robotics, multi-agent learning.

[![Image 722](https://camo.githubusercontent.com/88ff72ba99a56a3c5133684d4e2dedb4abb6da324d0d37de120499a688f8d6f7/68747470733a2f2f686f6d652d706c6174666f726d2e6769746875622e696f2f6173736574732f6f766572766965772e706e67)](https://camo.githubusercontent.com/88ff72ba99a56a3c5133684d4e2dedb4abb6da324d0d37de120499a688f8d6f7/68747470733a2f2f686f6d652d706c6174666f726d2e6769746875622e696f2f6173736574732f6f766572766965772e706e67)

**AI2-THOR: Photorealistic Interactive Environments for AI Agents** [\[Link\]](http://ai2thor.allenai.org/)  
AI2-THOR is a photo-realistic interactable framework for AI agents. There are a total 120 scenes in version 1.0 of the THOR environment covering four different room categories: kitchens, living rooms, bedrooms, and bathrooms. Each room has a number of actionable objects.

[![Image 723](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/AI2-Thor.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/AI2-Thor.jpeg)

**UnrealCV: Virtual Worlds for Computer Vision (2017)** [\[Link\]](http://unrealcv.org/)[\[Paper\]](http://www.idm.pku.edu.cn/staff/wangyizhou/papers/ACMMM2017_UnrealCV.pdf)  
An open source project to help computer vision researchers build virtual worlds using Unreal Engine 4.

[![Image 724](https://camo.githubusercontent.com/5db1c3c5da8c1d095c97c6d80640d4d9f072e4dce6b1aca7ae5d618c6510c47a/687474703a2f2f756e7265616c63762e6f72672f696d616765732f686f6d65706167655f7465617365722e706e67)](https://camo.githubusercontent.com/5db1c3c5da8c1d095c97c6d80640d4d9f072e4dce6b1aca7ae5d618c6510c47a/687474703a2f2f756e7265616c63762e6f72672f696d616765732f686f6d65706167655f7465617365722e706e67)

**Gibson Environment: Real-World Perception for Embodied Agents (2018 CVPR)** [\[Link\]](http://gibsonenv.stanford.edu/)  
This platform provides RGB from 1000 point clouds, as well as multimodal sensor data: surface normal, depth, and for a fraction of the spaces, semantics object annotations. The environment is also RL ready with physics integrated. Using such datasets can further narrow down the discrepency between virtual environment and real world.

[![Image 725](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Gibson%20Environment-%20Real-World%20Perception%20for%20Embodied%20Agents%20(2018%20CVPR)%20.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Gibson%20Environment-%20Real-World%20Perception%20for%20Embodied%20Agents%20(2018%20CVPR)%20.jpeg)

**InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes Dataset** [\[Link\]](https://interiornet.org/)  
System Overview: an end-to-end pipeline to render an RGB-D-inertial benchmark for large scale interior scene understanding and mapping. Our dataset contains 20M images created by pipeline: (A) We collect around 1 million CAD models provided by world-leading furniture manufacturers. These models have been used in the real-world production. (B) Based on those models, around 1,100 professional designers create around 22 million interior layouts. Most of such layouts have been used in real-world decorations. (C) For each layout, we generate a number of configurations to represent different random lightings and simulation of scene change over time in daily life. (D) We provide an interactive simulator (ViSim) to help for creating ground truth IMU, events, as well as monocular or stereo camera trajectories including hand-drawn, random walking and neural network based realistic trajectory. (E) All supported image sequences and ground truth.

[![Image 726](https://camo.githubusercontent.com/afc00ad91c90473fe6dda6179572f0db162eacf0cd4b14e2bc5f8b290a84f59e/68747470733a2f2f696e746572696f726e65742e6f72672f6974656d732f496e746572696f724e65742e6a7067)](https://camo.githubusercontent.com/afc00ad91c90473fe6dda6179572f0db162eacf0cd4b14e2bc5f8b290a84f59e/68747470733a2f2f696e746572696f726e65742e6f72672f6974656d732f496e746572696f724e65742e6a7067)

**Semantic3D**[\[Link\]](http://www.semantic3d.net/)  
Large-Scale Point Cloud Classification Benchmark, which provides a large labelled 3D point cloud data set of natural scenes with over 4 billion points in total, and also covers a range of diverse urban scenes.

[![Image 727](https://camo.githubusercontent.com/68974aed5b3c502988d35dd4a71d09a1fbc324dab2f3119527c50e7af6752597/687474703a2f2f7777772e73656d616e74696333642e6e65742f696d672f66756c6c5f7265736f6c7574696f6e2f736732375f382e6a7067)](https://camo.githubusercontent.com/68974aed5b3c502988d35dd4a71d09a1fbc324dab2f3119527c50e7af6752597/687474703a2f2f7777772e73656d616e74696333642e6e65742f696d672f66756c6c5f7265736f6c7574696f6e2f736732375f382e6a7067)

**Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling** [\[Link\]](https://structured3d-dataset.org/)

[![Image 728](https://camo.githubusercontent.com/b5a47bda33ae1abc6cc217f1124a515f5d97c6e82a43a3f1047a2ce824bcdd44/68747470733a2f2f7374727563747572656433642d646174617365742e6f72672f7374617469632f696d672f7465617365722e706e67)](https://camo.githubusercontent.com/b5a47bda33ae1abc6cc217f1124a515f5d97c6e82a43a3f1047a2ce824bcdd44/68747470733a2f2f7374727563747572656433642d646174617365742e6f72672f7374617469632f696d672f7465617365722e706e67)

**3D-FRONT: 3D Furnished Rooms with layOuts and semaNTics** [\[Link\]](https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset)  
Contains 10,000 houses (or apartments) and ~70,000 rooms with layout information.

[![Image 729](https://camo.githubusercontent.com/20016d03a57dcc312cc4c109de115d6b76df7178ce6f88cb602f755b38b26859/68747470733a2f2f696d672e616c6963646e2e636f6d2f7466732f5442313331584f4a654c32674b306a535a506858586168765858612d323939322d323735312e6a7067)](https://camo.githubusercontent.com/20016d03a57dcc312cc4c109de115d6b76df7178ce6f88cb602f755b38b26859/68747470733a2f2f696d672e616c6963646e2e636f6d2f7466732f5442313331584f4a654c32674b306a535a506858586168765858612d323939322d323735312e6a7067)

**3ThreeDWorld(TDW): A High-Fidelity, Multi-Modal Platform for Interactive Physical Simulation** [\[Link\]](http://www.threedworld.org/)

[![Image 730](https://camo.githubusercontent.com/18e39b7dda193aa1ddd2e95c5606de6c1fb82a293119ed2d59d6d8b68c64a74f/687474703a2f2f7777772e746872656564776f726c642e6f72672f696d672f67616c6c6572792f67616c6c6572792d312e6a7067)](https://camo.githubusercontent.com/18e39b7dda193aa1ddd2e95c5606de6c1fb82a293119ed2d59d6d8b68c64a74f/687474703a2f2f7777772e746872656564776f726c642e6f72672f696d672f67616c6c6572792f67616c6c6572792d312e6a7067)

**MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis** [\[Link\]](https://coohom.github.io/MINERVAS/)

[![Image 731](https://camo.githubusercontent.com/716d3c6d9fa98d37c1edcd090f9a79d1296490733bb8f1060e488c457d5e6063/68747470733a2f2f636f6f686f6d2e6769746875622e696f2f4d494e45525641532f7374617469632f696d672f7465617365722e706e67)](https://camo.githubusercontent.com/716d3c6d9fa98d37c1edcd090f9a79d1296490733bb8f1060e488c457d5e6063/68747470733a2f2f636f6f686f6d2e6769746875622e696f2f4d494e45525641532f7374617469632f696d672f7465617365722e706e67)

3D Pose Estimation
------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d-pose-estimation)

**Category-Specific Object Reconstruction from a Single Image (2014)** [\[Paper\]](https://people.eecs.berkeley.edu/~akar/categoryshapes.pdf)

[![Image 732](https://camo.githubusercontent.com/10c6c5078e069f3e5630ec8ba8e68c5d9b3fa4bafdeddd401830f7c5c9c1f461/687474703a2f2f70656f706c652e656563732e6265726b656c65792e6564752f7e616b61722f62617369737368617065735f686967687265732e706e67)](https://camo.githubusercontent.com/10c6c5078e069f3e5630ec8ba8e68c5d9b3fa4bafdeddd401830f7c5c9c1f461/687474703a2f2f70656f706c652e656563732e6265726b656c65792e6564752f7e616b61722f62617369737368617065735f686967687265732e706e67)

**Viewpoints and Keypoints (2015)** [\[Paper\]](https://people.eecs.berkeley.edu/~shubhtuls/papers/cvpr15vpsKps.pdf)

[![Image 733](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Viewpoints%20and%20Keypoints.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Viewpoints%20and%20Keypoints.jpeg)

**Render for CNN: Viewpoint Estimation in Images Using CNNs Trained with Rendered 3D Model Views (2015 ICCV)** [\[Paper\]](https://shapenet.cs.stanford.edu/projects/RenderForCNN/)

[![Image 734](https://camo.githubusercontent.com/2f67380097888912da234c9252ad8de4554931930c1945f2903f0d49d9c19493/68747470733a2f2f73686170656e65742e63732e7374616e666f72642e6564752f70726f6a656374732f52656e646572466f72434e4e2f696d616765732f7465617365722e6a7067)](https://camo.githubusercontent.com/2f67380097888912da234c9252ad8de4554931930c1945f2903f0d49d9c19493/68747470733a2f2f73686170656e65742e63732e7374616e666f72642e6564752f70726f6a656374732f52656e646572466f72434e4e2f696d616765732f7465617365722e6a7067)

**PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization (2015)** [\[Paper\]](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf)

[![Image 735](https://camo.githubusercontent.com/4e0c704414e81f40e0ac9a1bcb0a15a8a3b0d4c32aff63c482654b7d5723eba1/687474703a2f2f6d692e656e672e63616d2e61632e756b2f70726f6a656374732f72656c6f63616c69736174696f6e2f696d616765732f6d61702e706e67)](https://camo.githubusercontent.com/4e0c704414e81f40e0ac9a1bcb0a15a8a3b0d4c32aff63c482654b7d5723eba1/687474703a2f2f6d692e656e672e63616d2e61632e756b2f70726f6a656374732f72656c6f63616c69736174696f6e2f696d616765732f6d61702e706e67)

**Modeling Uncertainty in Deep Learning for Camera Relocalization (2016)** [\[Paper\]](https://arxiv.org/pdf/1509.05909.pdf)

[![Image 736](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Modeling%20Uncertainty%20in%20Deep%20Learning%20for%20Camera%20Relocalization.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Modeling%20Uncertainty%20in%20Deep%20Learning%20for%20Camera%20Relocalization.jpeg)

**Robust camera pose estimation by viewpoint classification using deep learning (2016)** [\[Paper\]](https://link.springer.com/article/10.1007/s41095-016-0067-z)

[![Image 737](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Robust%20camera%20pose%20estimation%20by%20viewpoint%20classification%20using%20deep%20learning.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Robust%20camera%20pose%20estimation%20by%20viewpoint%20classification%20using%20deep%20learning.jpeg)

**Image-based localization using lstms for structured feature correlation (2017 ICCV)** [\[Paper\]](https://arxiv.org/pdf/1611.07890.pdf)

[![Image 738](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Image-based%20localization%20using%20LSTMs%20for%20structured%20feature%20correlation.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Image-based%20localization%20using%20LSTMs%20for%20structured%20feature%20correlation.png)

**Image-Based Localization Using Hourglass Networks (2017 ICCV Workshops)** [\[Paper\]](https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w17/Melekhov_Image-Based_Localization_Using_ICCV_2017_paper.pdf)

[![Image 739](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Image-Based%20Localization%20Using%20Hourglass%20Networks.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Image-Based%20Localization%20Using%20Hourglass%20Networks.png)

**Geometric loss functions for camera pose regression with deep learning (2017 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1704.00390.pdf)

[![Image 740](https://camo.githubusercontent.com/0a8a097fa4f056b31fbaedaff8d4855ae5b5b6c9f7de13ded83f09dd4926aed2/687474703a2f2f6d692e656e672e63616d2e61632e756b2f7e6369706f6c6c612f696d616765732f706f73652d6e65742e706e67)](https://camo.githubusercontent.com/0a8a097fa4f056b31fbaedaff8d4855ae5b5b6c9f7de13ded83f09dd4926aed2/687474703a2f2f6d692e656e672e63616d2e61632e756b2f7e6369706f6c6c612f696d616765732f706f73652d6e65742e706e67)

**Generic 3D Representation via Pose Estimation and Matching (2017)** [\[Paper\]](http://3drepresentation.stanford.edu/)

[![Image 741](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Generic%203D%20Representation%20via%20Pose%20Estimation%20and%20Matching.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Generic%203D%20Representation%20via%20Pose%20Estimation%20and%20Matching.jpeg)

**3D Bounding Box Estimation Using Deep Learning and Geometry (2017)** [\[Paper\]](https://arxiv.org/pdf/1612.00496.pdf)

[![Image 742](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/3D%20Bounding%20Box%20Estimation%20Using%20Deep%20Learning%20and%20Geometry.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/3D%20Bounding%20Box%20Estimation%20Using%20Deep%20Learning%20and%20Geometry.png)

**6-DoF Object Pose from Semantic Keypoints (2017)** [\[Paper\]](https://www.seas.upenn.edu/~pavlakos/projects/object3d/)

[![Image 743](https://camo.githubusercontent.com/ea09a8d0d65152e80a6d3eb3e10c41cf48e75f93fd3afb7ca9f0defd3ac6ad61/68747470733a2f2f7777772e736561732e7570656e6e2e6564752f7e7061766c616b6f732f70726f6a656374732f6f626a65637433642f66696c65732f6f626a65637433642d7465617365722e706e67)](https://camo.githubusercontent.com/ea09a8d0d65152e80a6d3eb3e10c41cf48e75f93fd3afb7ca9f0defd3ac6ad61/68747470733a2f2f7777772e736561732e7570656e6e2e6564752f7e7061766c616b6f732f70726f6a656374732f6f626a65637433642f66696c65732f6f626a65637433642d7465617365722e706e67)

**Relative Camera Pose Estimation Using Convolutional Neural Networks (2017)** [\[Paper\]](https://arxiv.org/pdf/1702.01381.pdf)

[![Image 744](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Relative%20Camera%20Pose%20Estimation%20Using%20Convolutional%20Neural%20Networks.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Relative%20Camera%20Pose%20Estimation%20Using%20Convolutional%20Neural%20Networks.png)

**3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions (2017)** [\[Paper\]](http://3dmatch.cs.princeton.edu/)

[![Image 745](https://camo.githubusercontent.com/7c5b49f66ef5937586d1a41df3739f70d414200ca54fcd0ba68305e24d55b6c8/687474703a2f2f33646d617463682e63732e7072696e6365746f6e2e6564752f696d672f6f766572766965772e6a7067)](https://camo.githubusercontent.com/7c5b49f66ef5937586d1a41df3739f70d414200ca54fcd0ba68305e24d55b6c8/687474703a2f2f33646d617463682e63732e7072696e6365746f6e2e6564752f696d672f6f766572766965772e6a7067)

**Single Image 3D Interpreter Network (2016)** [\[Paper\]](http://3dinterpreter.csail.mit.edu/) [\[Code\]](https://github.com/jiajunwu/3dinn)

[![Image 746](https://camo.githubusercontent.com/ac7adb920d018af49df068998825c3eaf38af88ed27da534bb8c1740e17e7c06/687474703a2f2f3364696e7465727072657465722e637361696c2e6d69742e6564752f696d616765732f73706f746c696768745f3364696e6e5f6c617267652e6a7067)](https://camo.githubusercontent.com/ac7adb920d018af49df068998825c3eaf38af88ed27da534bb8c1740e17e7c06/687474703a2f2f3364696e7465727072657465722e637361696c2e6d69742e6564752f696d616765732f73706f746c696768745f3364696e6e5f6c617267652e6a7067)

**Multi-view Consistency as Supervisory Signal for Learning Shape and Pose Prediction (2018 CVPR)** [\[Paper\]](https://shubhtuls.github.io/mvcSnP/)

[![Image 747](https://camo.githubusercontent.com/e3ddb4e42fb2f4145c86834c25aaf677fcfa8643fea26bf3fe3645103c8bf32b/68747470733a2f2f736875626874756c732e6769746875622e696f2f6d7663536e502f7265736f75726365732f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/e3ddb4e42fb2f4145c86834c25aaf677fcfa8643fea26bf3fe3645103c8bf32b/68747470733a2f2f736875626874756c732e6769746875622e696f2f6d7663536e502f7265736f75726365732f696d616765732f7465617365722e706e67)

**PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes (2018)** [\[Paper\]](https://rse-lab.cs.washington.edu/projects/posecnn/)

[![Image 748](https://camo.githubusercontent.com/2469445cd7deb341d1a1cbac6fc3b32ba7324ff96ebd60c9739708173fa02989/68747470733a2f2f7975786e672e6769746875622e696f2f506f7365434e4e2e706e67)](https://camo.githubusercontent.com/2469445cd7deb341d1a1cbac6fc3b32ba7324ff96ebd60c9739708173fa02989/68747470733a2f2f7975786e672e6769746875622e696f2f506f7365434e4e2e706e67)

**Feature Mapping for Learning Fast and Accurate 3D Pose Inference from Synthetic Images (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1712.03904.pdf)

[![Image 749](https://camo.githubusercontent.com/0f19d56e0e6ddabdba184a79e4c1f8464163c8777a4ffcc8fabed29bafb917f8/68747470733a2f2f656e637279707465642d74626e302e677374617469632e636f6d2f696d616765733f713d74626e3a414e64394763546e7079616a4568626872504d6330597045517a7145384e39453743575f45565759413342786734366f55455946663958766b41)](https://camo.githubusercontent.com/0f19d56e0e6ddabdba184a79e4c1f8464163c8777a4ffcc8fabed29bafb917f8/68747470733a2f2f656e637279707465642d74626e302e677374617469632e636f6d2f696d616765733f713d74626e3a414e64394763546e7079616a4568626872504d6330597045517a7145384e39453743575f45565759413342786734366f55455946663958766b41)

**Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling (2018 CVPR)** [\[Paper\]](http://pix3d.csail.mit.edu/)

[![Image 750](https://camo.githubusercontent.com/9b31ec0fec15e4b8fb76e0a501ee66a44b179268034827c7f9105f37811ae4a4/687474703a2f2f70697833642e637361696c2e6d69742e6564752f696d616765732f73706f746c696768745f70697833642e6a7067)](https://camo.githubusercontent.com/9b31ec0fec15e4b8fb76e0a501ee66a44b179268034827c7f9105f37811ae4a4/687474703a2f2f70697833642e637361696c2e6d69742e6564752f696d616765732f73706f746c696768745f70697833642e6a7067)

**3D Pose Estimation and 3D Model Retrieval for Objects in the Wild (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1803.11493.pdf)

[![Image 751](https://camo.githubusercontent.com/314f511247d96763be460af8e2f47d2d7be58ca6b59ef9388945b9cce884fb0c/68747470733a2f2f7777772e74756772617a2e61742f66696c6561646d696e2f757365725f75706c6f61642f496e737469747574652f4943472f446f63756d656e74732f7465616d5f6c6570657469742f696d616765732f677261626e65722f706f73655f72657472696576616c5f6f766572766965772e706e67)](https://camo.githubusercontent.com/314f511247d96763be460af8e2f47d2d7be58ca6b59ef9388945b9cce884fb0c/68747470733a2f2f7777772e74756772617a2e61742f66696c6561646d696e2f757365725f75706c6f61642f496e737469747574652f4943472f446f63756d656e74732f7465616d5f6c6570657469742f696d616765732f677261626e65722f706f73655f72657472696576616c5f6f766572766965772e706e67)

**Deep Object Pose Estimation for Semantic Robotic Grasping of Household Objects (2018)** [\[Paper\]](https://research.nvidia.com/publication/2018-09_Deep-Object-Pose)

[![Image 752](https://camo.githubusercontent.com/38044f3596501db9d9a02bf9f6ada1d2bcd5c2911e4bac476b3e590f0785f39c/68747470733a2f2f72657365617263682e6e76696469612e636f6d2f73697465732f64656661756c742f66696c65732f7075626c69636174696f6e732f666f7277656273697465315f302e706e67)](https://camo.githubusercontent.com/38044f3596501db9d9a02bf9f6ada1d2bcd5c2911e4bac476b3e590f0785f39c/68747470733a2f2f72657365617263682e6e76696469612e636f6d2f73697465732f64656661756c742f66696c65732f7075626c69636174696f6e732f666f7277656273697465315f302e706e67)

**MocapNET2: a real-time method that estimates the 3D human pose directly in the popular Bio Vision Hierarchy (BVH) format (2021)** [\[Paper\]](http://users.ics.forth.gr/~argyros/mypapers/2021_01_ICPR_Qammaz.pdf), [\[Code\]](https://github.com/FORTH-ModelBasedTracker/MocapNET)

[![Image 753](https://raw.githubusercontent.com/FORTH-ModelBasedTracker/MocapNET/master/doc/mnet2.png)](https://raw.githubusercontent.com/FORTH-ModelBasedTracker/MocapNET/master/doc/mnet2.png)

Single Object Classification
----------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#single-object-classification)

üëæ **3D ShapeNets: A Deep Representation for Volumetric Shapes (2015)** [\[Paper\]](http://3dshapenets.cs.princeton.edu/)

[![Image 754](https://camo.githubusercontent.com/627499d42fbee7c876a7835e903141715a745d069e820c779d24d031773a21be/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f336564323333383632383461353633396362336538626161656366343936636161373636653333352f312d466967757265312d312e706e67)](https://camo.githubusercontent.com/627499d42fbee7c876a7835e903141715a745d069e820c779d24d031773a21be/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f336564323333383632383461353633396362336538626161656366343936636161373636653333352f312d466967757265312d312e706e67)

üëæ **VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition (2015)** [\[Paper\]](http://www.dimatura.net/publications/voxnet_maturana_scherer_iros15.pdf) [\[Code\]](https://github.com/dimatura/voxnet)

[![Image 755](https://camo.githubusercontent.com/46dbae09842b4d8100ec6847a663824e299acc002c76fd2ae4689acf8b823374/687474703a2f2f7777772e64696d61747572612e6e65742f72657365617263682f766f786e65742f6361725f766f786e65745f736964652e706e67)](https://camo.githubusercontent.com/46dbae09842b4d8100ec6847a663824e299acc002c76fd2ae4689acf8b823374/687474703a2f2f7777772e64696d61747572612e6e65742f72657365617263682f766f786e65742f6361725f766f786e65745f736964652e706e67)

üì∑ **Multi-view Convolutional Neural Networks for 3D Shape Recognition (2015)** [\[Paper\]](http://vis-www.cs.umass.edu/mvcnn/)

[![Image 756](https://camo.githubusercontent.com/8b190e20d6d86d6aca1e7ecc767e26583e199fd650e8b7c256951cf885c78acc/687474703a2f2f7669732d7777772e63732e756d6173732e6564752f6d76636e6e2f696d616765732f6d76636e6e2e706e67)](https://camo.githubusercontent.com/8b190e20d6d86d6aca1e7ecc767e26583e199fd650e8b7c256951cf885c78acc/687474703a2f2f7669732d7777772e63732e756d6173732e6564752f6d76636e6e2f696d616765732f6d76636e6e2e706e67)

üì∑ **DeepPano: Deep Panoramic Representation for 3-D Shape Recognition (2015)** [\[Paper\]](http://mclab.eic.hust.edu.cn/UpLoadFiles/Papers/DeepPano_SPL2015.pdf)

[![Image 757](https://camo.githubusercontent.com/45f17ddfff26b8397bcf0c526adec71b29bc890ad2fa34b0e8c0bcc7521bedda/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f356131623564333139303564386365636537623738353130663531663364386262623036333036332f312d466967757265332d312e706e67)](https://camo.githubusercontent.com/45f17ddfff26b8397bcf0c526adec71b29bc890ad2fa34b0e8c0bcc7521bedda/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f356131623564333139303564386365636537623738353130663531663364386262623036333036332f312d466967757265332d312e706e67)

üëæüì∑ **FusionNet: 3D Object Classification Using Multiple Data Representations (2016)** [\[Paper\]](https://stanford.edu/~rezab/papers/fusionnet.pdf)

[![Image 758](https://camo.githubusercontent.com/7e58305d911fe291597fa45f5d9a61a5d492bcf7a041a457e16186f0cc6712a9/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f306161623866626365663166306131346635363533643137306361333666346535616165383031302f362d466967757265352d312e706e67)](https://camo.githubusercontent.com/7e58305d911fe291597fa45f5d9a61a5d492bcf7a041a457e16186f0cc6712a9/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f306161623866626365663166306131346635363533643137306361333666346535616165383031302f362d466967757265352d312e706e67)

üëæüì∑ **Volumetric and Multi-View CNNs for Object Classification on 3D Data (2016)** [\[Paper\]](https://arxiv.org/pdf/1604.03265.pdf) [\[Code\]](https://github.com/charlesq34/3dcnn.torch)

[![Image 759](https://camo.githubusercontent.com/c10daac5c7b76ab83cccb5133af7c051a9b8dc38df5bb865763df06750c3a47d/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f3364636e6e2f7465617365722e6a7067)](https://camo.githubusercontent.com/c10daac5c7b76ab83cccb5133af7c051a9b8dc38df5bb865763df06750c3a47d/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f3364636e6e2f7465617365722e6a7067)

üëæ **Generative and Discriminative Voxel Modeling with Convolutional Neural Networks (2016)** [\[Paper\]](https://arxiv.org/pdf/1608.04236.pdf) [\[Code\]](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling)

[![Image 760](https://camo.githubusercontent.com/d56145d936b2119cd0f6c746a9513a4ac248e1a6a7682ee1a5283bda00ae1ff6/687474703a2f2f6461766964737475747a2e64652f776f726470726573732f77702d636f6e74656e742f75706c6f6164732f323031372f30322f62726f636b5f7661652e706e67)](https://camo.githubusercontent.com/d56145d936b2119cd0f6c746a9513a4ac248e1a6a7682ee1a5283bda00ae1ff6/687474703a2f2f6461766964737475747a2e64652f776f726470726573732f77702d636f6e74656e742f75706c6f6164732f323031372f30322f62726f636b5f7661652e706e67)

üíé **Geometric deep learning on graphs and manifolds using mixture model CNNs (2016)** [\[Link\]](https://arxiv.org/pdf/1611.08402.pdf)

[![Image 761](https://camo.githubusercontent.com/e57ce0818ff7c73edf79dba3112a7a5bcf5a5212229e262270f29157785b4e22/68747470733a2f2f69322e77702e636f6d2f70726566657272656472657365617263682e6a702f77702d636f6e74656e742f75706c6f6164732f323031372f30382f6d6f6e65742e706e673f726573697a653d3538312532433135352673736c3d31)](https://camo.githubusercontent.com/e57ce0818ff7c73edf79dba3112a7a5bcf5a5212229e262270f29157785b4e22/68747470733a2f2f69322e77702e636f6d2f70726566657272656472657365617263682e6a702f77702d636f6e74656e742f75706c6f6164732f323031372f30382f6d6f6e65742e706e673f726573697a653d3538312532433135352673736c3d31)

üëæ **3D GAN: Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling (2016)** [\[Paper\]](https://arxiv.org/pdf/1610.07584.pdf) [\[Code\]](https://github.com/zck119/3dgan-release)

[![Image 762](https://camo.githubusercontent.com/2146e9b4587fe34533ea0c438d3dc21aa778a5e1a41d6b085af6bf0bf526d224/687474703a2f2f336467616e2e637361696c2e6d69742e6564752f696d616765732f6d6f64656c2e6a7067)](https://camo.githubusercontent.com/2146e9b4587fe34533ea0c438d3dc21aa778a5e1a41d6b085af6bf0bf526d224/687474703a2f2f336467616e2e637361696c2e6d69742e6564752f696d616765732f6d6f64656c2e6a7067)

üëæ **Generative and Discriminative Voxel Modeling with Convolutional Neural Networks (2017)** [\[Paper\]](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling)

[![Image 763](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling/raw/master/doc/GUI3.png)](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling/blob/master/doc/GUI3.png)

üëæ **FPNN: Field Probing Neural Networks for 3D Data (2016)** [\[Paper\]](http://yangyanli.github.io/FPNN/) [\[Code\]](https://github.com/yangyanli/FPNN)

[![Image 764](https://camo.githubusercontent.com/bad94ff7c8669a844709b0c6707144020a72c073df448ad65d19b135e14403fe/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f313563613761646363663563643464633330396364636161363332386634633432396561643333372f312d466967757265322d312e706e67)](https://camo.githubusercontent.com/bad94ff7c8669a844709b0c6707144020a72c073df448ad65d19b135e14403fe/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f313563613761646363663563643464633330396364636161363332386634633432396561643333372f312d466967757265322d312e706e67)

üëæ **OctNet: Learning Deep 3D Representations at High Resolutions (2017)** [\[Paper\]](https://arxiv.org/pdf/1611.05009.pdf) [\[Code\]](https://github.com/griegler/octnet)

[![Image 765](https://camo.githubusercontent.com/9047e5725a0b4a77b47a9e49eb60436d0e439d0bad9494191469659f8d49c9be/68747470733a2f2f69732e74756562696e67656e2e6d70672e64652f75706c6f6164732f7075626c69636174696f6e2f696d6167652f31383932312f696d6730332e706e67)](https://camo.githubusercontent.com/9047e5725a0b4a77b47a9e49eb60436d0e439d0bad9494191469659f8d49c9be/68747470733a2f2f69732e74756562696e67656e2e6d70672e64652f75706c6f6164732f7075626c69636174696f6e2f696d6167652f31383932312f696d6730332e706e67)

üëæ **O-CNN: Octree-based Convolutional Neural Networks for 3D Shape Analysis (2017)** [\[Paper\]](http://wang-ps.github.io/O-CNN) [\[Code\]](https://github.com/Microsoft/O-CNN)

[![Image 766](https://camo.githubusercontent.com/082b9d695bc987aaec2ca05f04c31750c777e492914e6b3d2d0096be0a445664/687474703a2f2f77616e672d70732e6769746875622e696f2f4f2d434e4e5f66696c65732f7465617365722e706e67)](https://camo.githubusercontent.com/082b9d695bc987aaec2ca05f04c31750c777e492914e6b3d2d0096be0a445664/687474703a2f2f77616e672d70732e6769746875622e696f2f4f2d434e4e5f66696c65732f7465617365722e706e67)

üëæ **Orientation-boosted voxel nets for 3D object recognition (2017)** [\[Paper\]](https://lmb.informatik.uni-freiburg.de/Publications/2017/SZB17a/) [\[Code\]](https://github.com/lmb-freiburg/orion)

[![Image 767](https://camo.githubusercontent.com/0a47b78a0cd002034289ef88a810dbcd7e4376f954fa71b6ba87c3789abe6431/68747470733a2f2f6c6d622e696e666f726d6174696b2e756e692d66726569627572672e64652f5075626c69636174696f6e732f323031372f535a423137612f7465617365725f772e706e67)](https://camo.githubusercontent.com/0a47b78a0cd002034289ef88a810dbcd7e4376f954fa71b6ba87c3789abe6431/68747470733a2f2f6c6d622e696e666f726d6174696b2e756e692d66726569627572672e64652f5075626c69636174696f6e732f323031372f535a423137612f7465617365725f772e706e67)

üé≤ **PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation (2017)** [\[Paper\]](http://stanford.edu/~rqi/pointnet/) [\[Code\]](https://github.com/charlesq34/pointnet)

[![Image 768](https://camo.githubusercontent.com/ad22ad9cf0ee38f2b10f389a8073c1416c3aaa840b39663b512899839e7ee558/68747470733a2f2f7765622e7374616e666f72642e6564752f7e7271692f7061706572732f706f696e746e65742e706e67)](https://camo.githubusercontent.com/ad22ad9cf0ee38f2b10f389a8073c1416c3aaa840b39663b512899839e7ee558/68747470733a2f2f7765622e7374616e666f72642e6564752f7e7271692f7061706572732f706f696e746e65742e706e67)

üé≤ **PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space (2017)** [\[Paper\]](https://arxiv.org/pdf/1706.02413.pdf) [\[Code\]](https://github.com/charlesq34/pointnet2)

[![Image 769](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PointNet%2B%2B-%20Deep%20Hierarchical%20Feature%20Learning%20on%20Point%20Sets%20in%20a%20Metric%20Space.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointNet%2B%2B-%20Deep%20Hierarchical%20Feature%20Learning%20on%20Point%20Sets%20in%20a%20Metric%20Space.png)

üì∑ **Feedback Networks (2017)** [\[Paper\]](http://feedbacknet.stanford.edu/) [\[Code\]](https://github.com/amir32002/feedback-networks)

[![Image 770](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Feedback%20Networks.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Feedback%20Networks.png)

üé≤ **Escape from Cells: Deep Kd-Networks for The Recognition of 3D Point Cloud Models (2017)** [\[Paper\]](http://www.arxiv.org/pdf/1704.01222.pdf)

[![Image 771](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Escape%20From%20Cells.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Escape%20From%20Cells.png)

üé≤ **Dynamic Graph CNN for Learning on Point Clouds (2018)** [\[Paper\]](https://arxiv.org/pdf/1801.07829.pdf)

[![Image 772](https://camo.githubusercontent.com/ca8bff6506d52a9a60f0ef969ca67a38ba4419e17131ee44c78ef42f77f7941e/68747470733a2f2f6c69757a69776569372e6769746875622e696f2f686f6d65706167655f66696c65732f64796e616d696367636e6e5f6c6f676f2e706e67)](https://camo.githubusercontent.com/ca8bff6506d52a9a60f0ef969ca67a38ba4419e17131ee44c78ef42f77f7941e/68747470733a2f2f6c69757a69776569372e6769746875622e696f2f686f6d65706167655f66696c65732f64796e616d696367636e6e5f6c6f676f2e706e67)

üé≤ **PointCNN (2018)** [\[Paper\]](https://yangyanli.github.io/PointCNN/)

[![Image 773](https://camo.githubusercontent.com/86101befcfb7886abe3ebb609632dccf1b4f82f857004c5fb648d0a2165ed8bc/687474703a2f2f79616e6779616e2e6c692f696d616765732f70617065722f706f696e74636e6e2e706e67)](https://camo.githubusercontent.com/86101befcfb7886abe3ebb609632dccf1b4f82f857004c5fb648d0a2165ed8bc/687474703a2f2f79616e6779616e2e6c692f696d616765732f70617065722f706f696e74636e6e2e706e67)

üé≤üì∑ **A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation (2018 CVPR)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Roveri_A_Network_Architecture_CVPR_2018_paper.pdf)

[![Image 774](https://camo.githubusercontent.com/fbfe5bfc9d41c7d8ddabba1a154574f6903722ac1d5d58034ee4a3caba82db72/68747470733a2f2f73332d75732d776573742d312e616d617a6f6e6177732e636f6d2f6469736e657972657365617263682f77702d636f6e74656e742f75706c6f6164732f32303138303631393131343733322f412d4e6574776f726b2d4172636869746563747572652d666f722d506f696e742d436c6f75642d436c617373696669636174696f6e2d7669612d4175746f6d617469632d44657074682d496d616765732d47656e65726174696f6e2d496d6167652d363030783331372e6a7067)](https://camo.githubusercontent.com/fbfe5bfc9d41c7d8ddabba1a154574f6903722ac1d5d58034ee4a3caba82db72/68747470733a2f2f73332d75732d776573742d312e616d617a6f6e6177732e636f6d2f6469736e657972657365617263682f77702d636f6e74656e742f75706c6f6164732f32303138303631393131343733322f412d4e6574776f726b2d4172636869746563747572652d666f722d506f696e742d436c6f75642d436c617373696669636174696f6e2d7669612d4175746f6d617469632d44657074682d496d616765732d47656e65726174696f6e2d496d6167652d363030783331372e6a7067)

üé≤üëæ **PointGrid: A Deep Network for 3D Shape Understanding (CVPR 2018)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf) [\[Code\]](https://github.com/trucleduc/PointGrid)

[![Image 775](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg)

üíé **MeshNet: Mesh Neural Network for 3D Shape Representation (AAAI 2019)** [\[Paper\]](https://arxiv.org/pdf/1811.11424.pdf) [\[Code\]](https://github.com/Yue-Group/MeshNet)

[![Image 776](https://camo.githubusercontent.com/41e08a2672a479ef72c3b6407aae557bea7d57ce75b736e56d533b2d29546927/687474703a2f2f7777772e67616f7975652e6f72672f656e5f7473696e676875612f72657372632f6d6573686e65742e6a7067)](https://camo.githubusercontent.com/41e08a2672a479ef72c3b6407aae557bea7d57ce75b736e56d533b2d29546927/687474703a2f2f7777772e67616f7975652e6f72672f656e5f7473696e676875612f72657372632f6d6573686e65742e6a7067)

üé≤ **SpiderCNN (2018)** [\[Paper\]](https://github.com/xyf513/SpiderCNN)[\[Code\]](https://github.com/xyf513/SpiderCNN)

[![Image 777](https://camo.githubusercontent.com/6327d6adf58f4569405ce357584eb8b2cde339ca01e2d30bf1785c988af27178/687474703a2f2f356230393838653539353232352e63646e2e736f687563732e636f6d2f696d616765732f32303138313130392f34356333623637306536376634336232383837393163363530666237666230622e6a706567)](https://camo.githubusercontent.com/6327d6adf58f4569405ce357584eb8b2cde339ca01e2d30bf1785c988af27178/687474703a2f2f356230393838653539353232352e63646e2e736f687563732e636f6d2f696d616765732f32303138313130392f34356333623637306536376634336232383837393163363530666237666230622e6a706567)

üé≤ **PointConv (2018)** [\[Paper\]](https://github.com/DylanWusee/pointconv/tree/master/imgs)[\[Code\]](https://github.com/DylanWusee/pointconv/tree/master/imgs)

[![Image 778](https://camo.githubusercontent.com/63fe0b1b1a34ffcd7614ce9d6d36f3dca3be76f134da16a0012ab7d059c74fcc/68747470733a2f2f70696373342e62616964752e636f6d2f666565642f386238326239303134613930663630333237326665323966383865663036316662323531656434392e6a7065673f746f6b656e3d623233653164626261656166313266666533643136386264393937613864363626733d3031333037443332384645303743303130433639433143453030303044304233)](https://camo.githubusercontent.com/63fe0b1b1a34ffcd7614ce9d6d36f3dca3be76f134da16a0012ab7d059c74fcc/68747470733a2f2f70696373342e62616964752e636f6d2f666565642f386238326239303134613930663630333237326665323966383865663036316662323531656434392e6a7065673f746f6b656e3d623233653164626261656166313266666533643136386264393937613864363626733d3031333037443332384645303743303130433639433143453030303044304233)

üíé **MeshCNN (SIGGRAPH 2019)** [\[Paper\]](https://bit.ly/meshcnn)[\[Code\]](https://github.com/ranahanocka/MeshCNN)

[![Image 779](https://github.com/ranahanocka/MeshCNN/raw/master/docs/imgs/alien.gif?raw=true)](https://github.com/ranahanocka/MeshCNN/blob/master/docs/imgs/alien.gif?raw=true)

üé≤ **SampleNet: Differentiable Point Cloud Sampling (CVPR 2020)** [\[Paper\]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lang_SampleNet_Differentiable_Point_Cloud_Sampling_CVPR_2020_paper.pdf) [\[Code\]](https://github.com/itailang/SampleNet)

[![Image 780](https://github.com/itailang/SampleNet/raw/master/doc/teaser.png)](https://github.com/itailang/SampleNet/blob/master/doc/teaser.png)

Multiple Objects Detection
--------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#multiple-objects-detection)

**Sliding Shapes for 3D Object Detection in Depth Images (2014)** [\[Paper\]](http://slidingshapes.cs.princeton.edu/)

[![Image 781](https://camo.githubusercontent.com/8e35dc19228aecb23529e5ebeebeac95861a4da900333b6b3442ca220833cf28/687474703a2f2f736c6964696e677368617065732e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)](https://camo.githubusercontent.com/8e35dc19228aecb23529e5ebeebeac95861a4da900333b6b3442ca220833cf28/687474703a2f2f736c6964696e677368617065732e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)

**Object Detection in 3D Scenes Using CNNs in Multi-view Images (2016)** [\[Paper\]](https://stanford.edu/class/ee367/Winter2016/Qi_Report.pdf)

[![Image 782](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Object%20Detection%20in%203D%20Scenes%20Using%20CNNs%20in%20Multi-view%20Images.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Object%20Detection%20in%203D%20Scenes%20Using%20CNNs%20in%20Multi-view%20Images.png)

**Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images (2016)** [\[Paper\]](http://dss.cs.princeton.edu/) [\[Code\]](https://github.com/shurans/DeepSlidingShape)

[![Image 783](https://camo.githubusercontent.com/aba76496b2d6d389a13fe90bd3c62c096e3ac681e3b77a26435a576ac3c37423/687474703a2f2f3364766973696f6e2e7072696e6365746f6e2e6564752f736c6964652f4453532e6a7067)](https://camo.githubusercontent.com/aba76496b2d6d389a13fe90bd3c62c096e3ac681e3b77a26435a576ac3c37423/687474703a2f2f3364766973696f6e2e7072696e6365746f6e2e6564752f736c6964652f4453532e6a7067)

**Three-Dimensional Object Detection and Layout Prediction using Clouds of Oriented Gradients (2016)** [\[CVPR '16 Paper\]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ren_Three-Dimensional_Object_Detection_CVPR_2016_paper.pdf) [\[CVPR '18 Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Ren_3D_Object_Detection_CVPR_2018_paper.pdf) [\[T-PAMI '19 Paper\]](https://arxiv.org/pdf/1906.04725)

[![Image 784](https://github.com/luvegood/3D-Machine-Learning/raw/master/imgs/Three-Dimensional%20Object%20Detection%20and%20Layout%20Prediction%20using%20Clouds%20of%20Oriented%20Gradients.png)](https://github.com/luvegood/3D-Machine-Learning/blob/master/imgs/Three-Dimensional%20Object%20Detection%20and%20Layout%20Prediction%20using%20Clouds%20of%20Oriented%20Gradients.png)

**DeepContext: Context-Encoding Neural Pathways for 3D Holistic Scene Understanding (2016)** [\[Paper\]](http://deepcontext.cs.princeton.edu/)

[![Image 785](https://camo.githubusercontent.com/d21a2b3492136e51105d248a5a0061c7ae50bf795debeb6d405d0cfd27c41bb7/687474703a2f2f64656570636f6e746578742e63732e7072696e6365746f6e2e6564752f7465617365722e706e67)](https://camo.githubusercontent.com/d21a2b3492136e51105d248a5a0061c7ae50bf795debeb6d405d0cfd27c41bb7/687474703a2f2f64656570636f6e746578742e63732e7072696e6365746f6e2e6564752f7465617365722e706e67)

**SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite (2017)** [\[Paper\]](http://rgbd.cs.princeton.edu/)

[![Image 786](https://camo.githubusercontent.com/cb4c8cea1a87fb04141c98586da402e8b4348898e58eae0de715ffc0ae32951f/687474703a2f2f726762642e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)](https://camo.githubusercontent.com/cb4c8cea1a87fb04141c98586da402e8b4348898e58eae0de715ffc0ae32951f/687474703a2f2f726762642e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)

**VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection (2017)** [\[Paper\]](https://arxiv.org/pdf/1711.06396.pdf)

[![Image 787](https://camo.githubusercontent.com/afcb399fb67d93873445f498da5a1b9442edad2ce2c6daaa58680156bd6561f8/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44504d744c68485855416351556a322e6a7067)](https://camo.githubusercontent.com/afcb399fb67d93873445f498da5a1b9442edad2ce2c6daaa58680156bd6561f8/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44504d744c68485855416351556a322e6a7067)

**Frustum PointNets for 3D Object Detection from RGB-D Data (CVPR2018)** [\[Paper\]](https://arxiv.org/pdf/1711.08488.pdf)

[![Image 788](https://camo.githubusercontent.com/23ae635b8f15a82cb45af4c27774e271907909a8b17f4dbc388d2f7b69415da2/687474703a2f2f7374616e666f72642e6564752f7e7271692f6672757374756d2d706f696e746e6574732f696d616765732f7465617365722e6a7067)](https://camo.githubusercontent.com/23ae635b8f15a82cb45af4c27774e271907909a8b17f4dbc388d2f7b69415da2/687474703a2f2f7374616e666f72642e6564752f7e7271692f6672757374756d2d706f696e746e6574732f696d616765732f7465617365722e6a7067)

**A^2-Net: Molecular Structure Estimation from Cryo-EM Density Volumes (AAAI2019)** [\[Paper\]](https://arxiv.org/abs/1901.00785)

[![Image 789](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/a-square-net-min.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/a-square-net-min.jpg)

**Stereo R-CNN based 3D Object Detection for Autonomous Driving (CVPR2019)** [\[Paper\]](https://arxiv.org/abs/1902.09738v1)

[![Image 790](https://camo.githubusercontent.com/eb6dbfde4de7994ba3cbd669a0dc53dac494195bc8b2a1e85443172930ac53ee/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f3531353333382f73797374656d5f6e65776e65772e706e67)](https://camo.githubusercontent.com/eb6dbfde4de7994ba3cbd669a0dc53dac494195bc8b2a1e85443172930ac53ee/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f3531353333382f73797374656d5f6e65776e65772e706e67)

**Deep Hough Voting for 3D Object Detection in Point Clouds (ICCV2019)** [\[Paper\]](https://arxiv.org/pdf/1904.09664.pdf) [\[code\]](https://github.com/facebookresearch/votenet)

[![Image 791](https://github.com/facebookresearch/votenet/raw/master/doc/teaser.jpg)](https://github.com/facebookresearch/votenet/blob/master/doc/teaser.jpg)

Scene/Object Semantic Segmentation
----------------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#sceneobject-semantic-segmentation)

**Learning 3D Mesh Segmentation and Labeling (2010)** [\[Paper\]](https://people.cs.umass.edu/~kalo/papers/LabelMeshes/LabelMeshes.pdf)

[![Image 792](https://camo.githubusercontent.com/c583f823023d1ceaaebd05e85f92b87b6ec2976343cb57c2d3cdfa6679ce9169/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f306266333930653261313466373462636338383338643566623163306334636336306539326562372f372d466967757265372d312e706e67)](https://camo.githubusercontent.com/c583f823023d1ceaaebd05e85f92b87b6ec2976343cb57c2d3cdfa6679ce9169/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f306266333930653261313466373462636338383338643566623163306334636336306539326562372f372d466967757265372d312e706e67)

**Unsupervised Co-Segmentation of a Set of Shapes via Descriptor-Space Spectral Clustering (2011)** [\[Paper\]](https://www.cs.sfu.ca/~haoz/pubs/sidi_siga11_coseg.pdf)

[![Image 793](https://camo.githubusercontent.com/c9025342495572946aadce638b8375f7b051e6472edcbccb60724fb2e8b3cd1f/687474703a2f2f70656f706c652e7363732e6361726c65746f6e2e63612f7e6f6c6976657276616e6b6169636b2f636f7365676d656e746174696f6e2f726573756c7473362e706e67)](https://camo.githubusercontent.com/c9025342495572946aadce638b8375f7b051e6472edcbccb60724fb2e8b3cd1f/687474703a2f2f70656f706c652e7363732e6361726c65746f6e2e63612f7e6f6c6976657276616e6b6169636b2f636f7365676d656e746174696f6e2f726573756c7473362e706e67)

**Single-View Reconstruction via Joint Analysis of Image and Shape Collections (2015)** [\[Paper\]](https://www.cs.utexas.edu/~huangqx/modeling_sig15.pdf) [\[Code\]](https://github.com/huangqx/image_shape_align)

[![Image 794](https://camo.githubusercontent.com/32ad706bdf1ca9f0e26e2bb028f87acb7acd285196b7f5ad63bb83556d4a18ec/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031352f30352f73696e676c652d766965772e706e67)](https://camo.githubusercontent.com/32ad706bdf1ca9f0e26e2bb028f87acb7acd285196b7f5ad63bb83556d4a18ec/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031352f30352f73696e676c652d766965772e706e67)

**3D Shape Segmentation with Projective Convolutional Networks (2017)** [\[Paper\]](http://people.cs.umass.edu/~kalo/papers/shapepfcn/) [\[Code\]](https://github.com/kalov/ShapePFCN)

[![Image 795](https://camo.githubusercontent.com/7906809cd2a0b233cc8fef7ec91e01db05cd63f5de2d171eab1b0f089eebd346/687474703a2f2f70656f706c652e63732e756d6173732e6564752f7e6b616c6f2f7061706572732f73686170657066636e2f7465617365722e6a7067)](https://camo.githubusercontent.com/7906809cd2a0b233cc8fef7ec91e01db05cd63f5de2d171eab1b0f089eebd346/687474703a2f2f70656f706c652e63732e756d6173732e6564752f7e6b616c6f2f7061706572732f73686170657066636e2f7465617365722e6a7067)

**Learning Hierarchical Shape Segmentation and Labeling from Online Repositories (2017)** [\[Paper\]](http://cs.stanford.edu/~ericyi/project_page/hier_seg/index.html)

[![Image 796](https://camo.githubusercontent.com/d2d5276f5971743bbd4f74fe37fe80cca767d417468d1b818273b9636d209653/687474703a2f2f63732e7374616e666f72642e6564752f7e6572696379692f70726f6a6563745f706167652f686965725f7365672f666967757265732f7465617365722e6a7067)](https://camo.githubusercontent.com/d2d5276f5971743bbd4f74fe37fe80cca767d417468d1b818273b9636d209653/687474703a2f2f63732e7374616e666f72642e6564752f7e6572696379692f70726f6a6563745f706167652f686965725f7365672f666967757265732f7465617365722e6a7067)

üëæ **ScanNet (2017)** [\[Paper\]](https://arxiv.org/pdf/1702.04405.pdf) [\[Code\]](https://github.com/scannet/scannet)

[![Image 797](https://camo.githubusercontent.com/f109f4435373c0c9508e48bcf20f19f37755f483f270562d1b31ccdf88b4f10c/687474703a2f2f7777772e7363616e2d6e65742e6f72672f696d672f766f78656c2d70726564696374696f6e732e6a7067)](https://camo.githubusercontent.com/f109f4435373c0c9508e48bcf20f19f37755f483f270562d1b31ccdf88b4f10c/687474703a2f2f7777772e7363616e2d6e65742e6f72672f696d672f766f78656c2d70726564696374696f6e732e6a7067)

üé≤ **PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation (2017)** [\[Paper\]](http://stanford.edu/~rqi/pointnet/) [\[Code\]](https://github.com/charlesq34/pointnet)

[![Image 798](https://camo.githubusercontent.com/ad22ad9cf0ee38f2b10f389a8073c1416c3aaa840b39663b512899839e7ee558/68747470733a2f2f7765622e7374616e666f72642e6564752f7e7271692f7061706572732f706f696e746e65742e706e67)](https://camo.githubusercontent.com/ad22ad9cf0ee38f2b10f389a8073c1416c3aaa840b39663b512899839e7ee558/68747470733a2f2f7765622e7374616e666f72642e6564752f7e7271692f7061706572732f706f696e746e65742e706e67)

üé≤ **PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space (2017)** [\[Paper\]](https://arxiv.org/pdf/1706.02413.pdf) [\[Code\]](https://github.com/charlesq34/pointnet2)

[![Image 799](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PointNet%2B%2B-%20Deep%20Hierarchical%20Feature%20Learning%20on%20Point%20Sets%20in%20a%20Metric%20Space.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointNet%2B%2B-%20Deep%20Hierarchical%20Feature%20Learning%20on%20Point%20Sets%20in%20a%20Metric%20Space.png)

üé≤ **3D Graph Neural Networks for RGBD Semantic Segmentation (2017)** [\[Paper\]](http://www.cs.toronto.edu/~rjliao/papers/iccv_2017_3DGNN.pdf)

[![Image 800](https://camo.githubusercontent.com/9752b07f6d9d67d88aa8192961cf12260409a4e11ad09ad6d18702e83eea5315/687474703a2f2f7777772e666f6e6f772e636f6d2f496d616765732f323031372d31302d31382f36363337322d32303137313031383131353830393734302d323132353232373235302e6a7067)](https://camo.githubusercontent.com/9752b07f6d9d67d88aa8192961cf12260409a4e11ad09ad6d18702e83eea5315/687474703a2f2f7777772e666f6e6f772e636f6d2f496d616765732f323031372d31302d31382f36363337322d32303137313031383131353830393734302d323132353232373235302e6a7067)

üé≤ **3DCNN-DQN-RNN: A Deep Reinforcement Learning Framework for Semantic Parsing of Large-scale 3D Point Clouds (2017)** [\[Paper\]](https://arxiv.org/pdf/1707.06783.pdf)

[![Image 801](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/3DCNN-DQN-RNN.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/3DCNN-DQN-RNN.png)

üé≤üëæ **Semantic Segmentation of Indoor Point Clouds using Convolutional Neural Networks (2017)** [\[Paper\]](https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-4-W4/101/2017/isprs-annals-IV-4-W4-101-2017.pdf)

[![Image 802](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Semantic%20Segmentation%20of%20Indoor%20Point%20Clouds%20using%20Convolutional%20Neural%20Networks.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Semantic%20Segmentation%20of%20Indoor%20Point%20Clouds%20using%20Convolutional%20Neural%20Networks.png)

üé≤üëæ **SEGCloud: Semantic Segmentation of 3D Point Clouds (2017)** [\[Paper\]](https://arxiv.org/pdf/1710.07563.pdf)

[![Image 803](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/SEGCloud.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SEGCloud.png)

üé≤üëæ **Large-Scale 3D Shape Reconstruction and Segmentation from ShapeNet Core55 (2017)** [\[Paper\]](https://arxiv.org/pdf/1710.06104.pdf)

[![Image 804](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Core55.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Core55.png)

üé≤ **Pointwise Convolutional Neural Networks (CVPR 2018)** [\[Link\]](http://pointwise.scenenn.net/)  
We propose pointwise convolution that performs on-the-fly voxelization for learning local features of a point cloud.

[![Image 805](https://camo.githubusercontent.com/4d3a3f81846591beff9de6770404dec7d1fb952a126d1ed19f585019f90d1e71/687474703a2f2f706f696e74776973652e7363656e656e6e2e6e65742f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/4d3a3f81846591beff9de6770404dec7d1fb952a126d1ed19f585019f90d1e71/687474703a2f2f706f696e74776973652e7363656e656e6e2e6e65742f696d616765732f7465617365722e706e67)

üé≤ **Dynamic Graph CNN for Learning on Point Clouds (2018)** [\[Paper\]](https://arxiv.org/pdf/1801.07829.pdf)

[![Image 806](https://camo.githubusercontent.com/ca8bff6506d52a9a60f0ef969ca67a38ba4419e17131ee44c78ef42f77f7941e/68747470733a2f2f6c69757a69776569372e6769746875622e696f2f686f6d65706167655f66696c65732f64796e616d696367636e6e5f6c6f676f2e706e67)](https://camo.githubusercontent.com/ca8bff6506d52a9a60f0ef969ca67a38ba4419e17131ee44c78ef42f77f7941e/68747470733a2f2f6c69757a69776569372e6769746875622e696f2f686f6d65706167655f66696c65732f64796e616d696367636e6e5f6c6f676f2e706e67)

üé≤ **PointCNN (2018)** [\[Paper\]](https://yangyanli.github.io/PointCNN/)

[![Image 807](https://camo.githubusercontent.com/86101befcfb7886abe3ebb609632dccf1b4f82f857004c5fb648d0a2165ed8bc/687474703a2f2f79616e6779616e2e6c692f696d616765732f70617065722f706f696e74636e6e2e706e67)](https://camo.githubusercontent.com/86101befcfb7886abe3ebb609632dccf1b4f82f857004c5fb648d0a2165ed8bc/687474703a2f2f79616e6779616e2e6c692f696d616765732f70617065722f706f696e74636e6e2e706e67)

üì∑üëæ **3DMV: Joint 3D-Multi-View Prediction for 3D Semantic Scene Segmentation (2018)** [\[Paper\]](https://arxiv.org/pdf/1803.10409.pdf)

[![Image 808](https://github.com/angeladai/3DMV/raw/master/images/teaser.jpg)](https://github.com/angeladai/3DMV/blob/master/images/teaser.jpg)

üëæ **ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans (2018)** [\[Paper\]](https://arxiv.org/pdf/1712.10215.pdf)

[![Image 809](https://github.com/angeladai/ScanComplete/raw/master/images/teaser_mesh.jpg)](https://github.com/angeladai/ScanComplete/blob/master/images/teaser_mesh.jpg)

üé≤üì∑ **SPLATNet: Sparse Lattice Networks for Point Cloud Processing (2018)** [\[Paper\]](https://arxiv.org/pdf/1802.08275.pdf)

[![Image 810](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/SPLATNet-%20Sparse%20Lattice%20Networks%20for%20Point%20Cloud%20Processing.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SPLATNet-%20Sparse%20Lattice%20Networks%20for%20Point%20Cloud%20Processing.jpeg)

üé≤üëæ **PointGrid: A Deep Network for 3D Shape Understanding (CVPR 2018)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf) [\[Code\]](https://github.com/trucleduc/PointGrid)

[![Image 811](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg)

üé≤ **PointConv (2018)** [\[Paper\]](https://github.com/DylanWusee/pointconv/tree/master/imgs)[\[Code\]](https://github.com/DylanWusee/pointconv/tree/master/imgs)

[![Image 812](https://camo.githubusercontent.com/63fe0b1b1a34ffcd7614ce9d6d36f3dca3be76f134da16a0012ab7d059c74fcc/68747470733a2f2f70696373342e62616964752e636f6d2f666565642f386238326239303134613930663630333237326665323966383865663036316662323531656434392e6a7065673f746f6b656e3d623233653164626261656166313266666533643136386264393937613864363626733d3031333037443332384645303743303130433639433143453030303044304233)](https://camo.githubusercontent.com/63fe0b1b1a34ffcd7614ce9d6d36f3dca3be76f134da16a0012ab7d059c74fcc/68747470733a2f2f70696373342e62616964752e636f6d2f666565642f386238326239303134613930663630333237326665323966383865663036316662323531656434392e6a7065673f746f6b656e3d623233653164626261656166313266666533643136386264393937613864363626733d3031333037443332384645303743303130433639433143453030303044304233)

üé≤ **SpiderCNN (2018)** [\[Paper\]](https://github.com/xyf513/SpiderCNN)[\[Code\]](https://github.com/xyf513/SpiderCNN)

[![Image 813](https://camo.githubusercontent.com/6327d6adf58f4569405ce357584eb8b2cde339ca01e2d30bf1785c988af27178/687474703a2f2f356230393838653539353232352e63646e2e736f687563732e636f6d2f696d616765732f32303138313130392f34356333623637306536376634336232383837393163363530666237666230622e6a706567)](https://camo.githubusercontent.com/6327d6adf58f4569405ce357584eb8b2cde339ca01e2d30bf1785c988af27178/687474703a2f2f356230393838653539353232352e63646e2e736f687563732e636f6d2f696d616765732f32303138313130392f34356333623637306536376634336232383837393163363530666237666230622e6a706567)

üëæ **3D-SIS: 3D Semantic Instance Segmentation of RGB-D Scans (CVPR 2019)** [\[Paper\]](https://arxiv.org/pdf/1812.07003.pdf)[\[Code\]](https://github.com/Sekunde/3D-SIS)

[![Image 814](https://camo.githubusercontent.com/83d652b0a115cebaf81253cf67aa0976b025f42a7a2954bf3d497b7c7cb27ce1/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f367369732f7465617365722e6a7067)](https://camo.githubusercontent.com/83d652b0a115cebaf81253cf67aa0976b025f42a7a2954bf3d497b7c7cb27ce1/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f367369732f7465617365722e6a7067)

üé≤ **Real-time Progressive 3D Semantic Segmentation for Indoor Scenes (WACV 2019)** [\[Link\]](https://pqhieu.github.io/research/proseg/)  
We propose an efficient yet robust technique for on-the-fly dense reconstruction and semantic segmentation of 3D indoor scenes. Our method is built atop an efficient super-voxel clustering method and a conditional random field with higher-order constraints from structural and object cues, enabling progressive dense semantic segmentation without any precomputation.

[![Image 815](https://camo.githubusercontent.com/c70807fdd5a470336988545b15a242a54b4d6dcf6c364057e125e63c766190d1/68747470733a2f2f7071686965752e6769746875622e696f2f6d656469612f696d616765732f7761637631392f7468756d626e61696c2e676966)](https://camo.githubusercontent.com/c70807fdd5a470336988545b15a242a54b4d6dcf6c364057e125e63c766190d1/68747470733a2f2f7071686965752e6769746875622e696f2f6d656469612f696d616765732f7761637631392f7468756d626e61696c2e676966)[](https://camo.githubusercontent.com/c70807fdd5a470336988545b15a242a54b4d6dcf6c364057e125e63c766190d1/68747470733a2f2f7071686965752e6769746875622e696f2f6d656469612f696d616765732f7761637631392f7468756d626e61696c2e676966)

üé≤ **JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds (CVPR 2019)** [\[Link\]](https://pqhieu.github.io/research/jsis3d/)  
We jointly address the problems of semantic and instance segmentation of 3D point clouds with a multi-task pointwise network that simultaneously performs two tasks: predicting the semantic classes of 3D points and embedding the points into high-dimensional vectors so that points of the same object instance are represented by similar embeddings. We then propose a multi-value conditional random field model to incorporate the semantic and instance labels and formulate the problem of semantic and instance segmentation as jointly optimising labels in the field model.

[![Image 816](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/jsis3d.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/jsis3d.png)

üé≤ **ShellNet: Efficient Point Cloud Convolutional Neural Networks using Concentric Shells Statistics (ICCV 2019)** [\[Link\]](https://hkust-vgd.github.io/shellnet/)  
We propose an efficient end-to-end permutation invariant convolution for point cloud deep learning. We use statistics from concentric spherical shells to define representative features and resolve the point order ambiguity, allowing traditional convolution to perform efficiently on such features.

[![Image 817](https://camo.githubusercontent.com/224dc2f216ea9c270abe4a24554147202989a17029191f859c72aaed9dc0da51/68747470733a2f2f686b7573742d7667642e6769746875622e696f2f7368656c6c6e65742f696d616765732f7368656c6c636f6e765f6e65772e706e67)](https://camo.githubusercontent.com/224dc2f216ea9c270abe4a24554147202989a17029191f859c72aaed9dc0da51/68747470733a2f2f686b7573742d7667642e6769746875622e696f2f7368656c6c6e65742f696d616765732f7368656c6c636f6e765f6e65772e706e67)

üé≤ **Rotation Invariant Convolutions for 3D Point Clouds Deep Learning (3DV 2019)** [\[Link\]](https://hkust-vgd.github.io/riconv/)  
We introduce a novel convolution operator for point clouds that achieves rotation invariance. Our core idea is to use low-level rotation invariant geometric features such as distances and angles to design a convolution operator for point cloud learning.

[![Image 818](https://camo.githubusercontent.com/91a8726d3a28877155f01f57a7d26cdf710b7659c1cad2e4fe3ed3471ed8d09b/68747470733a2f2f686b7573742d7667642e6769746875622e696f2f7269636f6e762f696d616765732f52494f5f63616d2e706e67)](https://camo.githubusercontent.com/91a8726d3a28877155f01f57a7d26cdf710b7659c1cad2e4fe3ed3471ed8d09b/68747470733a2f2f686b7573742d7667642e6769746875622e696f2f7269636f6e762f696d616765732f52494f5f63616d2e706e67)

3D Model Synthesis/Reconstruction
---------------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#3d-model-synthesisreconstruction)

### Parametric Morphable Model-based methods

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#parametric-morphable-model-based-methods)

**A Morphable Model For The Synthesis Of 3D Faces (1999)** [\[Paper\]](http://gravis.dmi.unibas.ch/publications/Sigg99/morphmod2.pdf)[\[Code\]](https://github.com/MichaelMure/3DMM)

[![Image 819](https://camo.githubusercontent.com/654db119c0ca50e300b7259809975c599c29628031a5cc154eb6c52d6cc9c8f7/687474703a2f2f6d626c6f677468756d62332e7068696e662e6e617665722e6e65742f4d6a41784e7a417a4d5464664d6a637a2f4d4441784e4467354e7a45334d7a55304f4449332e396c51696f4c78776f476d746f49565858397362564f7a68657a6f71674b4d4b69546f76426e6255464e30672e73584e357447344b6f68676b374f4a4574506e75782d6d76374f416f5856787843796f3353475a4d633659672e504e472e6174656c6965726a70726f2f3033313731375f303232325f4461746144726976656e53342e706e673f747970653d77343230)](https://camo.githubusercontent.com/654db119c0ca50e300b7259809975c599c29628031a5cc154eb6c52d6cc9c8f7/687474703a2f2f6d626c6f677468756d62332e7068696e662e6e617665722e6e65742f4d6a41784e7a417a4d5464664d6a637a2f4d4441784e4467354e7a45334d7a55304f4449332e396c51696f4c78776f476d746f49565858397362564f7a68657a6f71674b4d4b69546f76426e6255464e30672e73584e357447344b6f68676b374f4a4574506e75782d6d76374f416f5856787843796f3353475a4d633659672e504e472e6174656c6965726a70726f2f3033313731375f303232325f4461746144726976656e53342e706e673f747970653d77343230)

**FLAME: Faces Learned with an Articulated Model and Expressions (2017)** [\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/400/paper.pdf)[\[Code (Chumpy)\]](https://github.com/Rubikplayer/flame-fitting)[\[Code (TF)\]](https://github.com/TimoBolkart/TF_FLAME) [\[Code (PyTorch)\]](https://github.com/HavenFeng/photometric_optimization)  
[FLAME](http://flame.is.tue.mpg.de/) is a lightweight and expressive generic head model learned from over 33,000 of accurately aligned 3D scans. The model combines a linear identity shape space (trained from 3800 scans of human heads) with an articulated neck, jaw, and eyeballs, pose-dependent corrective blendshapes, and additional global expression blendshapes. The code demonstrates how to 1) reconstruct textured 3D faces from images, 2) fit the model to 3D landmarks or registered 3D meshes, or 3) generate 3D face templates for [speech-driven facial animation](https://github.com/TimoBolkart/voca).

[![Image 820](https://github.com/TimoBolkart/TF_FLAME/raw/master/gifs/model_variations.gif)](https://github.com/TimoBolkart/TF_FLAME/blob/master/gifs/model_variations.gif)

**The Space of Human Body Shapes: Reconstruction and Parameterization from Range Scans (2003)** [\[Paper\]](http://grail.cs.washington.edu/projects/digital-human/pub/allen03space-submit.pdf)

[![Image 821](https://camo.githubusercontent.com/26571512d9afaeb0038da15b6a92195d5c3f802952472e8dc47beb9a861a985b/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f343664333962306532316165393536653462636237613738396639326265343830643435656531322f372d46696775726531302d312e706e67)](https://camo.githubusercontent.com/26571512d9afaeb0038da15b6a92195d5c3f802952472e8dc47beb9a861a985b/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f343664333962306532316165393536653462636237613738396639326265343830643435656531322f372d46696775726531302d312e706e67)

**SMPL-X: Expressive Body Capture: 3D Hands, Face, and Body from a Single Image (2019)** [\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/497/SMPL-X.pdf)[\[Video\]](https://youtu.be/XyXIEmapWkw)[\[Code\]](https://github.com/vchoutas/smplify-x)

[![Image 822](https://github.com/vchoutas/smplify-x/raw/master/images/teaser_fig.png)](https://github.com/vchoutas/smplify-x/blob/master/images/teaser_fig.png)

**PIFuHD: Multi-Level Pixel Aligned Implicit Function for High-Resolution 3D Human Digitization (CVPR 2020)** [\[Paper\]](https://arxiv.org/pdf/2004.00452.pdf)[\[Video\]](https://www.youtube.com/watch?v=uEDqCxvF5yc&feature=youtu.be)[\[Code\]](https://github.com/facebookresearch/pifuhd)

[![Image 823](https://github.com/timzhang642/3D-Machine-Learning/raw/master)](https://github.com/timzhang642/3D-Machine-Learning/blob/master)

**ExPose: Monocular Expressive Body Regression through Body-Driven Attention (2020)** [\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/620/0983.pdf)[\[Video\]](https://youtu.be/lNTmHLYTiB8)[\[Code\]](https://github.com/vchoutas/expose)

[![Image 824](https://github.com/vchoutas/expose/raw/master/images/expose.png)](https://github.com/vchoutas/expose/blob/master/images/expose.png)

**Category-Specific Object Reconstruction from a Single Image (2014)** [\[Paper\]](https://people.eecs.berkeley.edu/~akar/categoryshapes.pdf)

[![Image 825](https://camo.githubusercontent.com/d43e92f1f3be7735241420157452596f255cb52883e8d3c118d950afeb82df32/687474703a2f2f70656f706c652e656563732e6265726b656c65792e6564752f7e616b61722f63617465676f72795368617065732f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/d43e92f1f3be7735241420157452596f255cb52883e8d3c118d950afeb82df32/687474703a2f2f70656f706c652e656563732e6265726b656c65792e6564752f7e616b61722f63617465676f72795368617065732f696d616765732f7465617365722e706e67)

üé≤ **DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image (2017)** [\[Paper\]](http://ai.stanford.edu/~haosu/papers/SI2PC_arxiv_submit.pdf)

[![Image 826](https://camo.githubusercontent.com/6de640b65c10bcc029eeef20fa2e262bc518a45a788687130ad81983fb7c954b/68747470733a2f2f636872697363686f792e6769746875622e696f2f696d616765732f7075626c69636174696f6e2f6465666f726d6e65742f6d6f64656c2e706e67)](https://camo.githubusercontent.com/6de640b65c10bcc029eeef20fa2e262bc518a45a788687130ad81983fb7c954b/68747470733a2f2f636872697363686f792e6769746875622e696f2f696d616765732f7075626c69636174696f6e2f6465666f726d6e65742f6d6f64656c2e706e67)

üíé **Mesh-based Autoencoders for Localized Deformation Component Analysis (2017)** [\[Paper\]](https://arxiv.org/pdf/1709.04304.pdf)

[![Image 827](https://camo.githubusercontent.com/5f0133a9e3ef1a679bf70914ccc9a4c8b0f0bedb9f0de4d609b32aca24a1fdef/687474703a2f2f717974616e2e636f6d2f696d672f706f696e745f636f6e762e6a7067)](https://camo.githubusercontent.com/5f0133a9e3ef1a679bf70914ccc9a4c8b0f0bedb9f0de4d609b32aca24a1fdef/687474703a2f2f717974616e2e636f6d2f696d672f706f696e745f636f6e762e6a7067)

üíé **Exploring Generative 3D Shapes Using Autoencoder Networks (Autodesk 2017)** [\[Paper\]](https://www.autodeskresearch.com/publications/exploring_generative_3d_shapes)

[![Image 828](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Exploring%20Generative%203D%20Shapes%20Using%20Autoencoder%20Networks.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Exploring%20Generative%203D%20Shapes%20Using%20Autoencoder%20Networks.jpeg)

üíé **Using Locally Corresponding CAD Models for Dense 3D Reconstructions from a Single Image (2017)** [\[Paper\]](http://ci2cv.net/media/papers/chenkong_cvpr_2017.pdf)

[![Image 829](https://camo.githubusercontent.com/7f7b078fda145dc3f04d76ae0f31aa12f1187cee4192c28c30b729666b5810ab/68747470733a2f2f6368656e687375616e6c696e2e6269746275636b65742e696f2f696d616765732f72702f7230322e706e67)](https://camo.githubusercontent.com/7f7b078fda145dc3f04d76ae0f31aa12f1187cee4192c28c30b729666b5810ab/68747470733a2f2f6368656e687375616e6c696e2e6269746275636b65742e696f2f696d616765732f72702f7230322e706e67)

üíé **Compact Model Representation for 3D Reconstruction (2017)** [\[Paper\]](https://jhonykaesemodel.com/publication/3dv2017/)

[![Image 830](https://camo.githubusercontent.com/64a19bdca76bff20c61b07e1a089016bfbae486e802af48223526fb54efed38d/68747470733a2f2f6a686f6e796b616573656d6f64656c2e636f6d2f696d672f686561646572732f6f766572766965772e706e67)](https://camo.githubusercontent.com/64a19bdca76bff20c61b07e1a089016bfbae486e802af48223526fb54efed38d/68747470733a2f2f6a686f6e796b616573656d6f64656c2e636f6d2f696d672f686561646572732f6f766572766965772e706e67)

üíé **Image2Mesh: A Learning Framework for Single Image 3D Reconstruction (2017)** [\[Paper\]](https://arxiv.org/pdf/1711.10669.pdf)

[![Image 831](https://camo.githubusercontent.com/1351dc9783490e7f704683e3a25204c683be0d814523ecc331d7fe2ad8115479/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44573556686a70573441414553484f2e6a7067)](https://camo.githubusercontent.com/1351dc9783490e7f704683e3a25204c683be0d814523ecc331d7fe2ad8115479/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44573556686a70573441414553484f2e6a7067)

üíé **Learning free-form deformations for 3D object reconstruction (2018)** [\[Paper\]](https://jhonykaesemodel.com/publication/learning_ffd/)

[![Image 832](https://camo.githubusercontent.com/c79d36b70cdf39587f4a382e7bc38aa1a2145c107f7ece46f6ecb3da825c59cc/68747470733a2f2f6a686f6e796b616573656d6f64656c2e636f6d2f6c6561726e696e675f6666645f6f766572766965772e706e67)](https://camo.githubusercontent.com/c79d36b70cdf39587f4a382e7bc38aa1a2145c107f7ece46f6ecb3da825c59cc/68747470733a2f2f6a686f6e796b616573656d6f64656c2e636f6d2f6c6561726e696e675f6666645f6f766572766965772e706e67)

üíé **Variational Autoencoders for Deforming 3D Mesh Models(2018 CVPR)** [\[Paper\]](http://qytan.com/publication/vae/)

[![Image 833](https://camo.githubusercontent.com/80423792816d977508123d3ba4afeb84997bf6ddf0eaf1d0a74dfdfecce0445a/687474703a2f2f68756d616e6d6f74696f6e2e6963742e61632e636e2f7061706572732f3230313850355f566172696174696f6e616c4175746f656e636f646572732f546561736572496d6167652e6a7067)](https://camo.githubusercontent.com/80423792816d977508123d3ba4afeb84997bf6ddf0eaf1d0a74dfdfecce0445a/687474703a2f2f68756d616e6d6f74696f6e2e6963742e61632e636e2f7061706572732f3230313850355f566172696174696f6e616c4175746f656e636f646572732f546561736572496d6167652e6a7067)

üíé **Lions and Tigers and Bears: Capturing Non-Rigid, 3D, Articulated Shape from Images (2018 CVPR)** [\[Paper\]](http://files.is.tue.mpg.de/black/papers/zuffiCVPR2018.pdf)

[![Image 834](https://camo.githubusercontent.com/994b81495238623a3b20f1f054dc0c588bae31a21b134b01603ad86cf3dc873a/68747470733a2f2f336331373033666538642e736974652e696e7465726e617063646e2e6e65742f6e65776d616e2f6766782f6e6577732f68697265732f323031382f7265616c69737469636176612e6a7067)](https://camo.githubusercontent.com/994b81495238623a3b20f1f054dc0c588bae31a21b134b01603ad86cf3dc873a/68747470733a2f2f336331373033666538642e736974652e696e7465726e617063646e2e6e65742f6e65776d616e2f6766782f6e6577732f68697265732f323031382f7265616c69737469636176612e6a7067)

### Part-based Template Learning methods

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#part-based-template-learning-methods)

**Modeling by Example (2004)** [\[Paper\]](http://www.cs.princeton.edu/~funk/sig04a.pdf)

[![Image 835](https://camo.githubusercontent.com/b44b8e8fe4d165389f26f1849f511e2886a00b2bfeefada7b847bbbb9034ce7c/687474703a2f2f6766782e63732e7072696e6365746f6e2e6564752f707562732f46756e6b686f757365725f323030345f4d42452f63686169722e6a7067)](https://camo.githubusercontent.com/b44b8e8fe4d165389f26f1849f511e2886a00b2bfeefada7b847bbbb9034ce7c/687474703a2f2f6766782e63732e7072696e6365746f6e2e6564752f707562732f46756e6b686f757365725f323030345f4d42452f63686169722e6a7067)

**Model Composition from Interchangeable Components (2007)** [\[Paper\]](http://www.cs.princeton.edu/courses/archive/spring11/cos598A/pdfs/Kraevoy07.pdf)

[![Image 836](https://camo.githubusercontent.com/f81ce0a64c87313e073f666d7d76906f34d03d933b86c039bfee2ddedce4e2d7/687474703a2f2f7777772e63732e7562632e63612f6c6162732f696d616765722f74722f323030372f566c61645f53687566666c65722f7465617365722e6a7067)](https://camo.githubusercontent.com/f81ce0a64c87313e073f666d7d76906f34d03d933b86c039bfee2ddedce4e2d7/687474703a2f2f7777772e63732e7562632e63612f6c6162732f696d616765722f74722f323030372f566c61645f53687566666c65722f7465617365722e6a7067)

**Data-Driven Suggestions for Creativity Support in 3D Modeling (2010)** [\[Paper\]](http://vladlen.info/publications/data-driven-suggestions-for-creativity-support-in-3d-modeling/)

[![Image 837](https://camo.githubusercontent.com/f9fb16580c235114182c17a22b4716ca086d7029036782d3867139b4d64c8380/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031312f31322f637265617469766974792e706e67)](https://camo.githubusercontent.com/f9fb16580c235114182c17a22b4716ca086d7029036782d3867139b4d64c8380/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031312f31322f637265617469766974792e706e67)

**Photo-Inspired Model-Driven 3D Object Modeling (2011)** [\[Paper\]](http://kevinkaixu.net/projects/photo-inspired.html)

[![Image 838](https://camo.githubusercontent.com/53cd22fa7ef5147a44ef7261011e527e7f718f3bc60c6e2df0d3c226d1817f83/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f70686f746f2d696e7370697265642f6f766572766965772e504e47)](https://camo.githubusercontent.com/53cd22fa7ef5147a44ef7261011e527e7f718f3bc60c6e2df0d3c226d1817f83/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f70686f746f2d696e7370697265642f6f766572766965772e504e47)

**Probabilistic Reasoning for Assembly-Based 3D Modeling (2011)** [\[Paper\]](https://people.cs.umass.edu/~kalo/papers/assembly/ProbReasoningShapeModeling.pdf)

[![Image 839](https://camo.githubusercontent.com/df23185c480a445a842e45cf338111d3c32a8062eef0d0a4c70c03c4c0bafba6/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031312f31322f686967686c69676874392e706e67)](https://camo.githubusercontent.com/df23185c480a445a842e45cf338111d3c32a8062eef0d0a4c70c03c4c0bafba6/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031312f31322f686967686c69676874392e706e67)

**A Probabilistic Model for Component-Based Shape Synthesis (2012)** [\[Paper\]](https://people.cs.umass.edu/~kalo/papers/ShapeSynthesis/ShapeSynthesis.pdf)

[![Image 840](https://github.com/timzhang642/test1/raw/master/imgs/A%20Probabilistic%20Model%20for%20Component-Based%20Shape%20Synthesis.png)](https://github.com/timzhang642/test1/blob/master/imgs/A%20Probabilistic%20Model%20for%20Component-Based%20Shape%20Synthesis.png)

**Structure Recovery by Part Assembly (2012)** [\[Paper\]](http://cg.cs.tsinghua.edu.cn/StructureRecovery/)

[![Image 841](https://github.com/timzhang642/test1/raw/master/imgs/Structure%20Recovery%20by%20Part%20Assembly.png)](https://github.com/timzhang642/test1/blob/master/imgs/Structure%20Recovery%20by%20Part%20Assembly.png)

**Fit and Diverse: Set Evolution for Inspiring 3D Shape Galleries (2012)** [\[Paper\]](http://kevinkaixu.net/projects/civil.html)

[![Image 842](https://camo.githubusercontent.com/0ecf71bb7d8145e31db0b8fc9b094c4f1a11e6909ae4b4136d7aecc75047bfa7/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f636976696c2f7465617365722e706e67)](https://camo.githubusercontent.com/0ecf71bb7d8145e31db0b8fc9b094c4f1a11e6909ae4b4136d7aecc75047bfa7/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f636976696c2f7465617365722e706e67)

**AttribIt: Content Creation with Semantic Attributes (2013)** [\[Paper\]](https://people.cs.umass.edu/~kalo/papers/attribit/AttribIt.pdf)

[![Image 843](https://camo.githubusercontent.com/508c9a1369621d8c62f726f03475844adb5067aecc6abbaa5d1a193d47ee1375/687474703a2f2f6766782e63732e7072696e6365746f6e2e6564752f6766782f707562732f4368617564687572695f323031335f4143432f7465617365722e6a7067)](https://camo.githubusercontent.com/508c9a1369621d8c62f726f03475844adb5067aecc6abbaa5d1a193d47ee1375/687474703a2f2f6766782e63732e7072696e6365746f6e2e6564752f6766782f707562732f4368617564687572695f323031335f4143432f7465617365722e6a7067)

**Learning Part-based Templates from Large Collections of 3D Shapes (2013)** [\[Paper\]](http://shape.cs.princeton.edu/vkcorrs/papers/13_SIGGRAPH_CorrsTmplt.pdf)

[![Image 844](https://github.com/timzhang642/test1/raw/master/imgs/Learning%20Part-based%20Templates%20from%20Large%20Collections%20of%203D%20Shapes.png)](https://github.com/timzhang642/test1/blob/master/imgs/Learning%20Part-based%20Templates%20from%20Large%20Collections%20of%203D%20Shapes.png)

**Topology-Varying 3D Shape Creation via Structural Blending (2014)** [\[Paper\]](http://gruvi.cs.sfu.ca/project/topo/)

[![Image 845](https://camo.githubusercontent.com/e219a8a1028c1efb4213a9333ca295ce1bc35ca4ae38f84176f4dafa27fac030/68747470733a2f2f692e7974696d672e636f6d2f76692f5863347166377636612d772f6d617872657364656661756c742e6a7067)](https://camo.githubusercontent.com/e219a8a1028c1efb4213a9333ca295ce1bc35ca4ae38f84176f4dafa27fac030/68747470733a2f2f692e7974696d672e636f6d2f76692f5863347166377636612d772f6d617872657364656661756c742e6a7067)

**Estimating Image Depth using Shape Collections (2014)** [\[Paper\]](http://vecg.cs.ucl.ac.uk/Projects/SmartGeometry/image_shape_net/imageShapeNet_sigg14.html)

[![Image 846](https://camo.githubusercontent.com/3251402b57c8aa6606cadf06b193a6c0071135d2fdb1b2af50e04446ff68a087/687474703a2f2f766563672e63732e75636c2e61632e756b2f50726f6a656374732f536d61727447656f6d657472792f696d6167655f73686170655f6e65742f70617065725f646f63732f706970656c696e652e6a7067)](https://camo.githubusercontent.com/3251402b57c8aa6606cadf06b193a6c0071135d2fdb1b2af50e04446ff68a087/687474703a2f2f766563672e63732e75636c2e61632e756b2f50726f6a656374732f536d61727447656f6d657472792f696d6167655f73686170655f6e65742f70617065725f646f63732f706970656c696e652e6a7067)

**Single-View Reconstruction via Joint Analysis of Image and Shape Collections (2015)** [\[Paper\]](https://www.cs.utexas.edu/~huangqx/modeling_sig15.pdf)

[![Image 847](https://camo.githubusercontent.com/32ad706bdf1ca9f0e26e2bb028f87acb7acd285196b7f5ad63bb83556d4a18ec/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031352f30352f73696e676c652d766965772e706e67)](https://camo.githubusercontent.com/32ad706bdf1ca9f0e26e2bb028f87acb7acd285196b7f5ad63bb83556d4a18ec/687474703a2f2f766c61646c656e2e696e666f2f77702d636f6e74656e742f75706c6f6164732f323031352f30352f73696e676c652d766965772e706e67)

**Interchangeable Components for Hands-On Assembly Based Modeling (2016)** [\[Paper\]](http://www.cs.umb.edu/~craigyu/papers/handson_low_res.pdf)

[![Image 848](https://github.com/timzhang642/test1/raw/master/imgs/Interchangeable%20Components%20for%20Hands-On%20Assembly%20Based%20Modeling.png)](https://github.com/timzhang642/test1/blob/master/imgs/Interchangeable%20Components%20for%20Hands-On%20Assembly%20Based%20Modeling.png)

**Shape Completion from a Single RGBD Image (2016)** [\[Paper\]](http://www.kunzhou.net/2016/shapecompletion-tvcg16.pdf)

[![Image 849](https://camo.githubusercontent.com/f1ef3084809ee4835785c9e629d502222d7587ca6e63c93b4b56e9280c7b0bd1/687474703a2f2f7469616e6a69617368616f2e636f6d2f496d616765732f323031352f636f6d706c6574696f6e2e6a7067)](https://camo.githubusercontent.com/f1ef3084809ee4835785c9e629d502222d7587ca6e63c93b4b56e9280c7b0bd1/687474703a2f2f7469616e6a69617368616f2e636f6d2f496d616765732f323031352f636f6d706c6574696f6e2e6a7067)

### Deep Learning Methods

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#deep-learning-methods)

üì∑ **Learning to Generate Chairs, Tables and Cars with Convolutional Networks (2014)** [\[Paper\]](https://arxiv.org/pdf/1411.5928.pdf)

[![Image 850](https://camo.githubusercontent.com/c200afb4e7b1ed83c51660b31c8dbb16990bf29994092e9bbbc453281238fd06/68747470733a2f2f7a6f372e6769746875622e696f2f696d672f323031362d30392d32352d67656e65726174696e672d66616365732f6368616972732d6d6f64656c2e706e67)](https://camo.githubusercontent.com/c200afb4e7b1ed83c51660b31c8dbb16990bf29994092e9bbbc453281238fd06/68747470733a2f2f7a6f372e6769746875622e696f2f696d672f323031362d30392d32352d67656e65726174696e672d66616365732f6368616972732d6d6f64656c2e706e67)

üì∑ **Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis (2015, NIPS)** [\[Paper\]](https://papers.nips.cc/paper/5639-weakly-supervised-disentangling-with-recurrent-transformations-for-3d-view-synthesis.pdf)

[![Image 851](https://github.com/jimeiyang/deepRotator/raw/master/demo_img.png)](https://github.com/jimeiyang/deepRotator/blob/master/demo_img.png)

üé≤ **Analysis and synthesis of 3D shape families via deep-learned generative models of surfaces (2015)** [\[Paper\]](https://people.cs.umass.edu/~hbhuang/publications/bsm/)

[![Image 852](https://camo.githubusercontent.com/7f6ada9bd9ad840c589bb909814d3e36dc818035a05fa3f602222dee00456fbc/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e68626875616e672f7075626c69636174696f6e732f62736d2f62736d5f7465617365722e6a7067)](https://camo.githubusercontent.com/7f6ada9bd9ad840c589bb909814d3e36dc818035a05fa3f602222dee00456fbc/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e68626875616e672f7075626c69636174696f6e732f62736d2f62736d5f7465617365722e6a7067)

üì∑ **Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis (2015)** [\[Paper\]](https://papers.nips.cc/paper/5639-weakly-supervised-disentangling-with-recurrent-transformations-for-3d-view-synthesis.pdf) [\[Code\]](https://github.com/jimeiyang/deepRotator)

[![Image 853](https://camo.githubusercontent.com/9718d2a99f6307cd25ed9798400cb99d7a039c01986ea63bf627ab6858229c8e/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f303432393933633436323934613534323934366339633137303662376232326465623164376334332f322d466967757265312d312e706e67)](https://camo.githubusercontent.com/9718d2a99f6307cd25ed9798400cb99d7a039c01986ea63bf627ab6858229c8e/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f303432393933633436323934613534323934366339633137303662376232326465623164376334332f322d466967757265312d312e706e67)

üì∑ **Multi-view 3D Models from Single Images with a Convolutional Network (2016)** [\[Paper\]](https://arxiv.org/pdf/1511.06702.pdf) [\[Code\]](https://github.com/lmb-freiburg/mv3d)

[![Image 854](https://camo.githubusercontent.com/dcdce58c11b4c79f9c9aa7943324ed536ace37b31021cef7ce92b66dc086d850/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f336437636135616433346632336135666162313665373365323837643161303539646337656639612f342d466967757265322d312e706e67)](https://camo.githubusercontent.com/dcdce58c11b4c79f9c9aa7943324ed536ace37b31021cef7ce92b66dc086d850/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f336437636135616433346632336135666162313665373365323837643161303539646337656639612f342d466967757265322d312e706e67)

üì∑ **View Synthesis by Appearance Flow (2016)** [\[Paper\]](https://people.eecs.berkeley.edu/~tinghuiz/papers/eccv16_appflow.pdf) [\[Code\]](https://github.com/tinghuiz/appearance-flow)

[![Image 855](https://camo.githubusercontent.com/d7559d017692c623739103e81a1c49e44e504dfdb4611f725ff4dc0c45cfd9fd/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f313232383035303664633862356333636132646232396663336265363934643961386265663438632f362d466967757265322d312e706e67)](https://camo.githubusercontent.com/d7559d017692c623739103e81a1c49e44e504dfdb4611f725ff4dc0c45cfd9fd/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f313232383035303664633862356333636132646232396663336265363934643961386265663438632f362d466967757265322d312e706e67)

üëæ **Voxlets: Structured Prediction of Unobserved Voxels From a Single Depth Image (2016)** [\[Paper\]](http://visual.cs.ucl.ac.uk/pubs/depthPrediction/http://visual.cs.ucl.ac.uk/pubs/depthPrediction/) [\[Code\]](https://github.com/mdfirman/voxlets)

[![Image 856](https://camo.githubusercontent.com/bdf99df9881595023b7b0062290ae7407a6233547b7070bf2530c94679400e10/68747470733a2f2f692e7974696d672e636f6d2f76692f317779347932475744356f2f6d617872657364656661756c742e6a7067)](https://camo.githubusercontent.com/bdf99df9881595023b7b0062290ae7407a6233547b7070bf2530c94679400e10/68747470733a2f2f692e7974696d672e636f6d2f76692f317779347932475744356f2f6d617872657364656661756c742e6a7067)

üëæ **3D-R2N2: 3D Recurrent Reconstruction Neural Network (2016)** [\[Paper\]](http://cvgl.stanford.edu/3d-r2n2/) [\[Code\]](https://github.com/chrischoy/3D-R2N2)

[![Image 857](https://camo.githubusercontent.com/4a4eb2592537fea844ade9ecd4aaae9033b236f7b9b8884b5e25050b21dcf09f/687474703a2f2f33642d72326e322e7374616e666f72642e6564752f696d67732f6f766572766965772e706e67)](https://camo.githubusercontent.com/4a4eb2592537fea844ade9ecd4aaae9033b236f7b9b8884b5e25050b21dcf09f/687474703a2f2f33642d72326e322e7374616e666f72642e6564752f696d67732f6f766572766965772e706e67)

üëæ **Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision (2016)** [\[Paper\]](https://eng.ucmerced.edu/people/jyang44/papers/nips16_ptn.pdf)

[![Image 858](https://camo.githubusercontent.com/c033f1a2c6145c6be09511218c8abd01ec4df970a3b0d77b3fa8b57ce26e74fd/68747470733a2f2f73697465732e676f6f676c652e636f6d2f736974652f736b7977616c6b65727978632f5f2f727372632f313438313130343539363233382f70657273706563746976655f7472616e73666f726d65725f6e6574732f6e6574776f726b5f617263682e706e67)](https://camo.githubusercontent.com/c033f1a2c6145c6be09511218c8abd01ec4df970a3b0d77b3fa8b57ce26e74fd/68747470733a2f2f73697465732e676f6f676c652e636f6d2f736974652f736b7977616c6b65727978632f5f2f727372632f313438313130343539363233382f70657273706563746976655f7472616e73666f726d65725f6e6574732f6e6574776f726b5f617263682e706e67)

üëæ **TL-Embedding Network: Learning a Predictable and Generative Vector Representation for Objects (2016)** [\[Paper\]](https://arxiv.org/pdf/1603.08637.pdf)

[![Image 859](https://camo.githubusercontent.com/ab2888f2ca6cbb413087a039237b947d8afb2255862724c68892be30384d59cd/68747470733a2f2f726f686974676972646861722e6769746875622e696f2f47656e657261746976655072656469637461626c65566f78656c732f6173736574732f7765627465617365722e6a7067)](https://camo.githubusercontent.com/ab2888f2ca6cbb413087a039237b947d8afb2255862724c68892be30384d59cd/68747470733a2f2f726f686974676972646861722e6769746875622e696f2f47656e657261746976655072656469637461626c65566f78656c732f6173736574732f7765627465617365722e6a7067)

üëæ **3D GAN: Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling (2016)** [\[Paper\]](https://arxiv.org/pdf/1610.07584.pdf)

[![Image 860](https://camo.githubusercontent.com/2146e9b4587fe34533ea0c438d3dc21aa778a5e1a41d6b085af6bf0bf526d224/687474703a2f2f336467616e2e637361696c2e6d69742e6564752f696d616765732f6d6f64656c2e6a7067)](https://camo.githubusercontent.com/2146e9b4587fe34533ea0c438d3dc21aa778a5e1a41d6b085af6bf0bf526d224/687474703a2f2f336467616e2e637361696c2e6d69742e6564752f696d616765732f6d6f64656c2e6a7067)

üëæ **3D Shape Induction from 2D Views of Multiple Objects (2016)** [\[Paper\]](https://arxiv.org/pdf/1612.05872.pdf)

[![Image 861](https://camo.githubusercontent.com/b3750a63d05181ddb9d1bbf306a5c7a5d2649f1bd107ff70570ec81d7375fddf/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f653738353732656565663862393637646563343230303133633635613636383434383763313362322f322d466967757265322d312e706e67)](https://camo.githubusercontent.com/b3750a63d05181ddb9d1bbf306a5c7a5d2649f1bd107ff70570ec81d7375fddf/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f653738353732656565663862393637646563343230303133633635613636383434383763313362322f322d466967757265322d312e706e67)

üì∑ **Unsupervised Learning of 3D Structure from Images (2016)** [\[Paper\]](https://arxiv.org/pdf/1607.00662.pdf)

[![Image 862](https://camo.githubusercontent.com/57d41c80d9f98ab1dbd268f684ac2e42e289a4d0d97d5688f2fdddae26d570d1/68747470733a2f2f61647269616e636f6c7965722e66696c65732e776f726470726573732e636f6d2f323031362f31322f756e737570657276697365642d33642d6669672d31302e6a7065673f773d363030)](https://camo.githubusercontent.com/57d41c80d9f98ab1dbd268f684ac2e42e289a4d0d97d5688f2fdddae26d570d1/68747470733a2f2f61647269616e636f6c7965722e66696c65732e776f726470726573732e636f6d2f323031362f31322f756e737570657276697365642d33642d6669672d31302e6a7065673f773d363030)

üëæ **Generative and Discriminative Voxel Modeling with Convolutional Neural Networks (2016)** [\[Paper\]](https://arxiv.org/pdf/1608.04236.pdf) [\[Code\]](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling)

[![Image 863](https://camo.githubusercontent.com/d56145d936b2119cd0f6c746a9513a4ac248e1a6a7682ee1a5283bda00ae1ff6/687474703a2f2f6461766964737475747a2e64652f776f726470726573732f77702d636f6e74656e742f75706c6f6164732f323031372f30322f62726f636b5f7661652e706e67)](https://camo.githubusercontent.com/d56145d936b2119cd0f6c746a9513a4ac248e1a6a7682ee1a5283bda00ae1ff6/687474703a2f2f6461766964737475747a2e64652f776f726470726573732f77702d636f6e74656e742f75706c6f6164732f323031372f30322f62726f636b5f7661652e706e67)

üì∑ **Multi-view Supervision for Single-view Reconstruction via Differentiable Ray Consistency (2017)** [\[Paper\]](https://shubhtuls.github.io/drc/)

[![Image 864](https://camo.githubusercontent.com/1b525ea7f7ac1f33628b3a3c72533ed4e00a0146bfa50a7edad66e5cdc4a37c4/68747470733a2f2f736875626874756c732e6769746875622e696f2f6472632f7265736f75726365732f696d616765732f74656173657243686169722e706e67)](https://camo.githubusercontent.com/1b525ea7f7ac1f33628b3a3c72533ed4e00a0146bfa50a7edad66e5cdc4a37c4/68747470733a2f2f736875626874756c732e6769746875622e696f2f6472632f7265736f75726365732f696d616765732f74656173657243686169722e706e67)

üì∑ **Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks (2017)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Soltani_Synthesizing_3D_Shapes_CVPR_2017_paper.pdf) [\[Code\]](https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil)

[![Image 865](https://camo.githubusercontent.com/9df5bebd8399fbb967d8ed8bdbfd33e4d06107a37112a4582e8c9d833afbc9d6/68747470733a2f2f6a69616a756e77752e636f6d2f696d616765732f73706f746c696768745f33647661652e6a7067)](https://camo.githubusercontent.com/9df5bebd8399fbb967d8ed8bdbfd33e4d06107a37112a4582e8c9d833afbc9d6/68747470733a2f2f6a69616a756e77752e636f6d2f696d616765732f73706f746c696768745f33647661652e6a7067)

üëæ **Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis (2017)** [\[Paper\]](https://arxiv.org/pdf/1612.00101.pdf) [\[Code\]](https://github.com/angeladai/cnncomplete)

[![Image 866](https://camo.githubusercontent.com/2975dfe61e746ce102bd8027ec98b427fc93593ea0ca1c886d7cc038fe9bc38b/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f636e6e636f6d706c6574652f7465617365722e6a7067)](https://camo.githubusercontent.com/2975dfe61e746ce102bd8027ec98b427fc93593ea0ca1c886d7cc038fe9bc38b/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f636e6e636f6d706c6574652f7465617365722e6a7067)

üëæ **Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs (2017)** [\[Paper\]](https://arxiv.org/pdf/1703.09438.pdf) [\[Code\]](https://github.com/lmb-freiburg/ogn)

[![Image 867](https://camo.githubusercontent.com/d1d4c8c825e78e6aa1a61789a39339fd40574e417ce388bc7d960db8dec0532a/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f366332613239326262303138613837343263626230626263356532336464306134353466666533612f322d466967757265322d312e706e67)](https://camo.githubusercontent.com/d1d4c8c825e78e6aa1a61789a39339fd40574e417ce388bc7d960db8dec0532a/68747470733a2f2f6169322d73322d7075626c69632e73332e616d617a6f6e6177732e636f6d2f666967757265732f323031362d31312d30382f366332613239326262303138613837343263626230626263356532336464306134353466666533612f322d466967757265322d312e706e67)

üëæ **Hierarchical Surface Prediction for 3D Object Reconstruction (2017)** [\[Paper\]](https://arxiv.org/pdf/1704.00710.pdf)

[![Image 868](https://camo.githubusercontent.com/7342141f597ad67584015a8aa8b4ece2711f57a532b7ff2115a8b6dbb6420fff/687474703a2f2f626169722e6265726b656c65792e6564752f626c6f672f6173736574732f6873702f696d6167655f322e706e67)](https://camo.githubusercontent.com/7342141f597ad67584015a8aa8b4ece2711f57a532b7ff2115a8b6dbb6420fff/687474703a2f2f626169722e6265726b656c65792e6564752f626c6f672f6173736574732f6873702f696d6167655f322e706e67)

üëæ **OctNetFusion: Learning Depth Fusion from Data (2017)** [\[Paper\]](https://arxiv.org/pdf/1704.01047.pdf) [\[Code\]](https://github.com/griegler/octnetfusion)

[![Image 869](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/OctNetFusion-%20Learning%20Depth%20Fusion%20from%20Data.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/OctNetFusion-%20Learning%20Depth%20Fusion%20from%20Data.jpeg)

üé≤ **A Point Set Generation Network for 3D Object Reconstruction from a Single Image (2017)** [\[Paper\]](http://ai.stanford.edu/~haosu/papers/SI2PC_arxiv_submit.pdf) [\[Code\]](https://github.com/fanhqme/PointSetGeneration)

[![Image 870](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/A%20Point%20Set%20Generation%20Network%20for%203D%20Object%20Reconstruction%20from%20a%20Single%20Image%20(2017).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/A%20Point%20Set%20Generation%20Network%20for%203D%20Object%20Reconstruction%20from%20a%20Single%20Image%20(2017).jpeg)

üé≤ **Learning Representations and Generative Models for 3D Point Clouds (2017)** [\[Paper\]](https://arxiv.org/pdf/1707.02392.pdf) [\[Code\]](https://github.com/optas/latent_3d_points)

[![Image 871](https://github.com/optas/latent_3d_points/raw/master/doc/images/teaser.jpg)](https://github.com/optas/latent_3d_points/blob/master/doc/images/teaser.jpg)

üé≤ **Shape Generation using Spatially Partitioned Point Clouds (2017)** [\[Paper\]](https://arxiv.org/pdf/1707.06267.pdf)

[![Image 872](https://camo.githubusercontent.com/51de2334b865407305b944dcae674f64c934044ee2805ccbbaf7a056810f96c8/687474703a2f2f6d676164656c68612e6d652f737070632f6669672f61627374726163742e706e67)](https://camo.githubusercontent.com/51de2334b865407305b944dcae674f64c934044ee2805ccbbaf7a056810f96c8/687474703a2f2f6d676164656c68612e6d652f737070632f6669672f61627374726163742e706e67)

üé≤ **PCPNET Learning Local Shape Properties from Raw Point Clouds (2017)** [\[Paper\]](https://arxiv.org/pdf/1710.04954.pdf)

[![Image 873](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PCPNET%20Learning%20Local%20Shape%20Properties%20from%20Raw%20Point%20Clouds%20(2017).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PCPNET%20Learning%20Local%20Shape%20Properties%20from%20Raw%20Point%20Clouds%20(2017).jpeg)

üì∑ **Transformation-Grounded Image Generation Network for Novel 3D View Synthesis (2017)** [\[Paper\]](http://www.cs.unc.edu/~eunbyung/tvsn/) [\[Code\]](https://github.com/silverbottlep/tvsn)

[![Image 874](https://camo.githubusercontent.com/559f51db0d45049bdb12a1bbe49b2b1cd45b280077a5df6245178dff466509a6/68747470733a2f2f656e672e75636d65726365642e6564752f70656f706c652f6a79616e6734342f706963732f766965775f73796e7468657369732e676966)](https://camo.githubusercontent.com/559f51db0d45049bdb12a1bbe49b2b1cd45b280077a5df6245178dff466509a6/68747470733a2f2f656e672e75636d65726365642e6564752f70656f706c652f6a79616e6734342f706963732f766965775f73796e7468657369732e676966)[](https://camo.githubusercontent.com/559f51db0d45049bdb12a1bbe49b2b1cd45b280077a5df6245178dff466509a6/68747470733a2f2f656e672e75636d65726365642e6564752f70656f706c652f6a79616e6734342f706963732f766965775f73796e7468657369732e676966)

üì∑ **Tag Disentangled Generative Adversarial Networks for Object Image Re-rendering (2017)** [\[Paper\]](http://static.ijcai.org/proceedings-2017/0404.pdf)

[![Image 875](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Tag%20Disentangled%20Generative%20Adversarial%20Networks%20for%20Object%20Image%20Re-rendering.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Tag%20Disentangled%20Generative%20Adversarial%20Networks%20for%20Object%20Image%20Re-rendering.jpeg)

üì∑ **3D Shape Reconstruction from Sketches via Multi-view Convolutional Networks (2017)** [\[Paper\]](http://people.cs.umass.edu/~zlun/papers/SketchModeling/) [\[Code\]](https://github.com/happylun/SketchModeling)

[![Image 876](https://camo.githubusercontent.com/820d4977c4fb5977af12e6625379654774883bae7af0217ab421c70483472ffa/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e7a6c756e2f7061706572732f536b657463684d6f64656c696e672f536b657463684d6f64656c696e675f7465617365722e706e67)](https://camo.githubusercontent.com/820d4977c4fb5977af12e6625379654774883bae7af0217ab421c70483472ffa/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e7a6c756e2f7061706572732f536b657463684d6f64656c696e672f536b657463684d6f64656c696e675f7465617365722e706e67)

üëæ **Interactive 3D Modeling with a Generative Adversarial Network (2017)** [\[Paper\]](https://arxiv.org/pdf/1706.05170.pdf)

[![Image 877](https://camo.githubusercontent.com/8ec51796bd442480287af1bdde4f8c90b8d990cd5baeea2c8ab8b8816e358b23/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f444373504b4c71586f414542642d562e6a7067)](https://camo.githubusercontent.com/8ec51796bd442480287af1bdde4f8c90b8d990cd5baeea2c8ab8b8816e358b23/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f444373504b4c71586f414542642d562e6a7067)

üì∑üëæ **Weakly supervised 3D Reconstruction with Adversarial Constraint (2017)** [\[Paper\]](https://arxiv.org/pdf/1705.10904.pdf) [\[Code\]](https://github.com/jgwak/McRecon)

[![Image 878](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Weakly%20supervised%203D%20Reconstruction%20with%20Adversarial%20Constraint%20(2017).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Weakly%20supervised%203D%20Reconstruction%20with%20Adversarial%20Constraint%20(2017).jpeg)

üì∑ **SurfNet: Generating 3D shape surfaces using deep residual networks (2017)** [\[Paper\]](https://arxiv.org/pdf/1703.04079.pdf)

[![Image 879](https://camo.githubusercontent.com/a8ce7d19feab1dfce461fd61f068f76dd50d686e86604e2f7ce518e2bc7b5fb9/68747470733a2f2f336461646570742e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031372f30372f53637265656e73686f742d66726f6d2d323031372d30372d32362d3134353532312d65313530313037373533393732332e706e67)](https://camo.githubusercontent.com/a8ce7d19feab1dfce461fd61f068f76dd50d686e86604e2f7ce518e2bc7b5fb9/68747470733a2f2f336461646570742e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031372f30372f53637265656e73686f742d66726f6d2d323031372d30372d32362d3134353532312d65313530313037373533393732332e706e67)

üì∑ **Learning to Reconstruct Symmetric Shapes using Planar Parameterization of 3D Surface (2019)** [\[Paper\]](https://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Jain_Learning_to_Reconstruct_Symmetric_Shapes_using_Planar_Parameterization_of_3D_ICCVW_2019_paper.pdf) [\[Code\]](https://github.com/hrdkjain/LearningSymmetricShapes)

[![Image 880](https://github.com/hrdkjain/LearningSymmetricShapes/raw/master/Images/teaser.png)](https://github.com/hrdkjain/LearningSymmetricShapes/blob/master/Images/teaser.png)

üíä **GRASS: Generative Recursive Autoencoders for Shape Structures (SIGGRAPH 2017)** [\[Paper\]](http://kevinkaixu.net/projects/grass.html) [\[Code\]](https://github.com/junli-lj/grass) [\[code\]](https://github.com/kevin-kaixu/grass_pytorch)

[![Image 881](https://camo.githubusercontent.com/35541a86c007f682ad12ea95cd08c46fd55697341f03275585744448884b4c11/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f67726173732f7465617365722e6a7067)](https://camo.githubusercontent.com/35541a86c007f682ad12ea95cd08c46fd55697341f03275585744448884b4c11/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f67726173732f7465617365722e6a7067)

üíä **3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks (2017)** [\[Paper\]](https://arxiv.org/pdf/1708.01648.pdf)[\[code\]](https://github.com/zouchuhang/3D-PRNN)

[![Image 882](https://github.com/zouchuhang/3D-PRNN/raw/master/figs/teasor.jpg)](https://github.com/zouchuhang/3D-PRNN/blob/master/figs/teasor.jpg)

üíé **Neural 3D Mesh Renderer (2017)** [\[Paper\]](http://hiroharu-kato.com/projects_en/neural_renderer.html) [\[Code\]](https://github.com/hiroharu-kato/neural_renderer.git)

[![Image 883](https://camo.githubusercontent.com/00def3ec3d1b280c8da122a7c31979cb333c59e0bc0ed6c6f808ac177301e619/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f4450536d2d3448576b414170455a642e6a7067)](https://camo.githubusercontent.com/00def3ec3d1b280c8da122a7c31979cb333c59e0bc0ed6c6f808ac177301e619/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f4450536d2d3448576b414170455a642e6a7067)

üé≤üëæ **Large-Scale 3D Shape Reconstruction and Segmentation from ShapeNet Core55 (2017)** [\[Paper\]](https://arxiv.org/pdf/1710.06104.pdf)

[![Image 884](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Core55.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Core55.png)

üëæ **Pix2vox: Sketch-Based 3D Exploration with Stacked Generative Adversarial Networks (2017)** [\[Code\]](https://github.com/maxorange/pix2vox)

[![Image 885](https://github.com/maxorange/pix2vox/raw/master/img/sample.gif)](https://github.com/maxorange/pix2vox/blob/master/img/sample.gif)

üì∑üëæ **What You Sketch Is What You Get: 3D Sketching using Multi-View Deep Volumetric Prediction (2017)** [\[Paper\]](https://arxiv.org/pdf/1707.08390.pdf)

[![Image 886](https://camo.githubusercontent.com/46446e4240401cf494bd32c1f4c54d10fb34a8d579443e394e1b8c5b3c7fa5c2/68747470733a2f2f61727869762d73616e6974792d73616e6974792d70726f64756374696f6e2e73332e616d617a6f6e6177732e636f6d2f72656e6465722d6f75747075742f33313633312f78312e706e67)](https://camo.githubusercontent.com/46446e4240401cf494bd32c1f4c54d10fb34a8d579443e394e1b8c5b3c7fa5c2/68747470733a2f2f61727869762d73616e6974792d73616e6974792d70726f64756374696f6e2e73332e616d617a6f6e6177732e636f6d2f72656e6465722d6f75747075742f33313633312f78312e706e67)

üì∑üëæ **MarrNet: 3D Shape Reconstruction via 2.5D Sketches (2017)** [\[Paper\]](http://marrnet.csail.mit.edu/)

[![Image 887](https://camo.githubusercontent.com/6bc9da0b80da8a9d04ecc8d10eec3e8cb9895768e0caa59d451343ae70de124d/687474703a2f2f6d6172726e65742e637361696c2e6d69742e6564752f696d616765732f6d6f64656c2e6a7067)](https://camo.githubusercontent.com/6bc9da0b80da8a9d04ecc8d10eec3e8cb9895768e0caa59d451343ae70de124d/687474703a2f2f6d6172726e65742e637361696c2e6d69742e6564752f696d616765732f6d6f64656c2e6a7067)

üì∑üëæüé≤ **Learning a Multi-View Stereo Machine (2017 NIPS)** [\[Paper\]](http://bair.berkeley.edu/blog/2017/09/05/unified-3d/)

[![Image 888](https://camo.githubusercontent.com/43471020bf002c0ed7f29d562631099b5cbedd8ab1a00b6eb4219d8207b7350a/687474703a2f2f626169722e6265726b656c65792e6564752f7374617469632f626c6f672f756e69666965642d33642f4e6574776f726b2e706e67)](https://camo.githubusercontent.com/43471020bf002c0ed7f29d562631099b5cbedd8ab1a00b6eb4219d8207b7350a/687474703a2f2f626169722e6265726b656c65792e6564752f7374617469632f626c6f672f756e69666965642d33642f4e6574776f726b2e706e67)

üëæ **3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions (2017)** [\[Paper\]](http://3dmatch.cs.princeton.edu/)

[![Image 889](https://camo.githubusercontent.com/7c5b49f66ef5937586d1a41df3739f70d414200ca54fcd0ba68305e24d55b6c8/687474703a2f2f33646d617463682e63732e7072696e6365746f6e2e6564752f696d672f6f766572766965772e6a7067)](https://camo.githubusercontent.com/7c5b49f66ef5937586d1a41df3739f70d414200ca54fcd0ba68305e24d55b6c8/687474703a2f2f33646d617463682e63732e7072696e6365746f6e2e6564752f696d672f6f766572766965772e6a7067)

üëæ **Scaling CNNs for High Resolution Volumetric Reconstruction from a Single Image (2017)** [\[Paper\]](https://ieeexplore.ieee.org/document/8265323/)

[![Image 890](https://github.com/frankhjwx/3D-Machine-Learning/raw/master/imgs/Scaling%20CNN%20Reconstruction.png)](https://github.com/frankhjwx/3D-Machine-Learning/blob/master/imgs/Scaling%20CNN%20Reconstruction.png)

üíä **ComplementMe: Weakly-Supervised Component Suggestions for 3D Modeling (2017)** [\[Paper\]](https://arxiv.org/pdf/1708.01841.pdf)

[![Image 891](https://camo.githubusercontent.com/ce9159c94faa483ad2a414e944cf80cd2b6766504244b2841445ad37f735bb7c/68747470733a2f2f6d6873756e672e6769746875622e696f2f6173736574732f696d616765732f636f6d706c656d656e742d6d652f6669677572655f322e706e67)](https://camo.githubusercontent.com/ce9159c94faa483ad2a414e944cf80cd2b6766504244b2841445ad37f735bb7c/68747470733a2f2f6d6873756e672e6769746875622e696f2f6173736574732f696d616765732f636f6d706c656d656e742d6d652f6669677572655f322e706e67)

üëæ **Learning Descriptor Networks for 3D Shape Synthesis and Analysis (2018 CVPR)** [\[Project\]](http://www.stat.ucla.edu/~jxie/3DEBM/) [\[Paper\]](http://www.stat.ucla.edu/~jxie/3DDescriptorNet/3DDescriptorNet_file/doc/3DDescriptorNet.pdf) \[[Code](https://github.com/jianwen-xie/3DDescriptorNet)\]

An energy-based 3D shape descriptor network is a deep energy-based model for volumetric shape patterns. The maximum likelihood training of the model follows an ‚Äúanalysis by synthesis‚Äù scheme and can be interpreted as a mode seeking and mode shifting process. The model can synthesize 3D shape patterns by sampling from the probability distribution via MCMC such as Langevin dynamics. Experiments demonstrate that the proposed model can generate realistic 3D shape patterns and can be useful for 3D shape analysis.

[![Image 892](https://camo.githubusercontent.com/c0a57161c59e6723edec68e11ae0faecc26ead61bf51a98e6e7853788f0f79af/687474703a2f2f7777772e737461742e75636c612e6564752f7e6a7869652f334445424d2f66696c65732f33445f73796e2e706e67)](https://camo.githubusercontent.com/c0a57161c59e6723edec68e11ae0faecc26ead61bf51a98e6e7853788f0f79af/687474703a2f2f7777772e737461742e75636c612e6564752f7e6a7869652f334445424d2f66696c65732f33445f73796e2e706e67)

üé≤ **PU-Net: Point Cloud Upsampling Network (2018)** [\[Paper\]](https://arxiv.org/pdf/1801.06761.pdf) [\[Code\]](https://github.com/yulequan/PU-Net)

[![Image 893](https://camo.githubusercontent.com/e85e3c814f430df89df91af18dfc8c5e9a665ebf84c0915dd7070ce09dbfba5d/687474703a2f2f6170707372762e6373652e6375686b2e6564752e686b2f7e6c7179752f696e646578706963732f50752d4e65742e706e67)](https://camo.githubusercontent.com/e85e3c814f430df89df91af18dfc8c5e9a665ebf84c0915dd7070ce09dbfba5d/687474703a2f2f6170707372762e6373652e6375686b2e6564752e686b2f7e6c7179752f696e646578706963732f50752d4e65742e706e67)

üì∑üëæ **Multi-view Consistency as Supervisory Signal for Learning Shape and Pose Prediction (2018 CVPR)** [\[Paper\]](https://shubhtuls.github.io/mvcSnP/)

[![Image 894](https://camo.githubusercontent.com/e3ddb4e42fb2f4145c86834c25aaf677fcfa8643fea26bf3fe3645103c8bf32b/68747470733a2f2f736875626874756c732e6769746875622e696f2f6d7663536e502f7265736f75726365732f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/e3ddb4e42fb2f4145c86834c25aaf677fcfa8643fea26bf3fe3645103c8bf32b/68747470733a2f2f736875626874756c732e6769746875622e696f2f6d7663536e502f7265736f75726365732f696d616765732f7465617365722e706e67)

üì∑üé≤ **Object-Centric Photometric Bundle Adjustment with Deep Shape Prior (2018)** [\[Paper\]](http://ci2cv.net/media/papers/WACV18.pdf)

[![Image 895](https://camo.githubusercontent.com/b42f2871fae99af024d165bad9e7d3befda59cd7ee5003d6b794737f5904650e/68747470733a2f2f6368656e687375616e6c696e2e6269746275636b65742e696f2f696d616765732f72702f7230362e706e67)](https://camo.githubusercontent.com/b42f2871fae99af024d165bad9e7d3befda59cd7ee5003d6b794737f5904650e/68747470733a2f2f6368656e687375616e6c696e2e6269746275636b65742e696f2f696d616765732f72702f7230362e706e67)

üì∑üé≤ **Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction (2018 AAAI)** [\[Paper\]](https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/)

[![Image 896](https://camo.githubusercontent.com/72f886f4717b63085362d5d8bb2732cd25c376f043dfbab8d8ba7638a31176f8/68747470733a2f2f6368656e687375616e6c696e2e6269746275636b65742e696f2f696d616765732f72702f7230352e706e67)](https://camo.githubusercontent.com/72f886f4717b63085362d5d8bb2732cd25c376f043dfbab8d8ba7638a31176f8/68747470733a2f2f6368656e687375616e6c696e2e6269746275636b65742e696f2f696d616765732f72702f7230352e706e67)

üíé **Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images (2018)** [\[Paper\]](https://github.com/nywang16/Pixel2Mesh)

[![Image 897](https://camo.githubusercontent.com/ef464ed83e6bb60d119679f42df5db93113ce5807285defc778e50b3abc20310/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f3138383931312f78322e706e672e37353078305f7137355f63726f702e706e67)](https://camo.githubusercontent.com/ef464ed83e6bb60d119679f42df5db93113ce5807285defc778e50b3abc20310/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f3138383931312f78322e706e672e37353078305f7137355f63726f702e706e67)

üíé **AtlasNet: A Papier-M√¢ch√© Approach to Learning 3D Surface Generation (2018 CVPR)** [\[Paper\]](http://imagine.enpc.fr/~groueixt/atlasnet/) [\[Code\]](https://github.com/ThibaultGROUEIX/AtlasNet)

[![Image 898](https://camo.githubusercontent.com/9420db068e999c23ffbc5eff70caf0cf61535eeab4cc2ba4c01f180edb0843b7/687474703a2f2f696d6167696e652e656e70632e66722f7e67726f75656978742f61746c61736e65742f696d67732f7465617365722e736d616c6c2e706e67)](https://camo.githubusercontent.com/9420db068e999c23ffbc5eff70caf0cf61535eeab4cc2ba4c01f180edb0843b7/687474703a2f2f696d6167696e652e656e70632e66722f7e67726f75656978742f61746c61736e65742f696d67732f7465617365722e736d616c6c2e706e67)

üëæüíé **Deep Marching Cubes: Learning Explicit Surface Representations (2018 CVPR)** [\[Paper\]](http://www.cvlibs.net/publications/Liao2018CVPR.pdf)

[![Image 899](https://github.com/frankhjwx/3D-Machine-Learning/raw/master/imgs/Deep%20Marching%20Cubes.png)](https://github.com/frankhjwx/3D-Machine-Learning/blob/master/imgs/Deep%20Marching%20Cubes.png)

üëæ **Im2Avatar: Colorful 3D Reconstruction from a Single Image (2018)** [\[Paper\]](https://arxiv.org/pdf/1804.06375v1.pdf)

[![Image 900](https://github.com/syb7573330/im2avatar/raw/master/misc/demo_teaser.png)](https://github.com/syb7573330/im2avatar/blob/master/misc/demo_teaser.png)

üíé **Learning Category-Specific Mesh Reconstruction from Image Collections (2018)** [\[Paper\]](https://akanazawa.github.io/cmr/#)

[![Image 901](https://camo.githubusercontent.com/0e73fce4bb77d6aabdd5c79bf81009859ed56e035d669fd85a9e93cbdb3a6b83/68747470733a2f2f616b616e617a6177612e6769746875622e696f2f636d722f7265736f75726365732f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/0e73fce4bb77d6aabdd5c79bf81009859ed56e035d669fd85a9e93cbdb3a6b83/68747470733a2f2f616b616e617a6177612e6769746875622e696f2f636d722f7265736f75726365732f696d616765732f7465617365722e706e67)

üíä **CSGNet: Neural Shape Parser for Constructive Solid Geometry (2018)** [\[Paper\]](https://arxiv.org/pdf/1712.08290.pdf)

[![Image 902](https://camo.githubusercontent.com/ab240ac974450c4b63deefe7ec10e095652e050ad6849252e9730cc11e6fed5e/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44522d5267626155384145796a65572e6a7067)](https://camo.githubusercontent.com/ab240ac974450c4b63deefe7ec10e095652e050ad6849252e9730cc11e6fed5e/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44522d5267626155384145796a65572e6a7067)

üëæ **Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings (2018)** [\[Paper\]](http://text2shape.stanford.edu/)

[![Image 903](https://camo.githubusercontent.com/a20c00f8e8f217ddab2f08152c1cf44ea53070e2879366b082bce7cf5810fa23/687474703a2f2f746578743273686170652e7374616e666f72642e6564752f666967757265732f70756c6c2e706e67)](https://camo.githubusercontent.com/a20c00f8e8f217ddab2f08152c1cf44ea53070e2879366b082bce7cf5810fa23/687474703a2f2f746578743273686170652e7374616e666f72642e6564752f666967757265732f70756c6c2e706e67)

üëæüíéüì∑ **Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation (2018)** [\[Paper\]](https://arxiv.org/abs/1802.09987) [\[Code\]](https://github.com/EdwardSmith1884/Multi-View-Silhouette-and-Depth-Decomposition-for-High-Resolution-3D-Object-Representation)

[![Image 904](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/decomposition_new.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/decomposition_new.png) [![Image 905](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Multi-View%20Silhouette%20and%20Depth%20Decomposition%20for%20High%20Resolution%203D%20Object%20Representation.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Multi-View%20Silhouette%20and%20Depth%20Decomposition%20for%20High%20Resolution%203D%20Object%20Representation.png)

üëæüíéüì∑ **Pixels, voxels, and views: A study of shape representations for single view 3D object shape prediction (2018 CVPR)** [\[Paper\]](https://arxiv.org/abs/1804.06032)

[![Image 906](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/pixels-voxels-views-rgb2mesh.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/pixels-voxels-views-rgb2mesh.png)

üì∑üé≤ **Neural scene representation and rendering (2018)** [\[Paper\]](https://deepmind.com/blog/neural-scene-representation-and-rendering/)

[![Image 907](https://camo.githubusercontent.com/3e647c983b6ddebb6f40beca66d9381a04e24274502b0f12a17f99425c75da67/687474703a2f2f7777772e6172696d6f72636f732e636f6d2f7374617469632f696d616765732f7075626c69636174696f6e5f696d616765732f67716e5f696d6167652e706e67)](https://camo.githubusercontent.com/3e647c983b6ddebb6f40beca66d9381a04e24274502b0f12a17f99425c75da67/687474703a2f2f7777772e6172696d6f72636f732e636f6d2f7374617469632f696d616765732f7075626c69636174696f6e5f696d616765732f67716e5f696d6167652e706e67)

üíä **Im2Struct: Recovering 3D Shape Structure from a Single RGB Image (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1804.05469.pdf)

[![Image 908](https://camo.githubusercontent.com/a4b4bd6ab4d2af90516bf1b8450409cc708a3071322bb8a253e8c86e2b00fa1a/68747470733a2f2f6b6576696e6b616978752e6e65742f696d616765732f7075626c69636174696f6e732f6e69755f6376707231382e6a7067)](https://camo.githubusercontent.com/a4b4bd6ab4d2af90516bf1b8450409cc708a3071322bb8a253e8c86e2b00fa1a/68747470733a2f2f6b6576696e6b616978752e6e65742f696d616765732f7075626c69636174696f6e732f6e69755f6376707231382e6a7067)

üé≤ **FoldingNet: Point Cloud Auto-encoder via Deep Grid Deformation (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1712.07262.pdf)

[![Image 909](https://camo.githubusercontent.com/d1d57f9a2944295ddbd1137607681e83237cb4cd51f133f039f31df0cca16c58/687474703a2f2f73696d6261666f72726573742e6769746875622e696f2f6669672f466f6c64696e674e65742e6a7067)](https://camo.githubusercontent.com/d1d57f9a2944295ddbd1137607681e83237cb4cd51f133f039f31df0cca16c58/687474703a2f2f73696d6261666f72726573742e6769746875622e696f2f6669672f466f6c64696e674e65742e6a7067)

üì∑üëæ **Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling (2018 CVPR)** [\[Paper\]](http://pix3d.csail.mit.edu/)

[![Image 910](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Pix3D%20-%20Dataset%20and%20Methods%20for%20Single-Image%203D%20Shape%20Modeling%20(2018%20CVPR).png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Pix3D%20-%20Dataset%20and%20Methods%20for%20Single-Image%203D%20Shape%20Modeling%20(2018%20CVPR).png)

üíé **3D-RCNN: Instance-level 3D Object Reconstruction via Render-and-Compare (2018 CVPR)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1128.pdf)

[![Image 911](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/3D-RCNN-%20Instance-level%203D%20Object%20Reconstruction%20via%20Render-and-Compare%20(2018%20CVPR).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/3D-RCNN-%20Instance-level%203D%20Object%20Reconstruction%20via%20Render-and-Compare%20(2018%20CVPR).jpeg)

üëæ **Matryoshka Networks: Predicting 3D Geometry via Nested Shape Layers (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1804.10975.pdf)

[![Image 912](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Matryoshka%20Networks-%20Predicting%203D%20Geometry%20via%20Nested%20Shape%20Layers%20(2018%20CVPR).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Matryoshka%20Networks-%20Predicting%203D%20Geometry%20via%20Nested%20Shape%20Layers%20(2018%20CVPR).jpeg)

üíé **Deformable Shape Completion with Graph Convolutional Autoencoders (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1712.00268v1.pdf)

[![Image 913](https://camo.githubusercontent.com/021b8b0588918fd3c9e387f213c7ed0d348d1194a6fd06d959c39473118caaa4/68747470733a2f2f6f726c6974616e792e6769746875622e696f2f4f4c5f66696c65732f7368617065436f6d702e706e67)](https://camo.githubusercontent.com/021b8b0588918fd3c9e387f213c7ed0d348d1194a6fd06d959c39473118caaa4/68747470733a2f2f6f726c6974616e792e6769746875622e696f2f4f4c5f66696c65732f7368617065436f6d702e706e67)

üëæ **Global-to-Local Generative Model for 3D Shapes (SIGGRAPH Asia 2018)** [\[Paper\]](http://vcc.szu.edu.cn/research/2018/G2L)[\[Code\]](https://github.com/Hao-HUST/G2LGAN)

[![Image 914](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Global-to-Local%20Generative%20Model%20for%203D%20Shapes.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Global-to-Local%20Generative%20Model%20for%203D%20Shapes.jpg)

üíéüé≤üëæ **ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning (TOG 2018)** [\[Paper\]](https://bit.ly/alignet) [\[Code\]](https://github.com/ranahanocka/ALIGNet/)

[![Image 915](https://github.com/ranahanocka/ALIGNet/raw/master/docs/rep.png)](https://github.com/ranahanocka/ALIGNet/blob/master/docs/rep.png)

üé≤üëæ **PointGrid: A Deep Network for 3D Shape Understanding (CVPR 2018)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf) [\[Code\]](https://github.com/trucleduc/PointGrid)

[![Image 916](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PointGrid-%20A%20Deep%20Network%20for%203D%20Shape%20Understanding%20(2018).jpeg)

üé≤ **GAL: Geometric Adversarial Loss for Single-View 3D-Object Reconstruction (2018)** [\[Paper\]](https://xjqi.github.io/GAL.pdf)

[![Image 917](https://camo.githubusercontent.com/ecfaeebdda9afa6bcd8d6855e582d8dc18485435893258980e6675e071cf6588/68747470733a2f2f6d656469612e737072696e6765726e61747572652e636f6d2f6f726967696e616c2f737072696e6765722d7374617469632f696d6167652f63687025334131302e313030372532463937382d332d3033302d30313233372d335f34392f4d656469614f626a656374732f3437343231335f315f456e5f34395f466967325f48544d4c2e676966)](https://camo.githubusercontent.com/ecfaeebdda9afa6bcd8d6855e582d8dc18485435893258980e6675e071cf6588/68747470733a2f2f6d656469612e737072696e6765726e61747572652e636f6d2f6f726967696e616c2f737072696e6765722d7374617469632f696d6167652f63687025334131302e313030372532463937382d332d3033302d30313233372d335f34392f4d656469614f626a656374732f3437343231335f315f456e5f34395f466967325f48544d4c2e676966)

üé≤ **Visual Object Networks: Image Generation with Disentangled 3D Representation (2018)** [\[Paper\]](https://papers.nips.cc/paper/7297-visual-object-networks-image-generation-with-disentangled-3d-representations.pdf)

[![Image 918](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Visual%20Object%20Networks-%20Image%20Generation%20with%20Disentangled%203D%20Representation%20(2018).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Visual%20Object%20Networks-%20Image%20Generation%20with%20Disentangled%203D%20Representation%20(2018).jpeg)

üëæ **Learning to Infer and Execute 3D Shape Programs (2019))** [\[Paper\]](http://shape2prog.csail.mit.edu/)

[![Image 919](https://camo.githubusercontent.com/827b30718220c7891e59a24d711148cf2d4b6a46c3bf3764c6aa618d5276a1b0/687474703a2f2f73686170653270726f672e637361696c2e6d69742e6564752f73686170655f66696c65732f7465617365722e6a7067)](https://camo.githubusercontent.com/827b30718220c7891e59a24d711148cf2d4b6a46c3bf3764c6aa618d5276a1b0/687474703a2f2f73686170653270726f672e637361696c2e6d69742e6564752f73686170655f66696c65732f7465617365722e6a7067)

üëæ **Learning to Infer and Execute 3D Shape Programs (2019))** [\[Paper\]](https://arxiv.org/pdf/1901.05103.pdf)

[![Image 920](https://camo.githubusercontent.com/5161969489a062d254e8af8051ce7b4f2dfb6a646bf5d0787b77c1a6124ad384/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44784661572d6d553841456f3977632e6a7067)](https://camo.githubusercontent.com/5161969489a062d254e8af8051ce7b4f2dfb6a646bf5d0787b77c1a6124ad384/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44784661572d6d553841456f3977632e6a7067)

üíé **Learning View Priors for Single-view 3D Reconstruction (CVPR 2019)** [\[Paper\]](http://hiroharu-kato.com/projects_en/view_prior_learning.html)

[![Image 921](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Learning%20View%20Priors%20for%20Single-view%203D%20Reconstruction.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Learning%20View%20Priors%20for%20Single-view%203D%20Reconstruction.png)

üíéüé≤ **Learning Embedding of 3D models with Quadric Loss (BMVC 2019)** [\[Paper\]](https://arxiv.org/abs/1907.10250) [\[Code\]](https://github.com/nitinagarwal/QuadricLoss)

[![Image 922](https://camo.githubusercontent.com/1aaf5fd8633f9f705b3a467a04658e77a3097c090d28fe331ca044d74c57b705/68747470733a2f2f7777772e6963732e7563692e6564752f7e6167617277616c2f626d76635f323031392e706e67)](https://camo.githubusercontent.com/1aaf5fd8633f9f705b3a467a04658e77a3097c090d28fe331ca044d74c57b705/68747470733a2f2f7777772e6963732e7563692e6564752f7e6167617277616c2f626d76635f323031392e706e67)

üé≤ **CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition (ICCV 2019)** [\[Paper\]](https://arxiv.org/abs/1811.07441)[\[Code\]](https://github.com/nschor/CompoNet)

[![Image 923](https://raw.githubusercontent.com/nschor/CompoNet/master/images/network_architecture.png)](https://raw.githubusercontent.com/nschor/CompoNet/master/images/network_architecture.png)

**CoMA: Convolutional Mesh Autoencoders (2018)** [\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/439/1285.pdf)[\[Code (TF)\]](https://github.com/anuragranj/coma)[\[Code (PyTorch)\]](https://github.com/pixelite1201/pytorch_coma/)[\[Code (PyTorch)\]](https://github.com/sw-gong/coma)  
[CoMA](https://coma.is.tue.mpg.de/) is a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. CoMA introduces mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model.

[![Image 924](https://camo.githubusercontent.com/e38fa3deea747c7ee663b040d5fd8c225f1d4ea31212b20768aa7151a4ebbed5/68747470733a2f2f636f6d612e69732e7475652e6d70672e64652f75706c6f6164732f636b656469746f722f70696374757265732f39312f636f6e74656e745f636f6d615f66616365732e6a7067)](https://camo.githubusercontent.com/e38fa3deea747c7ee663b040d5fd8c225f1d4ea31212b20768aa7151a4ebbed5/68747470733a2f2f636f6d612e69732e7475652e6d70672e64652f75706c6f6164732f636b656469746f722f70696374757265732f39312f636f6e74656e745f636f6d615f66616365732e6a7067)

**RingNet: 3D Face Reconstruction from Single Images (2019)** [\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/509/paper_camera_ready.pdf)[\[Code\]](https://github.com/soubhiksanyal/RingNet)

[![Image 925](https://github.com/soubhiksanyal/RingNet/raw/master/gif/celeba_reconstruction.gif)](https://github.com/soubhiksanyal/RingNet/blob/master/gif/celeba_reconstruction.gif)

**VOCA: Voice Operated Character Animation (2019)** [\[Paper\]](https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/510/paper_final.pdf)[\[Video\]](https://youtu.be/XceCxf_GyW4)[\[Code\]](https://github.com/TimoBolkart/voca)  
[VOCA](https://voca.is.tue.mpg.de/) is a simple and generic speech-driven facial animation framework that works across a range of identities. The codebase demonstrates how to synthesize realistic character animations given an arbitrary speech signal and a static character mesh.

[![Image 926](https://github.com/TimoBolkart/voca/raw/master/gif/speech_driven_animation.gif)](https://github.com/TimoBolkart/voca/blob/master/gif/speech_driven_animation.gif)

üíé **Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer** [\[Paper\]](https://arxiv.org/abs/1908.01210)[\[Site\]](https://nv-tlabs.github.io/DIB-R/)[\[Code\]](https://github.com/nv-tlabs/DIB-R)

[![Image 927](https://camo.githubusercontent.com/861a239cf3504d7ea88c0a3cd732557e0a846db02b3e806037684f4281b90d9e/68747470733a2f2f6e762d746c6162732e6769746875622e696f2f4449422d522f666967757265732f6d6f64656c32612d322e706e67)](https://camo.githubusercontent.com/861a239cf3504d7ea88c0a3cd732557e0a846db02b3e806037684f4281b90d9e/68747470733a2f2f6e762d746c6162732e6769746875622e696f2f4449422d522f666967757265732f6d6f64656c32612d322e706e67)

üíé **Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning** [\[Paper\]](https://arxiv.org/abs/1904.01786)[\[Code\]](https://github.com/ShichenLiu/SoftRas)

[![Image 928](https://raw.githubusercontent.com/ShichenLiu/SoftRas/master/data/media/teaser/teaser.png)](https://raw.githubusercontent.com/ShichenLiu/SoftRas/master/data/media/teaser/teaser.png)

**NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis** [\[Project\]](http://www.matthewtancik.com/nerf)[\[Paper\]](https://arxiv.org/abs/2003.08934)[\[Code\]](https://github.com/bmild/nerf)

[![Image 929](https://camo.githubusercontent.com/9da81262b386115b8d7de343e2f967ad4168e6ec8ea2171ceaae7bfb1d90372b/68747470733a2f2f75706c6f6164732d73736c2e776562666c6f772e636f6d2f3531653064373364383364303662616137613030303030662f3565373030656636303637623433383231656435323736385f706970656c696e655f776562736974652d30312d702d3830302e706e67)](https://camo.githubusercontent.com/9da81262b386115b8d7de343e2f967ad4168e6ec8ea2171ceaae7bfb1d90372b/68747470733a2f2f75706c6f6164732d73736c2e776562666c6f772e636f6d2f3531653064373364383364303662616137613030303030662f3565373030656636303637623433383231656435323736385f706970656c696e655f776562736974652d30312d702d3830302e706e67)

üíéüé≤ **GAMesh: Guided and Augmented Meshing for Deep Point Networks (3DV 2020)** [\[Project\]](https://www.ics.uci.edu/~agarwal/GAMesh/) [\[Paper\]](https://arxiv.org/abs/2010.09774) [\[Code\]](https://github.com/nitinagarwal/GAMesh)

[![Image 930](https://camo.githubusercontent.com/fa0e081948efd36ccf0ede5bb5b78a2236ac8250b842a98f91fc6045ea8745e1/68747470733a2f2f7777772e6963732e7563692e6564752f7e6167617277616c2f3344565f323032302e706e67)](https://camo.githubusercontent.com/fa0e081948efd36ccf0ede5bb5b78a2236ac8250b842a98f91fc6045ea8745e1/68747470733a2f2f7777772e6963732e7563692e6564752f7e6167617277616c2f3344565f323032302e706e67)

üëæ **Generative VoxelNet: Learning Energy-Based Models for 3D Shape Synthesis and Analysis (2020 TPAMI)** [\[Paper\]](http://www.stat.ucla.edu/~jxie/3DEBM/3DEBM_file/doc/gVoxelNet.pdf)

This paper proposes a deep 3D energy-based model to represent volumetric shapes. The maximum likelihood training of the model follows an ‚Äúanalysis by synthesis‚Äù scheme. Experiments demonstrate that the proposed model can generate high-quality 3D shape patterns and can be useful for a wide variety of 3D shape analysis.

[![Image 931](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/voxelnet.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/voxelnet.png)

üé≤ **Generative PointNet: Deep Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification (2021 CVPR)**¬† [\[Project\]](http://www.stat.ucla.edu/~jxie/GPointNet/) [\[Paper\]](https://arxiv.org/pdf/2004.01301.pdf) \[[Code](https://github.com/fei960922/GPointNet)\]

Generative PointNet is an energy-based model of unordered point clouds, where the energy function is parameterized by an input-permutation-invariant bottom-up neural network. The model can be trained by MCMC-based maximum likelihood learning, or a short-run MCMC toward the energy-based model as a flow-like generator for point cloud reconstruction and interpolation. The learned point cloud representation can be useful for point cloud classification.

[![Image 932](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/gpointnet.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/gpointnet.png)

üé≤ üíé **Shape My Face: Registering 3D Face Scans by Surface-to-Surface Translation** [\[Paper\]](https://arxiv.org/abs/2012.09235) [\[Code\]](https://github.com/mbahri/smf)

Shape My Face (SMF) is a point cloud to mesh auto-encoder for the registration of raw human face scans, and the generation of synthetic human faces. SMF leverages a modified PointNet encoder with a visual attention module and differentiable surface sampling to be independent of the original surface representation and reduce the need for pre-processing. Mesh convolution decoders are combined with a specialized PCA model of the mouth, and smoothly blended based on geodesic distances, to create a compact model that is highly robust to noise. SMF is applied to register and perform expression transfer on scans captured in-the-wild with an iPhone depth camera represented either as meshes or point clouds.

[![Image 933](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/ShapeMyFace.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/ShapeMyFace.png)

üé≤ **Learning Implicit Fields for Generative Shape Modeling (2019)** [\[Paper\]](https://arxiv.org/abs/1812.02822) [\[Code\]](https://github.com/timzhang642/3D-Machine-Learning)

We advocate the use of implicit fields for learning generative models of shapes and introduce an implicit field decoder, called IM-NET, for shape generation, aimed at improving the visual quality of the generated shapes. An implicit field assigns a value to each point in 3D space, so that a shape can be extracted as an iso-surface. IM-NET is trained to perform this assignment by means of a binary classifier. Specifically, it takes a point coordinate, along with a feature vector encoding a shape, and outputs a value which indicates whether the point is outside the shape or not. By replacing conventional decoders by our implicit decoder for representation learning (via IM-AE) and shape generation (via IM-GAN), we demonstrate superior results for tasks such as generative shape modeling, interpolation, and single-view 3D reconstruction, particularly in terms of visual quality.

[![Image 934](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/IM_NET.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/IM_NET.png)

Texture/Material Analysis and Synthesis
---------------------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#texturematerial-analysis-and-synthesis)

**Texture Synthesis Using Convolutional Neural Networks (2015)** [\[Paper\]](https://arxiv.org/pdf/1505.07376.pdf)

[![Image 935](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Texture%20Synthesis%20Using%20Convolutional%20Neural%20Networks.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Texture%20Synthesis%20Using%20Convolutional%20Neural%20Networks.jpeg)

**Two-Shot SVBRDF Capture for Stationary Materials (SIGGRAPH 2015)** [\[Paper\]](https://mediatech.aalto.fi/publications/graphics/TwoShotSVBRDF/)

[![Image 936](https://camo.githubusercontent.com/e056af4ff4d16285c689121d9500f2261afadab5f228057fbe63b3153bca9df1/68747470733a2f2f6d65646961746563682e61616c746f2e66692f7075626c69636174696f6e732f67726170686963732f54776f53686f745356425244462f7465617365722e706e67)](https://camo.githubusercontent.com/e056af4ff4d16285c689121d9500f2261afadab5f228057fbe63b3153bca9df1/68747470733a2f2f6d65646961746563682e61616c746f2e66692f7075626c69636174696f6e732f67726170686963732f54776f53686f745356425244462f7465617365722e706e67)

**Reflectance Modeling by Neural Texture Synthesis (2016)** [\[Paper\]](https://mediatech.aalto.fi/publications/graphics/NeuralSVBRDF/)

[![Image 937](https://camo.githubusercontent.com/17a34d0568aa6e7403fce2b4770e73d4c81643091c33d50fd2881569484b6e0c/68747470733a2f2f6d65646961746563682e61616c746f2e66692f7075626c69636174696f6e732f67726170686963732f4e657572616c5356425244462f7465617365722e706e67)](https://camo.githubusercontent.com/17a34d0568aa6e7403fce2b4770e73d4c81643091c33d50fd2881569484b6e0c/68747470733a2f2f6d65646961746563682e61616c746f2e66692f7075626c69636174696f6e732f67726170686963732f4e657572616c5356425244462f7465617365722e706e67)

**Modeling Surface Appearance from a Single Photograph using Self-augmented Convolutional Neural Networks (2017)** [\[Paper\]](http://msraig.info/~sanet/sanet.htm)

[![Image 938](https://camo.githubusercontent.com/d1aaa63029f4da16a5de8fd80580053483fed4b7e54b2e2b5f48f3910808cede/687474703a2f2f6d73726169672e696e666f2f7e73616e65742f7465617365722e6a7067)](https://camo.githubusercontent.com/d1aaa63029f4da16a5de8fd80580053483fed4b7e54b2e2b5f48f3910808cede/687474703a2f2f6d73726169672e696e666f2f7e73616e65742f7465617365722e6a7067)

**High-Resolution Multi-Scale Neural Texture Synthesis (2017)** [\[Paper\]](https://wxs.ca/research/multiscale-neural-synthesis/)

[![Image 939](https://camo.githubusercontent.com/c7277bc6739ffbe64d333d674a43b9aa580642eef9cc24df43182600669b3388/68747470733a2f2f7778732e63612f72657365617263682f6d756c74697363616c652d6e657572616c2d73796e7468657369732f6d756c74697363616c652d6772616d2d6d6172626c652e6a7067)](https://camo.githubusercontent.com/c7277bc6739ffbe64d333d674a43b9aa580642eef9cc24df43182600669b3388/68747470733a2f2f7778732e63612f72657365617263682f6d756c74697363616c652d6e657572616c2d73796e7468657369732f6d756c74697363616c652d6772616d2d6d6172626c652e6a7067)

**Reflectance and Natural Illumination from Single Material Specular Objects Using Deep Learning (2017)** [\[Paper\]](https://homes.cs.washington.edu/~krematas/Publications/reflectance-natural-illumination.pdf)

[![Image 940](https://camo.githubusercontent.com/cc432cb62ac01cdc374eaaf44a39dcd49ab840e627b5ce68bcfb7895a3db73bf/687474703a2f2f7777772e766973696f6e2e65652e6574687a2e63682f7e67656f72676f75732f696d616765732f7470616d6931375f746561736572322e706e67)](https://camo.githubusercontent.com/cc432cb62ac01cdc374eaaf44a39dcd49ab840e627b5ce68bcfb7895a3db73bf/687474703a2f2f7777772e766973696f6e2e65652e6574687a2e63682f7e67656f72676f75732f696d616765732f7470616d6931375f746561736572322e706e67)

**Joint Material and Illumination Estimation from Photo Sets in the Wild (2017)** [\[Paper\]](https://arxiv.org/pdf/1710.08313.pdf)

[![Image 941](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Joint%20Material%20and%20Illumination%20Estimation%20from%20Photo%20Sets%20in%20the%20Wild.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Joint%20Material%20and%20Illumination%20Estimation%20from%20Photo%20Sets%20in%20the%20Wild.jpeg)

**JWhat Is Around The Camera? (2017)** [\[Paper\]](https://arxiv.org/pdf/1611.09325v2.pdf)

[![Image 942](https://camo.githubusercontent.com/409045af1a321f2d07b0d9f7c54ff144289f8e7241e0c4b8494c79fc683bdc29/68747470733a2f2f686f6d65732e63732e77617368696e67746f6e2e6564752f7e6b72656d617461732f6d795f696d616765732f61727869763136625f7465617365722e6a7067)](https://camo.githubusercontent.com/409045af1a321f2d07b0d9f7c54ff144289f8e7241e0c4b8494c79fc683bdc29/68747470733a2f2f686f6d65732e63732e77617368696e67746f6e2e6564752f7e6b72656d617461732f6d795f696d616765732f61727869763136625f7465617365722e6a7067)

**TextureGAN: Controlling Deep Image Synthesis with Texture Patches (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1706.02823.pdf)

[![Image 943](https://camo.githubusercontent.com/792a9687214d1acea9ed47205b960bf39b15985be96dde1de48a64c4eaa228f0/687474703a2f2f7465787475726567616e2e6579652e6761746563682e6564752f696d672f70617065725f6669677572652e706e67)](https://camo.githubusercontent.com/792a9687214d1acea9ed47205b960bf39b15985be96dde1de48a64c4eaa228f0/687474703a2f2f7465787475726567616e2e6579652e6761746563682e6564752f696d672f70617065725f6669677572652e706e67)

**Gaussian Material Synthesis (2018 SIGGRAPH)** [\[Paper\]](https://users.cg.tuwien.ac.at/zsolnai/gfx/gaussian-material-synthesis/)

[![Image 944](https://camo.githubusercontent.com/16216dd14aba1dde2495f622011da6af7e1ac38219b584907a344401bb02e898/68747470733a2f2f692e7974696d672e636f6d2f76692f564d327973436e443947412f6d617872657364656661756c742e6a7067)](https://camo.githubusercontent.com/16216dd14aba1dde2495f622011da6af7e1ac38219b584907a344401bb02e898/68747470733a2f2f692e7974696d672e636f6d2f76692f564d327973436e443947412f6d617872657364656661756c742e6a7067)

**Non-stationary Texture Synthesis by Adversarial Expansion (2018 SIGGRAPH)** [\[Paper\]](http://vcc.szu.edu.cn/research/2018/TexSyn)

[![Image 945](https://github.com/jessemelpolio/non-stationary_texture_syn/raw/master/imgs/teaser.png)](https://github.com/jessemelpolio/non-stationary_texture_syn/blob/master/imgs/teaser.png)

**Synthesized Texture Quality Assessment via Multi-scale Spatial and Statistical Texture Attributes of Image and Gradient Magnitude Coefficients (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1804.08020.pdf)

[![Image 946](https://user-images.githubusercontent.com/12434910/39275366-e18c7c1c-4899-11e8-8e61-05072618bbce.PNG)](https://user-images.githubusercontent.com/12434910/39275366-e18c7c1c-4899-11e8-8e61-05072618bbce.PNG)

**LIME: Live Intrinsic Material Estimation (2018 CVPR)** [\[Paper\]](https://gvv.mpi-inf.mpg.de/projects/LIME/)

[![Image 947](https://camo.githubusercontent.com/cf4c0a1976425e6ac9886d9ebe6bf4e8eb4e5685ed409b21984102dbe942a2b1/68747470733a2f2f7765622e7374616e666f72642e6564752f7e7a6f6c6c686f65662f7061706572732f4356505231385f4d6174657269616c2f7465617365722e706e67)](https://camo.githubusercontent.com/cf4c0a1976425e6ac9886d9ebe6bf4e8eb4e5685ed409b21984102dbe942a2b1/68747470733a2f2f7765622e7374616e666f72642e6564752f7e7a6f6c6c686f65662f7061706572732f4356505231385f4d6174657269616c2f7465617365722e706e67)

**Single-Image SVBRDF Capture with a Rendering-Aware Deep Network (2018)** [\[Paper\]](https://team.inria.fr/graphdeco/fr/projects/deep-materials/)

[![Image 948](https://camo.githubusercontent.com/ca96db55ab4c063f7bd5bc03dbd6f32e642134842dafa6e9c800e48846bfac16/68747470733a2f2f7465616d2e696e7269612e66722f67726170686465636f2f66696c65732f323031382f30382f7465617365725f76302e706e67)](https://camo.githubusercontent.com/ca96db55ab4c063f7bd5bc03dbd6f32e642134842dafa6e9c800e48846bfac16/68747470733a2f2f7465616d2e696e7269612e66722f67726170686465636f2f66696c65732f323031382f30382f7465617365725f76302e706e67)

**PhotoShape: Photorealistic Materials for Large-Scale Shape Collections (2018)** [\[Paper\]](https://keunhong.com/publications/photoshape/)

[![Image 949](https://camo.githubusercontent.com/601e366f0d69ce2bcf617f7ef821189c7e4d8a323c6a8a4c9781c7fd0d738f69/68747470733a2f2f6b65756e686f6e672e636f6d2f7075626c69636174696f6e732f70686f746f73686170652f7465617365722e6a7067)](https://camo.githubusercontent.com/601e366f0d69ce2bcf617f7ef821189c7e4d8a323c6a8a4c9781c7fd0d738f69/68747470733a2f2f6b65756e686f6e672e636f6d2f7075626c69636174696f6e732f70686f746f73686170652f7465617365722e6a7067)

**Learning Material-Aware Local Descriptors for 3D Shapes (2018)** [\[Paper\]](http://www.vovakim.com/papers/18_3DV_ShapeMatFeat.pdf)

[![Image 950](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Learning%20Material-Aware%20Local%20Descriptors%20for%203D%20Shapes%20(2018).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Learning%20Material-Aware%20Local%20Descriptors%20for%203D%20Shapes%20(2018).jpeg)

**FrankenGAN: Guided Detail Synthesis for Building Mass Models using Style-Synchonized GANs (2018 SIGGRAPH Asia)** [\[Paper\]](http://geometry.cs.ucl.ac.uk/projects/2018/frankengan/)

[![Image 951](https://camo.githubusercontent.com/bb318e5f5eefee6cd7cdb3d77804ecaca6a2c92eea67950b1018f9c120e5fac6/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031382f6672616e6b656e67616e2f70617065725f646f63732f7465617365722e6a7067)](https://camo.githubusercontent.com/bb318e5f5eefee6cd7cdb3d77804ecaca6a2c92eea67950b1018f9c120e5fac6/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031382f6672616e6b656e67616e2f70617065725f646f63732f7465617365722e6a7067)

Style Learning and Transfer
---------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#style-learning-and-transfer)

**Style-Content Separation by Anisotropic Part Scales (2010)** [\[Paper\]](https://www.cs.sfu.ca/~haoz/pubs/xu_siga10_style.pdf)

[![Image 952](https://camo.githubusercontent.com/0790573ee7ca2e895a4a6c5ad7e32f5a171f0b5e5bcd018bae8963a448452bac/68747470733a2f2f73697465732e676f6f676c652e636f6d2f736974652f6b6576696e6b616978752f5f2f727372632f313437323835323132333130362f7075626c69636174696f6e732f7374796c655f622e6a70673f6865696768743d3134352677696474683d343030)](https://camo.githubusercontent.com/0790573ee7ca2e895a4a6c5ad7e32f5a171f0b5e5bcd018bae8963a448452bac/68747470733a2f2f73697465732e676f6f676c652e636f6d2f736974652f6b6576696e6b616978752f5f2f727372632f313437323835323132333130362f7075626c69636174696f6e732f7374796c655f622e6a70673f6865696768743d3134352677696474683d343030)

**Design Preserving Garment Transfer (2012)** [\[Paper\]](https://hal.inria.fr/hal-00695903/file/GarmentTransfer.pdf)

[![Image 953](https://camo.githubusercontent.com/9c2e692c38765fad9d257e9ac77816d5ea5a763d9f223f586f3b0fe87ca516b9/68747470733a2f2f68616c2e696e7269612e66722f68616c2d303036393539303376322f66696c652f30325f576f6d616e546f416c6c2e6a7067)](https://camo.githubusercontent.com/9c2e692c38765fad9d257e9ac77816d5ea5a763d9f223f586f3b0fe87ca516b9/68747470733a2f2f68616c2e696e7269612e66722f68616c2d303036393539303376322f66696c652f30325f576f6d616e546f416c6c2e6a7067)

**Analogy-Driven 3D Style Transfer (2014)** [\[Paper\]](http://www.chongyangma.com/publications/st/index.html)

[![Image 954](https://camo.githubusercontent.com/7a3e4b13f7ffae7ff030f8bc6496ccaf06c583c8979cf984761f3793bce7bc29/687474703a2f2f7777772e63686f6e6779616e676d612e636f6d2f7075626c69636174696f6e732f73742f323031345f73745f7465617365722e706e67)](https://camo.githubusercontent.com/7a3e4b13f7ffae7ff030f8bc6496ccaf06c583c8979cf984761f3793bce7bc29/687474703a2f2f7777772e63686f6e6779616e676d612e636f6d2f7075626c69636174696f6e732f73742f323031345f73745f7465617365722e706e67)

**Elements of Style: Learning Perceptual Shape Style Similarity (2015)** [\[Paper\]](http://people.cs.umass.edu/~zlun/papers/StyleSimilarity/StyleSimilarity.pdf) [\[Code\]](https://github.com/happylun/StyleSimilarity)

[![Image 955](https://camo.githubusercontent.com/53c341dc726cbd08c1d3a70ac74a05f7ed3e6a32a1a567a3b26a89cca99bab12/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e7a6c756e2f7061706572732f5374796c6553696d696c61726974792f5374796c6553696d696c61726974795f7465617365722e6a7067)](https://camo.githubusercontent.com/53c341dc726cbd08c1d3a70ac74a05f7ed3e6a32a1a567a3b26a89cca99bab12/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e7a6c756e2f7061706572732f5374796c6553696d696c61726974792f5374796c6553696d696c61726974795f7465617365722e6a7067)

**Functionality Preserving Shape Style Transfer (2016)** [\[Paper\]](http://people.cs.umass.edu/~zlun/papers/StyleTransfer/StyleTransfer.pdf) [\[Code\]](https://github.com/happylun/StyleTransfer)

[![Image 956](https://camo.githubusercontent.com/db8ba764578d2decfb34e6322218ce1375a4a4ec3b92b92c6cf8bf6a9a86493b/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e7a6c756e2f7061706572732f5374796c655472616e736665722f5374796c655472616e736665725f7465617365722e6a7067)](https://camo.githubusercontent.com/db8ba764578d2decfb34e6322218ce1375a4a4ec3b92b92c6cf8bf6a9a86493b/68747470733a2f2f70656f706c652e63732e756d6173732e6564752f7e7a6c756e2f7061706572732f5374796c655472616e736665722f5374796c655472616e736665725f7465617365722e6a7067)

**Unsupervised Texture Transfer from Images to Model Collections (2016)** [\[Paper\]](http://ai.stanford.edu/~haosu/papers/siga16_texture_transfer_small.pdf)

[![Image 957](https://camo.githubusercontent.com/76dfee87975a5f3200a7bd0f921c7bbbab95b94c7d63d1f31bf9cd1cb7ff0dfb/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031362f746578747572655f7472616e736665722f70617065725f646f63732f7465617365722e706e67)](https://camo.githubusercontent.com/76dfee87975a5f3200a7bd0f921c7bbbab95b94c7d63d1f31bf9cd1cb7ff0dfb/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031362f746578747572655f7472616e736665722f70617065725f646f63732f7465617365722e706e67)

**Learning Detail Transfer based on Geometric Features (2017)** [\[Paper\]](http://surfacedetails.cs.princeton.edu/)

[![Image 958](https://camo.githubusercontent.com/f9f78b5dac97f94a5f6861b634e056da9aadef64faebbfdde89bd3855a867e28/687474703a2f2f7375726661636564657461696c732e63732e7072696e6365746f6e2e6564752f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/f9f78b5dac97f94a5f6861b634e056da9aadef64faebbfdde89bd3855a867e28/687474703a2f2f7375726661636564657461696c732e63732e7072696e6365746f6e2e6564752f696d616765732f7465617365722e706e67)

**Co-Locating Style-Defining Elements on 3D Shapes (2017)** [\[Paper\]](http://people.scs.carleton.ca/~olivervankaick/pubs/style_elem.pdf)

[![Image 959](https://camo.githubusercontent.com/53840bb816d9a6664b312680dfc6d4c684c9a0964113a946d409521448d77454/687474703a2f2f73323031372e73696767726170682e6f72672f73697465732f64656661756c742f66696c65732f7374796c65732f6c617267652f7075626c69632f696d616765732f6576656e74732f633131382d653130302d7075626c6963696d6167655f302d69746f6b3d794f384f6567514f2e706e67)](https://camo.githubusercontent.com/53840bb816d9a6664b312680dfc6d4c684c9a0964113a946d409521448d77454/687474703a2f2f73323031372e73696767726170682e6f72672f73697465732f64656661756c742f66696c65732f7374796c65732f6c617267652f7075626c69632f696d616765732f6576656e74732f633131382d653130302d7075626c6963696d6167655f302d69746f6b3d794f384f6567514f2e706e67)

**Neural 3D Mesh Renderer (2017)** [\[Paper\]](http://hiroharu-kato.com/projects_en/neural_renderer.html) [\[Code\]](https://github.com/hiroharu-kato/neural_renderer.git)

[![Image 960](https://camo.githubusercontent.com/00def3ec3d1b280c8da122a7c31979cb333c59e0bc0ed6c6f808ac177301e619/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f4450536d2d3448576b414170455a642e6a7067)](https://camo.githubusercontent.com/00def3ec3d1b280c8da122a7c31979cb333c59e0bc0ed6c6f808ac177301e619/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f4450536d2d3448576b414170455a642e6a7067)

**Appearance Modeling via Proxy-to-Image Alignment (2018)** [\[Paper\]](http://vcc.szu.edu.cn/research/2018/AppMod)

[![Image 961](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Appearance%20Modeling%20via%20Proxy-to-Image%20Alignment.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Appearance%20Modeling%20via%20Proxy-to-Image%20Alignment.png)

üíé **Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images (2018)** [\[Paper\]](http://bigvid.fudan.edu.cn/pixel2mesh/)

[![Image 962](https://camo.githubusercontent.com/672834737c7de606ddcd7a1c2671152bc9276281ba8c0a74bebd7255ca24054b/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44614975456e6655304141716573412e6a7067)](https://camo.githubusercontent.com/672834737c7de606ddcd7a1c2671152bc9276281ba8c0a74bebd7255ca24054b/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f44614975456e6655304141716573412e6a7067)

**Automatic Unpaired Shape Deformation Transfer (SIGGRAPH Asia 2018)** [\[Paper\]](http://geometrylearning.com/ausdt/)

[![Image 963](https://camo.githubusercontent.com/dbd2e0650c808ecc44f03b268cb5e2ed46a07360cd94e1545916998b64eab885/687474703a2f2f67656f6d657472796c6561726e696e672e636f6d2f61757364742f696d67732f7465617365722e706e67)](https://camo.githubusercontent.com/dbd2e0650c808ecc44f03b268cb5e2ed46a07360cd94e1545916998b64eab885/687474703a2f2f67656f6d657472796c6561726e696e672e636f6d2f61757364742f696d67732f7465617365722e706e67)

**3DSNet: Unsupervised Shape-to-Shape 3D Style Transfer (2020)** [\[Paper\]](https://arxiv.org/abs/2011.13388) [\[Code\]](https://github.com/ethz-asl/3dsnet)

[![Image 964](https://github.com/ethz-asl/3dsnet/raw/main/docs/chairs.jpg)](https://github.com/ethz-asl/3dsnet/blob/main/docs/chairs.jpg)

Scene Synthesis/Reconstruction
------------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#scene-synthesisreconstruction)

**Make It Home: Automatic Optimization of Furniture Arrangement (2011, SIGGRAPH)** [\[Paper\]](http://people.sutd.edu.sg/~saikit/projects/furniture/index.html)

[![Image 965](https://camo.githubusercontent.com/e306042817e110586a2d252a4879bf65596de36c33b6c68ebfd72eee1f710571/68747470733a2f2f7777772e63732e756d622e6564752f7e637261696779752f696d672f7061706572732f6675726e69747572652e676966)](https://camo.githubusercontent.com/e306042817e110586a2d252a4879bf65596de36c33b6c68ebfd72eee1f710571/68747470733a2f2f7777772e63732e756d622e6564752f7e637261696779752f696d672f7061706572732f6675726e69747572652e676966)

**Interactive Furniture Layout Using Interior Design Guidelines (2011)** [\[Paper\]](http://graphics.stanford.edu/~pmerrell/furnitureLayout.htm)

[![Image 966](https://camo.githubusercontent.com/34885624d6fc04acbbbf930021d077bc52bfb99a87d6da7dabee3bec1b52c4ba/687474703a2f2f7669732e6265726b656c65792e6564752f7061706572732f6675726e69747572654c61796f75742f6675726e69747572654269672e6a7067)](https://camo.githubusercontent.com/34885624d6fc04acbbbf930021d077bc52bfb99a87d6da7dabee3bec1b52c4ba/687474703a2f2f7669732e6265726b656c65792e6564752f7061706572732f6675726e69747572654c61796f75742f6675726e69747572654269672e6a7067)

**Synthesizing Open Worlds with Constraints using Locally Annealed Reversible Jump MCMC (2012)** [\[Paper\]](http://graphics.stanford.edu/~lfyg/owl.pdf)

[![Image 967](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Synthesizing%20Open%20Worlds%20with%20Constraints%20using%20Locally%20Annealed%20Reversible%20Jump%20MCMC%20(2012).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Synthesizing%20Open%20Worlds%20with%20Constraints%20using%20Locally%20Annealed%20Reversible%20Jump%20MCMC%20(2012).jpeg)

**Example-based Synthesis of 3D Object Arrangements (2012 SIGGRAPH Asia)** [\[Paper\]](http://graphics.stanford.edu/projects/scenesynth/)

[![Image 968](https://camo.githubusercontent.com/3f784c17dc09343bdb68e551a823892e2d107136ec54f8b0a363186aa418dec8/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f7363656e6573796e74682f696d672f7465617365722e6a7067)](https://camo.githubusercontent.com/3f784c17dc09343bdb68e551a823892e2d107136ec54f8b0a363186aa418dec8/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f7363656e6573796e74682f696d672f7465617365722e6a7067)

**Sketch2Scene: Sketch-based Co-retrieval and Co-placement of 3D Models (2013)** [\[Paper\]](http://sweb.cityu.edu.hk/hongbofu/projects/sketch2scene_sig13/#.WWWge__ysb0)

[![Image 969](https://camo.githubusercontent.com/8e5556841d95cc167c683b12573950c7d5beaa4f0c97abdf95cb6f08d458fa9b/687474703a2f2f73756e7765696c756e2e6769746875622e696f2f696d616765732f70617065722f736b65746368327363656e655f7468756d622e6a7067)](https://camo.githubusercontent.com/8e5556841d95cc167c683b12573950c7d5beaa4f0c97abdf95cb6f08d458fa9b/687474703a2f2f73756e7765696c756e2e6769746875622e696f2f696d616765732f70617065722f736b65746368327363656e655f7468756d622e6a7067)

**Action-Driven 3D Indoor Scene Evolution (2016)** [\[Paper\]](https://www.cs.sfu.ca/~haoz/pubs/ma_siga16_action.pdf)

[![Image 970](https://camo.githubusercontent.com/5ce781e1ca4943fac76ac352265d9d2f0294d9844a00a1082ea71fc52a2e7c03/68747470733a2f2f6d6172756974782e6769746875622e696f2f70726f6a6563742f61646973652f7465617365722e6a7067)](https://camo.githubusercontent.com/5ce781e1ca4943fac76ac352265d9d2f0294d9844a00a1082ea71fc52a2e7c03/68747470733a2f2f6d6172756974782e6769746875622e696f2f70726f6a6563742f61646973652f7465617365722e6a7067)

**The Clutterpalette: An Interactive Tool for Detailing Indoor Scenes (2015)** [\[Paper\]](https://www.cs.umb.edu/~craigyu/papers/clutterpalette.pdf)

[![Image 971](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/The%20Clutterpalette-%20An%20Interactive%20Tool%20for%20Detailing%20Indoor%20Scenes.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/The%20Clutterpalette-%20An%20Interactive%20Tool%20for%20Detailing%20Indoor%20Scenes.png)

**Image2Scene: Transforming Style of 3D Room (2015)** [\[Paper\]](https://dl.acm.org/doi/abs/10.1145/2733373.2806274)

[![Image 972](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Image2Scene.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Image2Scene.jpg)

**Relationship Templates for Creating Scene Variations (2016)** [\[Paper\]](http://geometry.cs.ucl.ac.uk/projects/2016/relationship-templates/)

[![Image 973](https://camo.githubusercontent.com/1fe060d5158893d8661fc6e4539edbbf5bc390fcc4b86e67f5c7ba415b28341a/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031362f72656c6174696f6e736869702d74656d706c617465732f70617065725f646f63732f7465617365722e706e67)](https://camo.githubusercontent.com/1fe060d5158893d8661fc6e4539edbbf5bc390fcc4b86e67f5c7ba415b28341a/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031362f72656c6174696f6e736869702d74656d706c617465732f70617065725f646f63732f7465617365722e706e67)

**IM2CAD (2017)** [\[Paper\]](http://homes.cs.washington.edu/~izadinia/im2cad.html)

[![Image 974](https://camo.githubusercontent.com/057b57efd8c143d1869456f70536771268f89f5653d0e72a2c06bdce2bac72de/687474703a2f2f692e696d6775722e636f6d2f4b68744f6575422e6a7067)](https://camo.githubusercontent.com/057b57efd8c143d1869456f70536771268f89f5653d0e72a2c06bdce2bac72de/687474703a2f2f692e696d6775722e636f6d2f4b68744f6575422e6a7067)

**Predicting Complete 3D Models of Indoor Scenes (2017)** [\[Paper\]](https://arxiv.org/pdf/1504.02437.pdf)

[![Image 975](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Predicting%20Complete%203D%20Models%20of%20Indoor%20Scenes.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Predicting%20Complete%203D%20Models%20of%20Indoor%20Scenes.png)

**Complete 3D Scene Parsing from Single RGBD Image (2017)** [\[Paper\]](https://arxiv.org/pdf/1710.09490.pdf)

[![Image 976](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Complete%203D%20Scene%20Parsing%20from%20Single%20RGBD%20Image.jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Complete%203D%20Scene%20Parsing%20from%20Single%20RGBD%20Image.jpeg)

**Raster-to-Vector: Revisiting Floorplan Transformation (2017, ICCV)** [\[Paper\]](http://www.cse.wustl.edu/~chenliu/floorplan-transformation.html) [\[Code\]](https://github.com/art-programmer/FloorplanTransformation)

[![Image 977](https://camo.githubusercontent.com/4f62f7f4425e16969781b1ca23d01b1d3b11b7fd7cbdbe03250a05f2d47121ce/68747470733a2f2f7777772e6373652e777573746c2e6564752f7e6368656e6c69752f666c6f6f72706c616e2d7472616e73666f726d6174696f6e2f7465617365722e706e67)](https://camo.githubusercontent.com/4f62f7f4425e16969781b1ca23d01b1d3b11b7fd7cbdbe03250a05f2d47121ce/68747470733a2f2f7777772e6373652e777573746c2e6564752f7e6368656e6c69752f666c6f6f72706c616e2d7472616e73666f726d6174696f6e2f7465617365722e706e67)

**Fully Convolutional Refined Auto-Encoding Generative Adversarial Networks for 3D Multi Object Scenes (2017)** [\[Blog\]](https://becominghuman.ai/3d-multi-object-gan-7b7cee4abf80)

[![Image 978](https://camo.githubusercontent.com/8e302d1afa232471aecf6c6f552f7b9b1d22862f8f91d8b443399823b03df38f/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a4e636b573268666762486845503350385a355a4c6a512e706e67)](https://camo.githubusercontent.com/8e302d1afa232471aecf6c6f552f7b9b1d22862f8f91d8b443399823b03df38f/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a4e636b573268666762486845503350385a355a4c6a512e706e67)

**Adaptive Synthesis of Indoor Scenes via Activity-Associated Object Relation Graphs (2017 SIGGRAPH Asia)** [\[Paper\]](http://arts.buaa.edu.cn/projects/sa17/)

[![Image 979](https://camo.githubusercontent.com/3b710bbb4012f0dd61f95f168e9654e4c9aebe41191cd1d75a0e325f9e2edf8b/68747470733a2f2f7361323031372e73696767726170682e6f72672f696d616765732f6576656e74732f633132312d6534352d7075626c6963696d6167652e6a7067)](https://camo.githubusercontent.com/3b710bbb4012f0dd61f95f168e9654e4c9aebe41191cd1d75a0e325f9e2edf8b/68747470733a2f2f7361323031372e73696767726170682e6f72672f696d616765732f6576656e74732f633132312d6534352d7075626c6963696d6167652e6a7067)

**Automated Interior Design Using a Genetic Algorithm (2017)** [\[Paper\]](https://publik.tuwien.ac.at/files/publik_262718.pdf)

[![Image 980](https://camo.githubusercontent.com/1d1ee9a3f2c11f4ae201e5e5f2c90e08f52579d4d4ce4a13feb0435bce77738e/687474703a2f2f7777772e70657465726b616e2e636f6d2f70696374757265732f746561736572712e6a7067)](https://camo.githubusercontent.com/1d1ee9a3f2c11f4ae201e5e5f2c90e08f52579d4d4ce4a13feb0435bce77738e/687474703a2f2f7777772e70657465726b616e2e636f6d2f70696374757265732f746561736572712e6a7067)

**SceneSuggest: Context-driven 3D Scene Design (2017)** [\[Paper\]](https://arxiv.org/pdf/1703.00061.pdf)

[![Image 981](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/SceneSuggest%20-Context-driven%203D%20Scene%20Design%20(2017).png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SceneSuggest%20-Context-driven%203D%20Scene%20Design%20(2017).png)

**A fully end-to-end deep learning approach for real-time simultaneous 3D reconstruction and material recognition (2017)** [\[Paper\]](https://arxiv.org/pdf/1703.04699v1.pdf)

[![Image 982](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/A%20fully%20end-to-end%20deep%20learning%20approach%20for%20real-time%20simultaneous%203D%20reconstruction%20and%20material%20recognition%20(2017).png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/A%20fully%20end-to-end%20deep%20learning%20approach%20for%20real-time%20simultaneous%203D%20reconstruction%20and%20material%20recognition%20(2017).png)

**Human-centric Indoor Scene Synthesis Using Stochastic Grammar (2018, CVPR)**[\[Paper\]](http://web.cs.ucla.edu/~syqi/publications/cvpr2018synthesis/cvpr2018synthesis.pdf) [\[Supplementary\]](http://web.cs.ucla.edu/~syqi/publications/cvpr2018synthesis/cvpr2018synthesis_supplementary.pdf) [\[Code\]](https://github.com/SiyuanQi/human-centric-scene-synthesis)

[![Image 983](https://camo.githubusercontent.com/5d1095e83a999daadeb298369db199b1814b6511be04b430093f36dcecb2e14e/687474703a2f2f7765622e63732e75636c612e6564752f7e737971692f7075626c69636174696f6e732f7468756d626e61696c732f637670723230313873796e7468657369732e676966)](https://camo.githubusercontent.com/5d1095e83a999daadeb298369db199b1814b6511be04b430093f36dcecb2e14e/687474703a2f2f7765622e63732e75636c612e6564752f7e737971692f7075626c69636174696f6e732f7468756d626e61696c732f637670723230313873796e7468657369732e676966)[](https://camo.githubusercontent.com/5d1095e83a999daadeb298369db199b1814b6511be04b430093f36dcecb2e14e/687474703a2f2f7765622e63732e75636c612e6564752f7e737971692f7075626c69636174696f6e732f7468756d626e61696c732f637670723230313873796e7468657369732e676966)

üì∑üé≤ **FloorNet: A Unified Framework for Floorplan Reconstruction from 3D Scans (2018)** [\[Paper\]](https://arxiv.org/pdf/1804.00090.pdf) [\[Code\]](http://art-programmer.github.io/floornet.html)

[![Image 984](https://camo.githubusercontent.com/a2eab8257f29be51de2c692e37997cd0e14b39d5e230849b5451bc11d42fd89c/687474703a2f2f6172742d70726f6772616d6d65722e6769746875622e696f2f666c6f6f726e65742f7465617365722e706e67)](https://camo.githubusercontent.com/a2eab8257f29be51de2c692e37997cd0e14b39d5e230849b5451bc11d42fd89c/687474703a2f2f6172742d70726f6772616d6d65722e6769746875622e696f2f666c6f6f726e65742f7465617365722e706e67)

üëæ **ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans (2018)** [\[Paper\]](https://arxiv.org/pdf/1712.10215.pdf)

[![Image 985](https://camo.githubusercontent.com/e84f6ec9a934492f562ec0cea35a25823908781759cbb910bad09129fb24aa92/68747470733a2f2f6e696573736e65726c61622e6f72672f7061706572732f323031382f337363616e636f6d706c6574652f7465617365722e6a7067)](https://camo.githubusercontent.com/e84f6ec9a934492f562ec0cea35a25823908781759cbb910bad09129fb24aa92/68747470733a2f2f6e696573736e65726c61622e6f72672f7061706572732f323031382f337363616e636f6d706c6574652f7465617365722e6a7067)

**Deep Convolutional Priors for Indoor Scene Synthesis (2018)** [\[Paper\]](https://kwang-ether.github.io/pdf/deepsynth.pdf)

[![Image 986](https://camo.githubusercontent.com/b69a9c5cca5f0804732ebc7367c22d40ce395586512774fc2e975c09537f0aa5/687474703a2f2f6d73617676612e6769746875622e696f2f66696c65732f6465657073796e74682e706e67)](https://camo.githubusercontent.com/b69a9c5cca5f0804732ebc7367c22d40ce395586512774fc2e975c09537f0aa5/687474703a2f2f6d73617676612e6769746875622e696f2f66696c65732f6465657073796e74682e706e67)

üì∑ **Fast and Flexible Indoor scene synthesis via Deep Convolutional Generative Models (2018)** [\[Paper\]](https://arxiv.org/pdf/1811.12463.pdf) [\[Code\]](https://github.com/brownvc/fast-synth)

[![Image 987](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Fast%20and%20Flexible%20Indoor%20scene%20synthesis%20via%20Deep%20Convolutional%20Generative%20Models.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Fast%20and%20Flexible%20Indoor%20scene%20synthesis%20via%20Deep%20Convolutional%20Generative%20Models.jpg)

**Configurable 3D Scene Synthesis and 2D Image Rendering with Per-Pixel Ground Truth using Stochastic Grammars (2018)** [\[Paper\]](https://arxiv.org/pdf/1704.00112.pdf)

[![Image 988](https://camo.githubusercontent.com/f642f9754e4a08c528106bd2b747175a8c8341aadc8da867db705badf4d75c4d/68747470733a2f2f6d656469612e737072696e6765726e61747572652e636f6d2f6f726967696e616c2f737072696e6765722d7374617469632f696d6167652f61727425334131302e313030372532467331313236332d3031382d313130332d352f4d656469614f626a656374732f31313236335f323031385f313130335f466967355f48544d4c2e6a7067)](https://camo.githubusercontent.com/f642f9754e4a08c528106bd2b747175a8c8341aadc8da867db705badf4d75c4d/68747470733a2f2f6d656469612e737072696e6765726e61747572652e636f6d2f6f726967696e616c2f737072696e6765722d7374617469632f696d6167652f61727425334131302e313030372532467331313236332d3031382d313130332d352f4d656469614f626a656374732f31313236335f323031385f313130335f466967355f48544d4c2e6a7067)

**Holistic 3D Scene Parsing and Reconstruction from a Single RGB Image (ECCV 2018)** [\[Paper\]](http://siyuanhuang.com/holistic_parsing/main.html)

[![Image 989](https://camo.githubusercontent.com/88a007b9f3982d77d574cf0c0f7f9f8a50d3bf8694cd77f018c12d0faf1ff6ef/687474703a2f2f7765622e63732e75636c612e6564752f7e737971692f7075626c69636174696f6e732f7468756d626e61696c732f65636376323031387363656e652e706e67)](https://camo.githubusercontent.com/88a007b9f3982d77d574cf0c0f7f9f8a50d3bf8694cd77f018c12d0faf1ff6ef/687474703a2f2f7765622e63732e75636c612e6564752f7e737971692f7075626c69636174696f6e732f7468756d626e61696c732f65636376323031387363656e652e706e67)

**Language-Driven Synthesis of 3D Scenes from Scene Databases (SIGGRAPH Asia 2018)** [\[Paper\]](http://www.sfu.ca/~agadipat/publications/2018/T2S/project_page.html)

[![Image 990](https://camo.githubusercontent.com/54e0b32f1bfb8eef205414e63b7b6a5656e03c047830257f0958cc00fc3746a9/687474703a2f2f7777772e7366752e63612f7e61676164697061742f7075626c69636174696f6e732f323031382f5432532f7465617365722e706e67)](https://camo.githubusercontent.com/54e0b32f1bfb8eef205414e63b7b6a5656e03c047830257f0958cc00fc3746a9/687474703a2f2f7777772e7366752e63612f7e61676164697061742f7075626c69636174696f6e732f323031382f5432532f7465617365722e706e67)

**Deep Generative Modeling for Scene Synthesis via Hybrid Representations (2018)** [\[Paper\]](https://arxiv.org/pdf/1808.02084.pdf)

[![Image 991](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Deep%20Generative%20Modeling%20for%20Scene%20Synthesis%20via%20Hybrid%20Representations%20(2018).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Deep%20Generative%20Modeling%20for%20Scene%20Synthesis%20via%20Hybrid%20Representations%20(2018).jpeg)

**GRAINS: Generative Recursive Autoencoders for INdoor Scenes (2018)** [\[Paper\]](https://arxiv.org/pdf/1807.09193.pdf)

[![Image 992](https://camo.githubusercontent.com/ee40c8a76b796ec4193dcd00e0ceac3702d2518c43ff6b54dcb8ded8cdcc3b24/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f3337333530332f6e65775f706963732f7465617365726669672e6a70672e37353078305f7137355f63726f702e6a7067)](https://camo.githubusercontent.com/ee40c8a76b796ec4193dcd00e0ceac3702d2518c43ff6b54dcb8ded8cdcc3b24/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f3337333530332f6e65775f706963732f7465617365726669672e6a70672e37353078305f7137355f63726f702e6a7067)

**SEETHROUGH: Finding Objects in Heavily Occluded Indoor Scene Images (2018)** [\[Paper\]](http://www.vovakim.com/papers/18_3DVOral_SeeThrough.pdf)

[![Image 993](https://camo.githubusercontent.com/fb739cb08fade13b578538757126ae42254a656c275c955d8eac6bd196ae5e3d/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031382f7365657468726f7567682f70617065725f646f63732f726573756c745f706c6174652e706e67)](https://camo.githubusercontent.com/fb739cb08fade13b578538757126ae42254a656c275c955d8eac6bd196ae5e3d/687474703a2f2f67656f6d657472792e63732e75636c2e61632e756b2f70726f6a656374732f323031382f7365657468726f7567682f70617065725f646f63732f726573756c745f706c6174652e706e67)

**üëæ Scan2CAD: Learning CAD Model Alignment in RGB-D Scans (CVPR 2019)** [\[Paper\]](https://arxiv.org/pdf/1811.11187.pdf) [\[Code\]](https://github.com/skanti/Scan2CAD)

[![Image 994](https://camo.githubusercontent.com/b7d11d5427d093a903759ab66644d6031fd2f3f1504d7e3a05c336d4700c5e6f/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f357363616e326361642f7465617365722e6a7067)](https://camo.githubusercontent.com/b7d11d5427d093a903759ab66644d6031fd2f3f1504d7e3a05c336d4700c5e6f/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f357363616e326361642f7465617365722e6a7067)

**üíé Scan2Mesh: From Unstructured Range Scans to 3D Meshes (CVPR 2019)** [\[Paper\]](https://arxiv.org/pdf/1811.10464.pdf)

[![Image 995](https://camo.githubusercontent.com/9c5e3df857c8d05fae60e95a3b6313f68cdee0dc68dea5a738594ec4a8c2c5f1/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f347363616e326d6573682f7465617365722e6a7067)](https://camo.githubusercontent.com/9c5e3df857c8d05fae60e95a3b6313f68cdee0dc68dea5a738594ec4a8c2c5f1/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f347363616e326d6573682f7465617365722e6a7067)

**üëæ 3D-SIC: 3D Semantic Instance Completion for RGB-D Scans (arXiv 2019)** [\[Paper\]](https://arxiv.org/pdf/1904.12012.pdf)

[![Image 996](https://camo.githubusercontent.com/724250ed0c0ad817361e376a3ab179e6219f7c7bbc9d14b5eb12748f49c3580b/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f7a317369632f7465617365722e6a7067)](https://camo.githubusercontent.com/724250ed0c0ad817361e376a3ab179e6219f7c7bbc9d14b5eb12748f49c3580b/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f7a317369632f7465617365722e6a7067)

**üëæ End-to-End CAD Model Retrieval and 9DoF Alignment in 3D Scans (arXiv 2019)** [\[Paper\]](https://arxiv.org/abs/1906.04201)

[![Image 997](https://camo.githubusercontent.com/c51fde011585312c10b7c44aa32649172c0041f53fdca05466fca762082bcb05/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f7a32656e6432656e642f7465617365722e6a7067)](https://camo.githubusercontent.com/c51fde011585312c10b7c44aa32649172c0041f53fdca05466fca762082bcb05/687474703a2f2f7777772e6e696573736e65726c61622e6f72672f7061706572732f323031392f7a32656e6432656e642f7465617365722e6a7067)

**A Survey of 3D Indoor Scene Synthesis (2020)** [\[Paper\]](https://www.researchgate.net/profile/Shao_Kui_Zhang/publication/333135099_A_Survey_of_3D_Indoor_Scene_Synthesis/links/5ce13a5492851c4eabad4de0/A-Survey-of-3D-Indoor-Scene-Synthesis.pdf)

[![Image 998](https://github.com/julyrashchenko/3D-Machine-Learning/raw/master/imgs/A%20Survey%20of%203D%20Indoor%20Scene%20Synthesis.jpg)](https://github.com/julyrashchenko/3D-Machine-Learning/blob/master/imgs/A%20Survey%20of%203D%20Indoor%20Scene%20Synthesis.jpg)

**üíä üì∑ PlanIT: Planning and Instantiating Indoor Scenes with Relation Graph and Spatial Prior Networks (2019)** [\[Paper\]](https://kwang-ether.github.io/pdf/planit.pdf) [\[Code\]](https://github.com/brownvc/planit)

[![Image 999](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/PlanIT.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/PlanIT.jpg)

**üëæ Feature-metric Registration: A Fast Semi-Supervised Approach for Robust Point Cloud Registration without Correspondences (CVPR 2020)** [\[Paper\]](https://arxiv.org/abs/2005.01014)[\[Code\]](https://github.com/XiaoshuiHuang/fmr)

[![Image 1000](https://github.com/XiaoshuiHuang/xiaoshuihuang.github.io/raw/master/research/2020-feature-metric.png?raw=true)](https://github.com/XiaoshuiHuang/xiaoshuihuang.github.io/blob/master/research/2020-feature-metric.png?raw=true)

**üíä Human-centric metrics for indoor scene assessment and synthesis (2020)** [\[Paper\]](https://github.com/timzhang642/3D-Machine-Learning/blob/master/sciencedirect.com/science/article/abs/pii/S1524070320300175)

[![Image 1001](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Human-centric%20metrics%20for%20indoor%20scene%20assessment%20and%20synthesis.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Human-centric%20metrics%20for%20indoor%20scene%20assessment%20and%20synthesis.jpg)

**SceneCAD: Predicting Object Alignments and Layouts in RGB-D Scans (2020)** [\[Paper\]](https://arxiv.org/pdf/2003.12622.pdf)

[![Image 1002](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/SceneCAD.jpg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/SceneCAD.jpg)

Scene Understanding (Another more detailed [repository](https://github.com/bertjiazheng/awesome-scene-understanding))
---------------------------------------------------------------------------------------------------------------------

[](https://github.com/timzhang642/3D-Machine-Learning?screenshot=true#scene-understanding-another-more-detailed-repository)

**Recovering the Spatial Layout of Cluttered Rooms (2009)** [\[Paper\]](http://dhoiem.cs.illinois.edu/publications/iccv2009_hedau_indoor.pdf)

[![Image 1003](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Recovering%20the%20Spatial%20Layout%20of%20Cluttered%20Rooms.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Recovering%20the%20Spatial%20Layout%20of%20Cluttered%20Rooms.png)

**Characterizing Structural Relationships in Scenes Using Graph Kernels (2011 SIGGRAPH)** [\[Paper\]](https://graphics.stanford.edu/~mdfisher/graphKernel.html)

[![Image 1004](https://camo.githubusercontent.com/65547feae9ce9641937731a8f60e2102f4dd67cba5b26d718d86edd3852178bd/68747470733a2f2f67726170686963732e7374616e666f72642e6564752f7e6d646669736865722f7061706572732f67726170684b65726e656c5465617365722e706e67)](https://camo.githubusercontent.com/65547feae9ce9641937731a8f60e2102f4dd67cba5b26d718d86edd3852178bd/68747470733a2f2f67726170686963732e7374616e666f72642e6564752f7e6d646669736865722f7061706572732f67726170684b65726e656c5465617365722e706e67)

**Understanding Indoor Scenes Using 3D Geometric Phrases (2013)** [\[Paper\]](http://cvgl.stanford.edu/projects/3dgp/)

[![Image 1005](https://camo.githubusercontent.com/c8db675124e215816cc0587491cec22bf02dadfe6840548ad20622a1caa317ed/687474703a2f2f6376676c2e7374616e666f72642e6564752f70726f6a656374732f336467702f696d616765732f7469746c652e706e67)](https://camo.githubusercontent.com/c8db675124e215816cc0587491cec22bf02dadfe6840548ad20622a1caa317ed/687474703a2f2f6376676c2e7374616e666f72642e6564752f70726f6a656374732f336467702f696d616765732f7469746c652e706e67)

**Organizing Heterogeneous Scene Collections through Contextual Focal Points (2014 SIGGRAPH)** [\[Paper\]](http://kevinkaixu.net/projects/focal.html)

[![Image 1006](https://camo.githubusercontent.com/508297cbbc91f1ee1c30ac1f62b483003c2e46ee9ae87ee8dd4782ed6d084586/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f666f63616c2f6f7665726c617070696e675f636c7573746572732e6a7067)](https://camo.githubusercontent.com/508297cbbc91f1ee1c30ac1f62b483003c2e46ee9ae87ee8dd4782ed6d084586/687474703a2f2f6b6576696e6b616978752e6e65742f70726f6a656374732f666f63616c2f6f7665726c617070696e675f636c7573746572732e6a7067)

**SceneGrok: Inferring Action Maps in 3D Environments (2014, SIGGRAPH)** [\[Paper\]](http://graphics.stanford.edu/projects/scenegrok/)

[![Image 1007](https://camo.githubusercontent.com/2af4b73416e6dbc3ca0b122470569fed7efe2dc222b68a9c3f3c15425bae5130/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f7363656e6567726f6b2f7363656e6567726f6b2e706e67)](https://camo.githubusercontent.com/2af4b73416e6dbc3ca0b122470569fed7efe2dc222b68a9c3f3c15425bae5130/687474703a2f2f67726170686963732e7374616e666f72642e6564752f70726f6a656374732f7363656e6567726f6b2f7363656e6567726f6b2e706e67)

**PanoContext: A Whole-room 3D Context Model for Panoramic Scene Understanding (2014)** [\[Paper\]](http://panocontext.cs.princeton.edu/)

[![Image 1008](https://camo.githubusercontent.com/70ebcfcd2aaf989ef3a3b260b59edf47cdbcb991ecd53e016cba1d4cb29108c2/687474703a2f2f70616e6f636f6e746578742e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)](https://camo.githubusercontent.com/70ebcfcd2aaf989ef3a3b260b59edf47cdbcb991ecd53e016cba1d4cb29108c2/687474703a2f2f70616e6f636f6e746578742e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)

**Learning Informative Edge Maps for Indoor Scene Layout Prediction (2015)** [\[Paper\]](http://slazebni.cs.illinois.edu/publications/iccv15_informative.pdf)

[![Image 1009](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Learning%20Informative%20Edge%20Maps%20for%20Indoor%20Scene%20Layout%20Prediction.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Learning%20Informative%20Edge%20Maps%20for%20Indoor%20Scene%20Layout%20Prediction.png)

**Rent3D: Floor-Plan Priors for Monocular Layout Estimation (2015)** [\[Paper\]](http://www.cs.toronto.edu/~fidler/projects/rent3D.html)

[![Image 1010](https://camo.githubusercontent.com/4b47b0fcce7cceb7fa7f860289dae092ec0eb900485c3e879cfd3c6ed6b2097e/687474703a2f2f7777772e63732e746f726f6e746f2e6564752f7e6669646c65722f70726f6a656374732f6c61796f75742d7265732e6a7067)](https://camo.githubusercontent.com/4b47b0fcce7cceb7fa7f860289dae092ec0eb900485c3e879cfd3c6ed6b2097e/687474703a2f2f7777772e63732e746f726f6e746f2e6564752f7e6669646c65722f70726f6a656374732f6c61796f75742d7265732e6a7067)

**A Coarse-to-Fine Indoor Layout Estimation (CFILE) Method (2016)** [\[Paper\]](https://pdfs.semanticscholar.org/7024/a92186b81e6133dc779f497d06877b48d82b.pdf?_ga=2.54181869.497995160.1510977308-665742395.1510465328)

[![Image 1011](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/A%20Coarse-to-Fine%20Indoor%20Layout%20Estimation%20(CFILE)%20Method%20(2016).png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/A%20Coarse-to-Fine%20Indoor%20Layout%20Estimation%20(CFILE)%20Method%20(2016).png)

**DeLay: Robust Spatial Layout Estimation for Cluttered Indoor Scenes (2016)** [\[Paper\]](http://deeplayout.stanford.edu/)

[![Image 1012](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/DeLay-Robust%20Spatial%20Layout%20Estimation%20for%20Cluttered%20Indoor%20Scenes.png)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/DeLay-Robust%20Spatial%20Layout%20Estimation%20for%20Cluttered%20Indoor%20Scenes.png)

**3D Semantic Parsing of Large-Scale Indoor Spaces (2016)** [\[Paper\]](http://buildingparser.stanford.edu/method.html) [\[Code\]](https://github.com/alexsax/2D-3D-Semantics)

[![Image 1013](https://camo.githubusercontent.com/e9ba6c0fbbec511c817d2639eece41378fd41c207cc882d67e9ecb93f152cc30/687474703a2f2f6275696c64696e677061727365722e7374616e666f72642e6564752f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/e9ba6c0fbbec511c817d2639eece41378fd41c207cc882d67e9ecb93f152cc30/687474703a2f2f6275696c64696e677061727365722e7374616e666f72642e6564752f696d616765732f7465617365722e706e67)

**Single Image 3D Interpreter Network (2016)** [\[Paper\]](http://3dinterpreter.csail.mit.edu/) [\[Code\]](https://github.com/jiajunwu/3dinn)

[![Image 1014](https://camo.githubusercontent.com/ac7adb920d018af49df068998825c3eaf38af88ed27da534bb8c1740e17e7c06/687474703a2f2f3364696e7465727072657465722e637361696c2e6d69742e6564752f696d616765732f73706f746c696768745f3364696e6e5f6c617267652e6a7067)](https://camo.githubusercontent.com/ac7adb920d018af49df068998825c3eaf38af88ed27da534bb8c1740e17e7c06/687474703a2f2f3364696e7465727072657465722e637361696c2e6d69742e6564752f696d616765732f73706f746c696768745f3364696e6e5f6c617267652e6a7067)

**Deep Multi-Modal Image Correspondence Learning (2016)** [\[Paper\]](http://www.cse.wustl.edu/~chenliu/floorplan-matching.html)

[![Image 1015](https://camo.githubusercontent.com/e636e03bbe272f4d52e15a4eeea6653366a2d6939f48ca6ba3f4adf457e7120d/687474703a2f2f6172742d70726f6772616d6d65722e6769746875622e696f2f666c6f6f72706c616e2d6d61746368696e672f7465617365722e706e67)](https://camo.githubusercontent.com/e636e03bbe272f4d52e15a4eeea6653366a2d6939f48ca6ba3f4adf457e7120d/687474703a2f2f6172742d70726f6772616d6d65722e6769746875622e696f2f666c6f6f72706c616e2d6d61746368696e672f7465617365722e706e67)

**Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks (2017)** [\[Paper\]](http://3dvision.princeton.edu/projects/2016/PBRS/) [\[Code\]](https://github.com/yindaz/pbrs) [\[Code\]](https://github.com/yindaz/surface_normal) [\[Code\]](https://github.com/fyu/dilation) [\[Code\]](https://github.com/s9xie/hed)

[![Image 1016](https://camo.githubusercontent.com/ed3df0fc890f163bb593a3510fe1d729da179c3e7696a136c9920ee22c321143/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f43305945524a4f584541413639784e2e6a7067)](https://camo.githubusercontent.com/ed3df0fc890f163bb593a3510fe1d729da179c3e7696a136c9920ee22c321143/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f43305945524a4f584541413639784e2e6a7067)

**RoomNet: End-to-End Room Layout Estimation (2017)** [\[Paper\]](https://arxiv.org/pdf/1703.06241.pdf)

[![Image 1017](https://camo.githubusercontent.com/df47a9907c7f5306b8cd66059f0c80e3369212c6eef93d0d3844eb614a4b4059/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f43375a3239477356304141534576522e6a7067)](https://camo.githubusercontent.com/df47a9907c7f5306b8cd66059f0c80e3369212c6eef93d0d3844eb614a4b4059/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f43375a3239477356304141534576522e6a7067)

**SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite (2017)** [\[Paper\]](http://rgbd.cs.princeton.edu/)

[![Image 1018](https://camo.githubusercontent.com/cb4c8cea1a87fb04141c98586da402e8b4348898e58eae0de715ffc0ae32951f/687474703a2f2f726762642e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)](https://camo.githubusercontent.com/cb4c8cea1a87fb04141c98586da402e8b4348898e58eae0de715ffc0ae32951f/687474703a2f2f726762642e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)

**Semantic Scene Completion from a Single Depth Image (2017)** [\[Paper\]](http://sscnet.cs.princeton.edu/) [\[Code\]](https://github.com/shurans/sscnet)

[![Image 1019](https://camo.githubusercontent.com/e8e10cc00ceed49f1c5926280150bcb92f4c9829d5c59aafe17b654827450f1d/687474703a2f2f7373636e65742e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)](https://camo.githubusercontent.com/e8e10cc00ceed49f1c5926280150bcb92f4c9829d5c59aafe17b654827450f1d/687474703a2f2f7373636e65742e63732e7072696e6365746f6e2e6564752f7465617365722e6a7067)

**Factoring Shape, Pose, and Layout from the 2D Image of a 3D Scene (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1712.01812.pdf) [\[Code\]](https://shubhtuls.github.io/factored3d/)

[![Image 1020](https://camo.githubusercontent.com/e8ed5d60d44fd07aa79d300192d76e882107d5ad4a5f8a70ea0e0d333b8f3e75/68747470733a2f2f736875626874756c732e6769746875622e696f2f666163746f72656433642f7265736f75726365732f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/e8ed5d60d44fd07aa79d300192d76e882107d5ad4a5f8a70ea0e0d333b8f3e75/68747470733a2f2f736875626874756c732e6769746875622e696f2f666163746f72656433642f7265736f75726365732f696d616765732f7465617365722e706e67)

**LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image (2018 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1803.08999.pdf) [\[Code\]](https://github.com/zouchuhang/LayoutNet)

[![Image 1021](https://camo.githubusercontent.com/55c88798e6985f18480410af9620dfb4658e4344d3eab85a14098770c20f76df/687474703a2f2f70302e6966656e67696d672e636f6d2f706d6f702f323031382f303430342f413144304341453438313330433931384645363234464136303439354632333743363731373246365f73697a6536335f773739375f683735352e6a706567)](https://camo.githubusercontent.com/55c88798e6985f18480410af9620dfb4658e4344d3eab85a14098770c20f76df/687474703a2f2f70302e6966656e67696d672e636f6d2f706d6f702f323031382f303430342f413144304341453438313330433931384645363234464136303439354632333743363731373246365f73697a6536335f773739375f683735352e6a706567)

**PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image (2018 CVPR)** [\[Paper\]](http://art-programmer.github.io/planenet/paper.pdf) [\[Code\]](http://art-programmer.github.io/planenet.html)

[![Image 1022](https://camo.githubusercontent.com/4cca9e0cd7c33bfd2ef26a20a9a2b41e094febcf467e9f127b3e63f085c35efa/687474703a2f2f6172742d70726f6772616d6d65722e6769746875622e696f2f696d616765732f706c616e656e65742e706e67)](https://camo.githubusercontent.com/4cca9e0cd7c33bfd2ef26a20a9a2b41e094febcf467e9f127b3e63f085c35efa/687474703a2f2f6172742d70726f6772616d6d65722e6769746875622e696f2f696d616765732f706c616e656e65742e706e67)

**Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic Imagery (2018 CVPR)** [\[Paper\]](http://web.cs.ucdavis.edu/~yjlee/projects/cvpr2018.pdf)

[![Image 1023](https://camo.githubusercontent.com/f32ca950e14368a6536b576e9dcdfb8290d2cb82ec00bd5b20291ca72c0a8c00/68747470733a2f2f6a61736f6e3731382e6769746875622e696f2f70726f6a6563742f6376707231382f66696c65732f636f6e636570745f7069632e706e67)](https://camo.githubusercontent.com/f32ca950e14368a6536b576e9dcdfb8290d2cb82ec00bd5b20291ca72c0a8c00/68747470733a2f2f6a61736f6e3731382e6769746875622e696f2f70726f6a6563742f6376707231382f66696c65732f636f6e636570745f7069632e706e67)

**Pano2CAD: Room Layout From A Single Panorama Image (2018 CVPR)** [\[Paper\]](http://bjornstenger.github.io/papers/xu_wacv2017.pdf)

[![Image 1024](https://camo.githubusercontent.com/11d8f4af4c39e216c60ca1a8677227109688e3638295b4b8d3359c9c39fd6f49/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f35383932342f666967757265732f436f6d706172655f32622e706e67)](https://camo.githubusercontent.com/11d8f4af4c39e216c60ca1a8677227109688e3638295b4b8d3359c9c39fd6f49/68747470733a2f2f7777772e67726f756e6461692e636f6d2f6d656469612f61727869765f70726f6a656374732f35383932342f666967757265732f436f6d706172655f32622e706e67)

**Automatic 3D Indoor Scene Modeling from Single Panorama (2018 CVPR)** [\[Paper\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_Automatic_3D_Indoor_CVPR_2018_paper.pdf)

[![Image 1025](https://github.com/timzhang642/3D-Machine-Learning/raw/master/imgs/Automatic%203D%20Indoor%20Scene%20Modeling%20from%20Single%20Panorama%20(2018%20CVPR).jpeg)](https://github.com/timzhang642/3D-Machine-Learning/blob/master/imgs/Automatic%203D%20Indoor%20Scene%20Modeling%20from%20Single%20Panorama%20(2018%20CVPR).jpeg)

**Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding (2019 CVPR)** [\[Paper\]](https://arxiv.org/pdf/1902.09777.pdf) [\[Code\]](https://github.com/svip-lab/PlanarReconstruction)

[![Image 1026](https://github.com/svip-lab/PlanarReconstruction/raw/master/misc/pipeline.jpg)](https://github.com/svip-lab/PlanarReconstruction/blob/master/misc/pipeline.jpg)

**3D-Aware Scene Manipulation via Inverse Graphics (NeurIPS 2018)** [\[Paper\]](http://3dsdn.csail.mit.edu/) [\[Code\]](https://github.com/svip-lab/PlanarReconstruction)

[![Image 1027](https://camo.githubusercontent.com/3f69b73e87206d89f9a6182a7795682f81895b36fb52bc8d897427ffed912dfe/687474703a2f2f336473646e2e637361696c2e6d69742e6564752f696d616765732f7465617365722e706e67)](https://camo.githubusercontent.com/3f69b73e87206d89f9a6182a7795682f81895b36fb52bc8d897427ffed912dfe/687474703a2f2f336473646e2e637361696c2e6d69742e6564752f696d616765732f7465617365722e706e67)

üíé **3D Scene Reconstruction with Multi-layer Depth and Epipolar Transformers (ICCV 2019)** [\[Paper\]](https://research.dshin.org/iccv19/multi-layer-depth/)

[![Image 1028](https://camo.githubusercontent.com/9de1738b7762b1fde7f941fe3e3117a50b0c6d5b51e68f4420870609e882486e/68747470733a2f2f72657365617263682e647368696e2e6f72672f6963637631392f6d756c74692d6c617965722d64657074682f666967757265732f6f766572766965775f312e706e67)](https://camo.githubusercontent.com/9de1738b7762b1fde7f941fe3e3117a50b0c6d5b51e68f4420870609e882486e/68747470733a2f2f72657365617263682e647368696e2e6f72672f6963637631392f6d756c74692d6c617965722d64657074682f666967757265732f6f766572766965775f312e706e67)  
[![Image 1029](https://camo.githubusercontent.com/7306f1ca080bedf6c8279bbf402ec898fba330713bde672aa6f2e8122e38f0e8/68747470733a2f2f72657365617263682e647368696e2e6f72672f6963637631392f6d756c74692d6c617965722d64657074682f666967757265732f766f78656c697a6174696f6e30302e6a7067)](https://camo.githubusercontent.com/7306f1ca080bedf6c8279bbf402ec898fba330713bde672aa6f2e8122e38f0e8/68747470733a2f2f72657365617263682e647368696e2e6f72672f6963637631392f6d756c74692d6c617965722d64657074682f666967757265732f766f78656c697a6174696f6e30302e6a7067)

**PerspectiveNet: 3D Object Detection from a Single RGB Image via Perspective Points (NIPS 2019)** [\[Paper\]](https://papers.nips.cc/paper/9093-perspectivenet-3d-object-detection-from-a-single-rgb-image-via-perspective-points.pdf)

[![Image 1030](https://camo.githubusercontent.com/f58a36464390a862333ad2c13eb7591d1eb242121a261c7196c4aa617dcc7d51/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f67726f756e6461692d7765622d70726f642f6d656469612f75736572732f757365725f3238383033362f70726f6a6563745f3430323335382f696d616765732f78312e706e67)](https://camo.githubusercontent.com/f58a36464390a862333ad2c13eb7591d1eb242121a261c7196c4aa617dcc7d51/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f67726f756e6461692d7765622d70726f642f6d656469612f75736572732f757365725f3238383033362f70726f6a6563745f3430323335382f696d616765732f78312e706e67)

**Holistic++ Scene Understanding: Single-view 3D Holistic Scene Parsing and Human Pose Estimation with Human-Object Interaction and Physical Commonsense (ICCV 2019)** [\[Paper & Code\]](https://github.com/yixchen/holistic_scene_human)

[![Image 1031](https://camo.githubusercontent.com/aac80e706c9f75e4c2d4deb370272abff4a2607581692f661f1bd2a1d6091622/68747470733a2f2f7969786368656e2e6769746875622e696f2f686f6c697374696370702f66696c652f70672e706e67)](https://camo.githubusercontent.com/aac80e706c9f75e4c2d4deb370272abff4a2607581692f661f1bd2a1d6091622/68747470733a2f2f7969786368656e2e6769746875622e696f2f686f6c697374696370702f66696c652f70672e706e67)