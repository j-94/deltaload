---
title: LM Studio - Discover, download, and run local LLMs
description: Run Llama, Mistral, Phi-3 locally on your computer.
url: https://lmstudio.ai/
timestamp: 2025-01-20T15:45:30.088Z
domain: lmstudio.ai
path: root
---

# LM Studio - Discover, download, and run local LLMs


Run Llama, Mistral, Phi-3 locally on your computer.


## Content

![Image 11: LM Studio](https://lmstudio.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fandroid-chrome-192x192.3a60873f.png&w=384&q=75)LM Studio

Discover, download, and run local LLMs

Run

Supported Architectures Include:

Llama 3.2

Mistral

Phi

Gemma

DeepSeek

Qwen 2.5

on your computer

With LM Studio, you can ...

ðŸ¤– â€¢ Run LLMs on your laptop, entirely offline

ðŸ“š â€¢ Chat with your local documents (new in 0.3)

ðŸ‘¾ â€¢ Use models through the in-app Chat UI or an OpenAI compatible local server

ðŸ“‚ â€¢ Download any compatible model files from Hugging Face ðŸ¤— repositories

ðŸ”­ â€¢ Discover new & noteworthy LLMs right inside the app's Discover page

LM Studio supports any GGUF Llama, Mistral, Phi, Gemma, StarCoder, etc model on Hugging Face

Minimum requirements: M1/M2/M3/M4 Mac, or a Windows / Linux PC with a processor that supports AVX2.

Made possible thanks to the [llama.cpp project.](https://github.com/ggerganov/llama.cpp)

We are expanding our team. See our [careers page](https://lmstudio.ai/careers).

Consult the Technical Documentation at [https://lmstudio.ai/docs](https://lmstudio.ai/docs).

### Frequently Asked Questions[](https://lmstudio.ai/#frequently-asked-questions)

**TLDR:** The app does not collect data or monitor your actions. Your data stays local on your machine. It's free for personal use. For business use, please get in touch.

### Does LM Studio collect any data?[](https://lmstudio.ai/#does-lm-studio-collect-any-data)

**No**. One of the main reasons for using a local LLM is privacy, and LM Studio is designed for that. Your data remains private and local to your machine.

See [Documentation \> Offline Operation](https://lmstudio.ai/docs/offline) for more.

### Can I use LM Studio at work?[](https://lmstudio.ai/#can-i-use-lm-studio-at-work)

We'd love to enable you. Please fill out the [LM Studio @ Work request form](https://docs.google.com/forms/d/e/1FAIpQLSd-zGyQIVlSSqzRyM4YzPEmdNehW3iCd3_X8np5NWCD_1G3BA/viewform?usp=sf_link) and we will get back to you as soon as we can.

### What are the minimum hardware / software requirements?[](https://lmstudio.ai/#what-are-the-minimum-hardware--software-requirements)

Visit the [System Requirements](https://lmstudio.ai/docs/system-requirements) page for the most up to date information.

### Are you hiring?[](https://lmstudio.ai/#are-you-hiring)

See our [careers page](https://lmstudio.ai/careers) for open positions.

## Metadata

```json
{
  "title": "LM Studio - Discover, download, and run local LLMs",
  "description": "Run Llama, Mistral, Phi-3 locally on your computer.",
  "url": "https://lmstudio.ai/",
  "content": "![Image 11: LM Studio](https://lmstudio.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fandroid-chrome-192x192.3a60873f.png&w=384&q=75)LM Studio\n\nDiscover, download, and run local LLMs\n\nRun\n\nSupported Architectures Include:\n\nLlama 3.2\n\nMistral\n\nPhi\n\nGemma\n\nDeepSeek\n\nQwen 2.5\n\non your computer\n\nWith LM Studio, you can ...\n\nðŸ¤– â€¢ Run LLMs on your laptop, entirely offline\n\nðŸ“š â€¢ Chat with your local documents (new in 0.3)\n\nðŸ‘¾ â€¢ Use models through the in-app Chat UI or an OpenAI compatible local server\n\nðŸ“‚ â€¢ Download any compatible model files from Hugging Face ðŸ¤— repositories\n\nðŸ”­ â€¢ Discover new & noteworthy LLMs right inside the app's Discover page\n\nLM Studio supports any GGUF Llama, Mistral, Phi, Gemma, StarCoder, etc model on Hugging Face\n\nMinimum requirements: M1/M2/M3/M4 Mac, or a Windows / Linux PC with a processor that supports AVX2.\n\nMade possible thanks to the [llama.cpp project.](https://github.com/ggerganov/llama.cpp)\n\nWe are expanding our team. See our [careers page](https://lmstudio.ai/careers).\n\nConsult the Technical Documentation at [https://lmstudio.ai/docs](https://lmstudio.ai/docs).\n\n### Frequently Asked Questions[](https://lmstudio.ai/#frequently-asked-questions)\n\n**TLDR:** The app does not collect data or monitor your actions. Your data stays local on your machine. It's free for personal use. For business use, please get in touch.\n\n### Does LM Studio collect any data?[](https://lmstudio.ai/#does-lm-studio-collect-any-data)\n\n**No**. One of the main reasons for using a local LLM is privacy, and LM Studio is designed for that. Your data remains private and local to your machine.\n\nSee [Documentation \\> Offline Operation](https://lmstudio.ai/docs/offline) for more.\n\n### Can I use LM Studio at work?[](https://lmstudio.ai/#can-i-use-lm-studio-at-work)\n\nWe'd love to enable you. Please fill out the [LM Studio @ Work request form](https://docs.google.com/forms/d/e/1FAIpQLSd-zGyQIVlSSqzRyM4YzPEmdNehW3iCd3_X8np5NWCD_1G3BA/viewform?usp=sf_link) and we will get back to you as soon as we can.\n\n### What are the minimum hardware / software requirements?[](https://lmstudio.ai/#what-are-the-minimum-hardware--software-requirements)\n\nVisit the [System Requirements](https://lmstudio.ai/docs/system-requirements) page for the most up to date information.\n\n### Are you hiring?[](https://lmstudio.ai/#are-you-hiring)\n\nSee our [careers page](https://lmstudio.ai/careers) for open positions.",
  "usage": {
    "tokens": 669
  }
}
```
