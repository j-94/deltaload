---
title: Keras documentation: Natural Language Processing
description: Keras documentation
url: https://keras.io/examples/nlp/
timestamp: 2025-01-20T16:01:12.968Z
domain: keras.io
path: examples_nlp
---

# Keras documentation: Natural Language Processing


Keras documentation


## Content

### Text classification

[★ **V3** Text classification from scratch](https://keras.io/examples/nlp/text_classification_from_scratch)[**V3** Review Classification using Active Learning](https://keras.io/examples/nlp/active_learning_review_classification)[**V3** Text Classification using FNet](https://keras.io/examples/nlp/fnet_classification_with_keras_hub)[V2 Large-scale multi-label text classification](https://keras.io/examples/nlp/multi_label_classification)[**V3** Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer)[**V3** Text classification with Switch Transformer](https://keras.io/examples/nlp/text_classification_with_switch_transformer)[V2 Text classification using Decision Forests and pretrained embeddings](https://keras.io/examples/nlp/tweet-classification-using-tfdf)[**V3** Using pre-trained word embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings)[**V3** Bidirectional LSTM on IMDB](https://keras.io/examples/nlp/bidirectional_lstm_imdb)[**V3** Data Parallel Training with KerasHub and tf.distribute](https://keras.io/examples/nlp/data_parallel_training_with_keras_hub)

### Machine translation

[**V3** English-to-Spanish translation with KerasHub](https://keras.io/examples/nlp/neural_machine_translation_with_keras_hub)[★ **V3** English-to-Spanish translation with a sequence-to-sequence Transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer)[**V3** Character-level recurrent sequence-to-sequence model](https://keras.io/examples/nlp/lstm_seq2seq)

### Entailment prediction

[V2 Multimodal entailment](https://keras.io/examples/nlp/multimodal_entailment)

### Named entity recognition

[**V3** Named Entity Recognition using Transformers](https://keras.io/examples/nlp/ner_transformers)

### Sequence-to-sequence

[V2 Text Extraction with BERT](https://keras.io/examples/nlp/text_extraction_with_bert)[**V3** Sequence to sequence learning for performing number addition](https://keras.io/examples/nlp/addition_rnn)

### Text similarity search

[**V3** Semantic Similarity with KerasHub](https://keras.io/examples/nlp/semantic_similarity_with_keras_hub)[**V3** Semantic Similarity with BERT](https://keras.io/examples/nlp/semantic_similarity_with_bert)[**V3** Sentence embeddings using Siamese RoBERTa-networks](https://keras.io/examples/nlp/sentence_embeddings_with_sbert)

### Language modeling

[**V3** End-to-end Masked Language Modeling with BERT](https://keras.io/examples/nlp/masked_language_modeling)[**V3** Abstractive Text Summarization with BART](https://keras.io/examples/nlp/abstractive_summarization_with_bart)[V2 Pretraining BERT with Hugging Face Transformers](https://keras.io/examples/nlp/pretraining_BERT)

### Parameter efficient fine-tuning

[**V3** Parameter-efficient fine-tuning of GPT-2 with LoRA](https://keras.io/examples/nlp/parameter_efficient_finetuning_of_gpt2_with_lora)

### Other

[V2 MultipleChoice Task with Transfer Learning](https://keras.io/examples/nlp/multiple_choice_task_with_transfer_learning)[V2 Question Answering with Hugging Face Transformers](https://keras.io/examples/nlp/question_answering)[V2 Abstractive Summarization with Hugging Face Transformers](https://keras.io/examples/nlp/t5_hf_summarization)

* * *

## Metadata

```json
{
  "title": "Keras documentation: Natural Language Processing",
  "description": "Keras documentation",
  "url": "https://keras.io/examples/nlp/",
  "content": "### Text classification\n\n[★ **V3** Text classification from scratch](https://keras.io/examples/nlp/text_classification_from_scratch)[**V3** Review Classification using Active Learning](https://keras.io/examples/nlp/active_learning_review_classification)[**V3** Text Classification using FNet](https://keras.io/examples/nlp/fnet_classification_with_keras_hub)[V2 Large-scale multi-label text classification](https://keras.io/examples/nlp/multi_label_classification)[**V3** Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer)[**V3** Text classification with Switch Transformer](https://keras.io/examples/nlp/text_classification_with_switch_transformer)[V2 Text classification using Decision Forests and pretrained embeddings](https://keras.io/examples/nlp/tweet-classification-using-tfdf)[**V3** Using pre-trained word embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings)[**V3** Bidirectional LSTM on IMDB](https://keras.io/examples/nlp/bidirectional_lstm_imdb)[**V3** Data Parallel Training with KerasHub and tf.distribute](https://keras.io/examples/nlp/data_parallel_training_with_keras_hub)\n\n### Machine translation\n\n[**V3** English-to-Spanish translation with KerasHub](https://keras.io/examples/nlp/neural_machine_translation_with_keras_hub)[★ **V3** English-to-Spanish translation with a sequence-to-sequence Transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer)[**V3** Character-level recurrent sequence-to-sequence model](https://keras.io/examples/nlp/lstm_seq2seq)\n\n### Entailment prediction\n\n[V2 Multimodal entailment](https://keras.io/examples/nlp/multimodal_entailment)\n\n### Named entity recognition\n\n[**V3** Named Entity Recognition using Transformers](https://keras.io/examples/nlp/ner_transformers)\n\n### Sequence-to-sequence\n\n[V2 Text Extraction with BERT](https://keras.io/examples/nlp/text_extraction_with_bert)[**V3** Sequence to sequence learning for performing number addition](https://keras.io/examples/nlp/addition_rnn)\n\n### Text similarity search\n\n[**V3** Semantic Similarity with KerasHub](https://keras.io/examples/nlp/semantic_similarity_with_keras_hub)[**V3** Semantic Similarity with BERT](https://keras.io/examples/nlp/semantic_similarity_with_bert)[**V3** Sentence embeddings using Siamese RoBERTa-networks](https://keras.io/examples/nlp/sentence_embeddings_with_sbert)\n\n### Language modeling\n\n[**V3** End-to-end Masked Language Modeling with BERT](https://keras.io/examples/nlp/masked_language_modeling)[**V3** Abstractive Text Summarization with BART](https://keras.io/examples/nlp/abstractive_summarization_with_bart)[V2 Pretraining BERT with Hugging Face Transformers](https://keras.io/examples/nlp/pretraining_BERT)\n\n### Parameter efficient fine-tuning\n\n[**V3** Parameter-efficient fine-tuning of GPT-2 with LoRA](https://keras.io/examples/nlp/parameter_efficient_finetuning_of_gpt2_with_lora)\n\n### Other\n\n[V2 MultipleChoice Task with Transfer Learning](https://keras.io/examples/nlp/multiple_choice_task_with_transfer_learning)[V2 Question Answering with Hugging Face Transformers](https://keras.io/examples/nlp/question_answering)[V2 Abstractive Summarization with Hugging Face Transformers](https://keras.io/examples/nlp/t5_hf_summarization)\n\n* * *",
  "usage": {
    "tokens": 788
  }
}
```
