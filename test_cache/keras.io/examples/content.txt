Our code examples are short (less than 300 lines of code), focused demonstrations of vertical deep learning workflows.

All of our examples are written as Jupyter notebooks and can be run in one click in [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb), a hosted notebook environment that requires no setup and runs in the cloud. Google Colab includes GPU and TPU runtimes.

â˜…

\= Good starter example

**V3**

\= Keras 3 example

[Computer Vision](https://keras.io/examples/vision/)
----------------------------------------------------

### Image classification

[â˜… **V3** Image classification from scratch](https://keras.io/examples/vision/image_classification_from_scratch)[â˜… **V3** Simple MNIST convnet](https://keras.io/examples/vision/mnist_convnet)[â˜… **V3** Image classification via fine-tuning with EfficientNet](https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning)[**V3** Image classification with Vision Transformer](https://keras.io/examples/vision/image_classification_with_vision_transformer)[**V3** Classification using Attention-based Deep Multiple Instance Learning](https://keras.io/examples/vision/attention_mil_classification)[**V3** Image classification with modern MLP models](https://keras.io/examples/vision/mlp_image_classification)[**V3** A mobile-friendly Transformer-based model for image classification](https://keras.io/examples/vision/mobilevit)[**V3** Pneumonia Classification on TPU](https://keras.io/examples/vision/xray_classification_with_tpus)[**V3** Compact Convolutional Transformers](https://keras.io/examples/vision/cct)[**V3** Image classification with ConvMixer](https://keras.io/examples/vision/convmixer)[**V3** Image classification with EANet (External Attention Transformer)](https://keras.io/examples/vision/eanet)[**V3** Involutional neural networks](https://keras.io/examples/vision/involution)[**V3** Image classification with Perceiver](https://keras.io/examples/vision/perceiver_image_classification)[**V3** Few-Shot learning with Reptile](https://keras.io/examples/vision/reptile)[**V3** Semi-supervised image classification using contrastive pretraining with SimCLR](https://keras.io/examples/vision/semisupervised_simclr)[**V3** Image classification with Swin Transformers](https://keras.io/examples/vision/swin_transformers)[**V3** Train a Vision Transformer on small datasets](https://keras.io/examples/vision/vit_small_ds)[**V3** A Vision Transformer without Attention](https://keras.io/examples/vision/shiftvit)[**V3** Image Classification using Global Context Vision Transformer](https://keras.io/examples/vision/image_classification_using_global_context_vision_transformer)[**V3** When Recurrence meets Transformers](https://keras.io/examples/vision/temporal_latent_bottleneck)[**V3** Image Classification using BigTransfer (BiT)](https://keras.io/examples/vision/bit)

### Image segmentation

[â˜… **V3** Image segmentation with a U-Net-like architecture](https://keras.io/examples/vision/oxford_pets_image_segmentation)[**V3** Multiclass semantic segmentation using DeepLabV3+](https://keras.io/examples/vision/deeplabv3_plus)[V2 Highly accurate boundaries segmentation using BASNet](https://keras.io/examples/vision/basnet_segmentation)[**V3** Image Segmentation using Composable Fully-Convolutional Networks](https://keras.io/examples/vision/fully_convolutional_network)

### Object detection

[V2 Object Detection with RetinaNet](https://keras.io/examples/vision/retinanet)[**V3** Keypoint Detection with Transfer Learning](https://keras.io/examples/vision/keypoint_detection)[**V3** Object detection with Vision Transformers](https://keras.io/examples/vision/object_detection_using_vision_transformer)

### 3D

[**V3** 3D image classification from CT scans](https://keras.io/examples/vision/3D_image_classification)[**V3** Monocular depth estimation](https://keras.io/examples/vision/depth_estimation)[â˜… **V3** 3D volumetric rendering with NeRF](https://keras.io/examples/vision/nerf)[**V3** Point cloud segmentation with PointNet](https://keras.io/examples/vision/pointnet_segmentation)[**V3** Point cloud classification](https://keras.io/examples/vision/pointnet)

### OCR

[**V3** OCR model for reading Captchas](https://keras.io/examples/vision/captcha_ocr)[**V3** Handwriting recognition](https://keras.io/examples/vision/handwriting_recognition)

### Image enhancement

[**V3** Convolutional autoencoder for image denoising](https://keras.io/examples/vision/autoencoder)[**V3** Low-light image enhancement using MIRNet](https://keras.io/examples/vision/mirnet)[**V3** Image Super-Resolution using an Efficient Sub-Pixel CNN](https://keras.io/examples/vision/super_resolution_sub_pixel)[**V3** Enhanced Deep Residual Networks for single-image super-resolution](https://keras.io/examples/vision/edsr)[**V3** Zero-DCE for low-light image enhancement](https://keras.io/examples/vision/zero_dce)

### Data augmentation

[**V3** CutMix data augmentation for image classification](https://keras.io/examples/vision/cutmix)[**V3** MixUp augmentation for image classification](https://keras.io/examples/vision/mixup)[**V3** RandAugment for Image Classification for Improved Robustness](https://keras.io/examples/vision/randaugment)

### Image & Text

[â˜… **V3** Image captioning](https://keras.io/examples/vision/image_captioning)[V2 Natural language image search with a Dual Encoder](https://keras.io/examples/vision/nl_image_search)

### Vision models interpretability

[**V3** Visualizing what convnets learn](https://keras.io/examples/vision/visualizing_what_convnets_learn)[**V3** Model interpretability with Integrated Gradients](https://keras.io/examples/vision/integrated_gradients)[**V3** Investigating Vision Transformer representations](https://keras.io/examples/vision/probing_vits)[**V3** Grad-CAM class activation visualization](https://keras.io/examples/vision/grad_cam)

### Image similarity search

[V2 Near-duplicate image search](https://keras.io/examples/vision/near_dup_search)[**V3** Semantic Image Clustering](https://keras.io/examples/vision/semantic_image_clustering)[**V3** Image similarity estimation using a Siamese Network with a contrastive loss](https://keras.io/examples/vision/siamese_contrastive)[**V3** Image similarity estimation using a Siamese Network with a triplet loss](https://keras.io/examples/vision/siamese_network)[**V3** Metric learning for image similarity search](https://keras.io/examples/vision/metric_learning)[V2 Metric learning for image similarity search using TensorFlow Similarity](https://keras.io/examples/vision/metric_learning_tf_similarity)[**V3** Self-supervised contrastive learning with NNCLR](https://keras.io/examples/vision/nnclr)

### Video

[**V3** Video Classification with a CNN-RNN Architecture](https://keras.io/examples/vision/video_classification)[**V3** Next-Frame Video Prediction with Convolutional LSTMs](https://keras.io/examples/vision/conv_lstm)[**V3** Video Classification with Transformers](https://keras.io/examples/vision/video_transformers)[**V3** Video Vision Transformer](https://keras.io/examples/vision/vivit)

### Performance recipes

[**V3** Gradient Centralization for Better Training Performance](https://keras.io/examples/vision/gradient_centralization)[**V3** Learning to tokenize in Vision Transformers](https://keras.io/examples/vision/token_learner)[**V3** Knowledge Distillation](https://keras.io/examples/vision/knowledge_distillation)[**V3** FixRes: Fixing train-test resolution discrepancy](https://keras.io/examples/vision/fixres)[**V3** Class Attention Image Transformers with LayerScale](https://keras.io/examples/vision/cait)[**V3** Augmenting convnets with aggregated attention](https://keras.io/examples/vision/patch_convnet)[**V3** Learning to Resize](https://keras.io/examples/vision/learnable_resizer)

### Other

[V2 Semi-supervision and domain adaptation with AdaMatch](https://keras.io/examples/vision/adamatch)[V2 Barlow Twins for Contrastive SSL](https://keras.io/examples/vision/barlow_twins)[V2 Consistency training with supervision](https://keras.io/examples/vision/consistency_training)[V2 Distilling Vision Transformers](https://keras.io/examples/vision/deit)[V2 Focal Modulation: A replacement for Self-Attention](https://keras.io/examples/vision/focal_modulation_network)[V2 Using the Forward-Forward Algorithm for Image Classification](https://keras.io/examples/vision/forwardforward)[V2 Masked image modeling with Autoencoders](https://keras.io/examples/vision/masked_image_modeling)[V2 Segment Anything Model with ðŸ¤—Transformers](https://keras.io/examples/vision/sam)[V2 Semantic segmentation with SegFormer and Hugging Face Transformers](https://keras.io/examples/vision/segformer)[V2 Self-supervised contrastive learning with SimSiam](https://keras.io/examples/vision/simsiam)[V2 Supervised Contrastive Learning](https://keras.io/examples/vision/supervised-contrastive-learning)[V2 Efficient Object Detection with YOLOV8 and KerasCV](https://keras.io/examples/vision/yolov8)

* * *

[Natural Language Processing](https://keras.io/examples/nlp/)
-------------------------------------------------------------

### Text classification

[â˜… **V3** Text classification from scratch](https://keras.io/examples/nlp/text_classification_from_scratch)[**V3** Review Classification using Active Learning](https://keras.io/examples/nlp/active_learning_review_classification)[**V3** Text Classification using FNet](https://keras.io/examples/nlp/fnet_classification_with_keras_hub)[V2 Large-scale multi-label text classification](https://keras.io/examples/nlp/multi_label_classification)[**V3** Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer)[**V3** Text classification with Switch Transformer](https://keras.io/examples/nlp/text_classification_with_switch_transformer)[V2 Text classification using Decision Forests and pretrained embeddings](https://keras.io/examples/nlp/tweet-classification-using-tfdf)[**V3** Using pre-trained word embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings)[**V3** Bidirectional LSTM on IMDB](https://keras.io/examples/nlp/bidirectional_lstm_imdb)[**V3** Data Parallel Training with KerasHub and tf.distribute](https://keras.io/examples/nlp/data_parallel_training_with_keras_hub)

### Machine translation

[**V3** English-to-Spanish translation with KerasHub](https://keras.io/examples/nlp/neural_machine_translation_with_keras_hub)[â˜… **V3** English-to-Spanish translation with a sequence-to-sequence Transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer)[**V3** Character-level recurrent sequence-to-sequence model](https://keras.io/examples/nlp/lstm_seq2seq)

### Entailment prediction

[V2 Multimodal entailment](https://keras.io/examples/nlp/multimodal_entailment)

### Named entity recognition

[**V3** Named Entity Recognition using Transformers](https://keras.io/examples/nlp/ner_transformers)

### Sequence-to-sequence

[V2 Text Extraction with BERT](https://keras.io/examples/nlp/text_extraction_with_bert)[**V3** Sequence to sequence learning for performing number addition](https://keras.io/examples/nlp/addition_rnn)

### Text similarity search

[**V3** Semantic Similarity with KerasHub](https://keras.io/examples/nlp/semantic_similarity_with_keras_hub)[**V3** Semantic Similarity with BERT](https://keras.io/examples/nlp/semantic_similarity_with_bert)[**V3** Sentence embeddings using Siamese RoBERTa-networks](https://keras.io/examples/nlp/sentence_embeddings_with_sbert)

### Language modeling

[**V3** End-to-end Masked Language Modeling with BERT](https://keras.io/examples/nlp/masked_language_modeling)[**V3** Abstractive Text Summarization with BART](https://keras.io/examples/nlp/abstractive_summarization_with_bart)[V2 Pretraining BERT with Hugging Face Transformers](https://keras.io/examples/nlp/pretraining_BERT)

### Parameter efficient fine-tuning

[**V3** Parameter-efficient fine-tuning of GPT-2 with LoRA](https://keras.io/examples/nlp/parameter_efficient_finetuning_of_gpt2_with_lora)

### Other

[V2 MultipleChoice Task with Transfer Learning](https://keras.io/examples/nlp/multiple_choice_task_with_transfer_learning)[V2 Question Answering with Hugging Face Transformers](https://keras.io/examples/nlp/question_answering)[V2 Abstractive Summarization with Hugging Face Transformers](https://keras.io/examples/nlp/t5_hf_summarization)

* * *

[Structured Data](https://keras.io/examples/structured_data/)
-------------------------------------------------------------

### Structured data classification

[â˜… **V3** Structured data classification with FeatureSpace](https://keras.io/examples/structured_data/structured_data_classification_with_feature_space)[â˜… **V3** FeatureSpace advanced use cases](https://keras.io/examples/structured_data/feature_space_advanced)[â˜… **V3** Imbalanced classification: credit card fraud detection](https://keras.io/examples/structured_data/imbalanced_classification)[**V3** Structured data classification from scratch](https://keras.io/examples/structured_data/structured_data_classification_from_scratch)[**V3** Structured data learning with Wide, Deep, and Cross networks](https://keras.io/examples/structured_data/wide_deep_cross_networks)[V2 Classification with Gated Residual and Variable Selection Networks](https://keras.io/examples/structured_data/classification_with_grn_and_vsn)[V2 Classification with TensorFlow Decision Forests](https://keras.io/examples/structured_data/classification_with_tfdf)[**V3** Classification with Neural Decision Forests](https://keras.io/examples/structured_data/deep_neural_decision_forests)[**V3** Structured data learning with TabTransformer](https://keras.io/examples/structured_data/tabtransformer)

### Structured data regression

[**V3** Deep Learning for Customer Lifetime Value](https://keras.io/examples/structured_data/customer_lifetime_value)

### Recommendation

[**V3** Collaborative Filtering for Movie Recommendations](https://keras.io/examples/structured_data/collaborative_filtering_movielens)[**V3** A Transformer-based recommendation system](https://keras.io/examples/structured_data/movielens_recommendations_transformers)

* * *

[Timeseries](https://keras.io/examples/timeseries/)
---------------------------------------------------

### Timeseries classification

[â˜… **V3** Timeseries classification from scratch](https://keras.io/examples/timeseries/timeseries_classification_from_scratch)[**V3** Timeseries classification with a Transformer model](https://keras.io/examples/timeseries/timeseries_classification_transformer)[**V3** Electroencephalogram Signal Classification for action identification](https://keras.io/examples/timeseries/eeg_signal_classification)[**V3** Event classification for payment card fraud detection](https://keras.io/examples/timeseries/event_classification_for_payment_card_fraud_detection)

### Anomaly detection

[**V3** Timeseries anomaly detection using an Autoencoder](https://keras.io/examples/timeseries/timeseries_anomaly_detection)

### Timeseries forecasting

[**V3** Traffic forecasting using graph neural networks and LSTM](https://keras.io/examples/timeseries/timeseries_traffic_forecasting)[**V3** Timeseries forecasting for weather prediction](https://keras.io/examples/timeseries/timeseries_weather_forecasting)

* * *

[Generative Deep Learning](https://keras.io/examples/generative/)
-----------------------------------------------------------------

### Image generation

[â˜… **V3** Denoising Diffusion Implicit Models](https://keras.io/examples/generative/ddim)[â˜… **V3** A walk through latent space with Stable Diffusion 3](https://keras.io/examples/generative/random_walks_with_stable_diffusion_3)[V2 DreamBooth](https://keras.io/examples/generative/dreambooth)[V2 Denoising Diffusion Probabilistic Models](https://keras.io/examples/generative/ddpm)[V2 Teach StableDiffusion new concepts via Textual Inversion](https://keras.io/examples/generative/fine_tune_via_textual_inversion)[V2 Fine-tuning Stable Diffusion](https://keras.io/examples/generative/finetune_stable_diffusion)[**V3** Variational AutoEncoder](https://keras.io/examples/generative/vae)[**V3** GAN overriding Model.train\_step](https://keras.io/examples/generative/dcgan_overriding_train_step)[**V3** WGAN-GP overriding Model.train\_step](https://keras.io/examples/generative/wgan_gp)[**V3** Conditional GAN](https://keras.io/examples/generative/conditional_gan)[**V3** CycleGAN](https://keras.io/examples/generative/cyclegan)[V2 Data-efficient GANs with Adaptive Discriminator Augmentation](https://keras.io/examples/generative/gan_ada)[**V3** Deep Dream](https://keras.io/examples/generative/deep_dream)[**V3** GauGAN for conditional image generation](https://keras.io/examples/generative/gaugan)[**V3** PixelCNN](https://keras.io/examples/generative/pixelcnn)[V2 Face image generation with StyleGAN](https://keras.io/examples/generative/stylegan)[V2 Vector-Quantized Variational Autoencoders](https://keras.io/examples/generative/vq_vae)[**V3** A walk through latent space with Stable Diffusion](https://keras.io/examples/generative/random_walks_with_stable_diffusion)

### Style transfer

[**V3** Neural style transfer](https://keras.io/examples/generative/neural_style_transfer)[V2 Neural Style Transfer with AdaIN](https://keras.io/examples/generative/adain)

### Text generation

[â˜… **V3** GPT2 Text Generation with KerasHub](https://keras.io/examples/generative/gpt2_text_generation_with_keras_hub)[**V3** GPT text generation from scratch with KerasHub](https://keras.io/examples/generative/text_generation_gpt)[**V3** Text generation with a miniature GPT](https://keras.io/examples/generative/text_generation_with_miniature_gpt)[**V3** Character-level text generation with LSTM](https://keras.io/examples/generative/lstm_character_level_text_generation)[V2 Text Generation using FNet](https://keras.io/examples/generative/text_generation_fnet)

### Audio generation

[**V3** Music Generation with Transformer Models](https://keras.io/examples/generative/midi_generation_with_transformer)

### Graph generation

[**V3** Drug Molecule Generation with VAE](https://keras.io/examples/generative/molecule_generation)[V2 WGAN-GP with R-GCN for the generation of small molecular graphs](https://keras.io/examples/generative/wgan-graphs)

### Other

[V2 Density estimation using Real NVP](https://keras.io/examples/generative/real_nvp)

* * *

[Audio Data](https://keras.io/examples/audio/)
----------------------------------------------

### Vocal track separation

[**V3** Vocal Track Separation with Encoder-Decoder Architecture](https://keras.io/examples/audio/vocal_track_separation)

### Speech recognition

[**V3** Automatic Speech Recognition with Transformer](https://keras.io/examples/audio/transformer_asr)

### Other

[V2 Automatic Speech Recognition using CTC](https://keras.io/examples/audio/ctc_asr)[V2 MelGAN-based spectrogram inversion using feature matching](https://keras.io/examples/audio/melgan_spectrogram_inversion)[V2 Speaker Recognition](https://keras.io/examples/audio/speaker_recognition_using_cnn)[V2 Audio Classification with the STFTSpectrogram layer](https://keras.io/examples/audio/stft)[V2 English speaker accent recognition using Transfer Learning](https://keras.io/examples/audio/uk_ireland_accent_recognition)[V2 Audio Classification with Hugging Face Transformers](https://keras.io/examples/audio/wav2vec2_audiocls)

* * *

[Reinforcement Learning](https://keras.io/examples/rl/)
-------------------------------------------------------

[Actor Critic Method](https://keras.io/examples/rl/actor_critic_cartpole)[Proximal Policy Optimization](https://keras.io/examples/rl/ppo_cartpole)[Deep Q-Learning for Atari Breakout](https://keras.io/examples/rl/deep_q_network_breakout)[Deep Deterministic Policy Gradient (DDPG)](https://keras.io/examples/rl/ddpg_pendulum)

* * *

[Graph Data](https://keras.io/examples/graph/)
----------------------------------------------

[Graph attention network (GAT) for node classification](https://keras.io/examples/graph/gat_node_classification)[Node Classification with Graph Neural Networks](https://keras.io/examples/graph/gnn_citations)[Message-passing neural network (MPNN) for molecular property prediction](https://keras.io/examples/graph/mpnn-molecular-graphs)[Graph representation learning with node2vec](https://keras.io/examples/graph/node2vec_movielens)

* * *

[Quick Keras Recipes](https://keras.io/examples/keras_recipes/)
---------------------------------------------------------------

### Keras usage tips

[**V3** Parameter-efficient fine-tuning of Gemma with LoRA and QLoRA](https://keras.io/examples/keras_recipes/parameter_efficient_finetuning_of_gemma_with_lora_and_qlora)[**V3** Float8 training and inference with a simple Transformer model](https://keras.io/examples/keras_recipes/float8_training_and_inference_with_transformer)[**V3** Keras debugging tips](https://keras.io/examples/keras_recipes/debugging_tips)[**V3** Customizing the convolution operation of a Conv2D layer](https://keras.io/examples/keras_recipes/subclassing_conv_layers)[**V3** Trainer pattern](https://keras.io/examples/keras_recipes/trainer_pattern)[**V3** Endpoint layer pattern](https://keras.io/examples/keras_recipes/endpoint_layer_pattern)[**V3** Reproducibility in Keras Models](https://keras.io/examples/keras_recipes/reproducibility_recipes)[**V3** Writing Keras Models With TensorFlow NumPy](https://keras.io/examples/keras_recipes/tensorflow_numpy_models)[**V3** Simple custom layer example: Antirectifier](https://keras.io/examples/keras_recipes/antirectifier)[**V3** Packaging Keras models for wide distribution using Functional Subclassing](https://keras.io/examples/keras_recipes/packaging_keras_models_for_wide_distribution)

### Serving

[**V3** Serving TensorFlow models with TFServing](https://keras.io/examples/keras_recipes/tf_serving)

### ML best practices

[**V3** Estimating required sample size for model training](https://keras.io/examples/keras_recipes/sample_size_estimate)[**V3** Memory-efficient embeddings for recommendation systems](https://keras.io/examples/keras_recipes/memory_efficient_embeddings)[**V3** Creating TFRecords](https://keras.io/examples/keras_recipes/creating_tfrecords)

### Other

[V2 Approximating non-Function Mappings with Mixture Density Networks](https://keras.io/examples/keras_recipes/approximating_non_function_mappings)[V2 Probabilistic Bayesian Neural Networks](https://keras.io/examples/keras_recipes/bayesian_neural_networks)[V2 Knowledge distillation recipes](https://keras.io/examples/keras_recipes/better_knowledge_distillation)[V2 Evaluating and exporting scikit-learn metrics in a Keras callback](https://keras.io/examples/keras_recipes/sklearn_metric_callbacks)[V2 How to train a Keras model on TFRecord files](https://keras.io/examples/keras_recipes/tfrecord)

* * *

Adding a new code example
-------------------------

We welcome new code examples! Here are our rules:

*   They should be shorter than 300 lines of code (comments may be as long as you want).
*   They should demonstrate modern Keras best practices.
*   They should be substantially different in topic from all examples listed above.
*   They should be extensively documented & commented.

New examples are added via Pull Requests to the [keras.io repository](https://github.com/keras-team/keras-io). They must be submitted as a `.py` file that follows a specific format. They are usually generated from Jupyter notebooks. See the [`tutobooks` documentation](https://github.com/keras-team/keras-io/blob/master/README.md) for more details.

If you would like to convert a Keras 2 example to Keras 3, please open a Pull Request to the [keras.io repository](https://github.com/keras-team/keras-io).