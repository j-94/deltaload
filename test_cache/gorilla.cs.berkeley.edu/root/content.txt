Gorilla
===============
         

[Home](https://gorilla.cs.berkeley.edu/index.html) [Blogs](https://gorilla.cs.berkeley.edu/blog.html) [Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html) [API Zoo Index](https://gorilla.cs.berkeley.edu/apizoo/)

ğŸ¦ Gorilla: Large Language Model Connected with Massive APIs
============================================================

#### [Shishir G. Patil\*](https://people.eecs.berkeley.edu/~shishirpatil/), [Tianjun Zhang\*](https://tianjunz.github.io/), [Xin Wang](https://xinw.ai/), [Joseph E. Gonzalez](https://people.eecs.berkeley.edu/~jegonzal/)

##### UC Berkeley

###### sgp@berkeley.edu, tianjunz@berkeley.edu

[Blogs](https://gorilla.cs.berkeley.edu/blog.html) [GitHub](https://github.com/ShishirPatil/gorilla) [HuggingFace](https://huggingface.co/gorilla-llm) [Discord](https://discord.gg/grXXvj9Whz)

[Gorilla Paper](https://arxiv.org/abs/2305.15334) [RAFT Paper](https://arxiv.org/abs/2403.10131) [GoEX Paper](https://arxiv.org/abs/2404.06921)

### Systems and Algorithms for Integrating LLMs with Applications, Tools, and Services

### Gorilla Used at

Microsoft Nvidia

Gorilla OpenFunctions

Teach LLM tool use

![Image 6: Image 1](https://gorilla.cs.berkeley.edu/assets/img/blog_post_4_gorilla_open_function_calling.png)

ğŸIn OpenFunctions-v2, we natively train the model to support parallel functions (generate multiple functions at a time) and multiple functions (select one or more functions). Java/REST/Python APIs are also supported for the first time with extended data typesğŸ“·

*   Read More: [Blog](https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html)
*   How well to other function-calling models perform: [Berkeley Function Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html)
*   Play with the model online: [Gorilla OpenFunctions-v2 Web Demo](https://gorilla.cs.berkeley.edu/leaderboard.html#api-explorer)
*   Check out the project: [GitHub Code](https://github.com/ShishirPatil/gorilla/tree/main/openfunctions)
*   Model (6.91B) on HuggingFace ğŸ¤—: [gorilla-llm/gorilla-openfunctions-v2](https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2)

BFCL

Benchmarking LLMs on function calling capabilities

![Image 7: Image 1](https://gorilla.cs.berkeley.edu/assets/img/leaderboard-summary.jpg)

ğŸ† Berkeley Function-Calling Leaderboard (BFCL) ğŸ“Š aims to provide a thorough study of the function-calling capability of different LLMs. It consists of 2k ğŸ“ question-function-answer pairs with multiple languages (ğŸ Python, â˜• Java, ğŸŸ¨ JavaScript, ğŸŒ REST API), diverse application domains, and complex use cases (multiple and parallel function calls). We also investigate function relevance detection ğŸ•µï¸â€â™‚ï¸, to determine how the model will react when the provided function is not suitable to answer the user's question.

*   Read More: [Blog](https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html)
*   Live Leaderboard: [Website](https://gorilla.cs.berkeley.edu/leaderboard.html)
*   BFCL Evaluation Dataset: [HuggingFace Dataset ğŸ¤—](https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard)
*   Gradio Demo: [HuggingFace Space ğŸ¤—](https://huggingface.co/spaces/gorilla-llm/berkeley-function-calling-leaderboard)
*   Reproducibility: [Github Code](https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard)

RAFT

Better way to do RAG

![Image 8: Image 1](https://gorilla.cs.berkeley.edu/assets/img/blog_post_9_raft_openbook.png)

RAFT: Retriever-Aware FineTuning for domain-specific RAG ğŸš€ Drawing parallels between LLMs and students in open-book (RAG) ğŸ“” and closed-book exams (SFT) ğŸ§ , we present a better recipe for fine-tuning a base LLM for RAG-focused challenges. Discover how RAFT prepares LLMs to excel with a specific document set, mirroring students' prep for finals! ğŸ“

*   Read More: [Blog](https://gorilla.cs.berkeley.edu/blogs/9_raft.html)
*   Read More: [MSFT-META Blog](https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/raft-a-new-way-to-teach-llms-to-be-better-at-rag/ba-p/4084674)
*   Paper: [https://arxiv.org/abs/2403.10131](https://arxiv.org/abs/2403.10131)
*   Reproducibility: [Github Code](https://github.com/ShishirPatil/gorilla/tree/main/raft)
    

GoEX

Runtime for executing LLM-generated actions

![Image 9: Image 1](https://gorilla.cs.berkeley.edu/assets/img/blog_post_10_intro.png)

Gorilla Execution Engine (GoEX) is a runtime for LLM-generated actions like code, API calls, and more. Featuring "post-facto validation" for assessing LLM actions after execution ğŸ” Key to our approach is "undo" ğŸ”„ and "damage confinement" abstractions to manage unintended actions & risks. This paves the way for fully autonomous LLM agents, enhancing interaction between apps & services with human-out-of-loopğŸš€

*   Read More: [Blog](https://gorilla.cs.berkeley.edu/blogs/10_gorilla_exec_engine.html)
*   Paper: [https://arxiv.org/abs/2404.06921](https://arxiv.org/abs/2404.06921)
*   Try it out: [Web Demo](https://goex.gorilla-llm.com/index)
*   Reproducibility: [GitHub Code](https://github.com/ShishirPatil/gorilla/tree/main/goex)

News
----

##### ğŸš’ [GoEx](https://goex.gorilla-llm.com/index): A Runtime for executing LLM generated actions like code & API calls GoEx presents â€œundoâ€ and â€œdamage confinementâ€ abstractions for mitigating the risk of unintended actions taken in LLM-powered systems. [Release blog](https://gorilla.cs.berkeley.edu/blogs/10_gorilla_exec_engine.html), [Paper](https://arxiv.org/abs/2404.06921).

##### ğŸ‰ [Berkeley Function Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html)! How do models stack up for function calling? ğŸ¯ Read more in our [Release Blog](https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html).

##### ğŸ† [Gorilla OpenFunctions v2](https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html) Sets new SoTA for open-source LLMs ğŸ’ª On-par with GPT-4 ğŸ™Œ Supports more languages ğŸ‘Œ

##### ğŸ¥‡ [Gorilla OpenFunctions!](https://gorilla.cs.berkeley.edu/blogs/4_open_functions.html) Drop in replacement! [Examples](https://colab.research.google.com/drive/16M5J2H9F8YQora_W2PDnp120slZH-Mqd?usp=sharing)

##### ğŸš€ [Try Gorilla in 60s!](https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP?usp=sharing) No sign-ups, no installs, just colab!

##### ğŸ¤© With Apache 2.0 licensed LLM models, you can use Gorilla commercially without any obligations!

##### ğŸ“£ We are excited to hear your feedback and we welcome API contributions as we build this open-source project. Join us on [Discord](https://discord.gg/grXXvj9Whz) or feel free to email us!

Gorilla for your CLI and Spotlight Search
-----------------------------------------

Gorilla powered CLI  
Get started with `pip install gorilla-cli`

Gorilla Powered Spotlight Search  
[Gorilla-Spotlight Signup](https://docs.google.com/forms/d/1iuWrfQbTb8_T5s4J75HNftPF-w1Jg1Aeg-gB64X8MJg/edit)

Vision
------

![Image 10: Gorilla LLM logo](https://gorilla.cs.berkeley.edu/assets/img/blog_post_1_teaser.gif)

_Rather have the user at the center, Gorilla enables users to interact with a wide range of services through LLMs. Gorilla is an open-source, state-of-the-art LLM that invokes API calls to interact with services!_

Contact Us
----------

   Submit

Citation
--------

                            ```

@article{patil2023gorilla,
    title={Gorilla: Large Language Model Connected with Massive APIs},
    author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
    journal={arXiv preprint arXiv:2305.15334},
    year={2023},
}
                
```