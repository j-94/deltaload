\[PDF\] Qwen Technical Report | Semantic Scholar
===============
                                                                                                         

[Skip to search form](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#search-form)[Skip to main content](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#main-content)[Skip to account menu](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#account-menu)

[](https://www.semanticscholar.org/)

Search 223,685,187 papers from all fields of science

Search

Sign InCreate Free Account

*   DOI:[10.48550/arXiv.2309.16609](https://doi.org/10.48550/arXiv.2309.16609)
    
*   Corpus ID: 263134555

Qwen Technical Report
=====================

@article{Bai2023QwenTR,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenhang Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and K. Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Yu Bowen and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xing Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.16609},
  url={https://api.semanticscholar.org/CorpusID:263134555}
}

*   [Jinze Bai](https://www.semanticscholar.org/author/Jinze-Bai/41211611), [Shuai Bai](https://www.semanticscholar.org/author/Shuai-Bai/2247821453), +47 authors [Tianhang Zhu](https://www.semanticscholar.org/author/Tianhang-Zhu/2248127832)
*   Published in [arXiv.org](https://www.semanticscholar.org/venue?name=arXiv.org) 28 September 2023
*   Computer Science, Linguistics

TLDR

Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts, and includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques.Expand

[View PDF on arXiv](https://arxiv.org/pdf/2309.16609.pdf "https://arxiv.org/pdf/2309.16609.pdf")

Save to LibrarySave

Create AlertAlert

Cite

Share

1,080 Citations

[Highly Influential Citations](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#citing-papers)[](https://www.semanticscholar.org/faq#influential-citations)

146

[Background Citations](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#citing-papers)

364

[Methods Citations](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#citing-papers)

334

[Results Citations](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#citing-papers)

13

[View All](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#citing-papers)

Figures and Tables from this paper
----------------------------------

*   [![Image 23: figure 1](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/3-Figure1-1.png) figure 1](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/0)
*   [![Image 24: table 1](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/7-Table1-1.png) table 1](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/1)
*   [![Image 25: figure 2](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/5-Figure2-1.png) figure 2](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/2)
*   [![Image 26: table 2](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/8-Table2-1.png) table 2](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/3)
*   [![Image 27: figure 3](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/6-Figure3-1.png) figure 3](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/4)
*   [![Image 28: table 3](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/9-Table3-1.png) table 3](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/5)
*   [![Image 29: table 4](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/11-Table4-1.png) table 4](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/6)
*   [![Image 30: figure 4](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/13-Figure4-1.png) figure 4](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/7)
*   [![Image 31: table 5](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/12-Table5-1.png) table 5](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/8)
*   [![Image 32: figure 5](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/59-Figure5-1.png) figure 5](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/9)
*   [![Image 33: table 6](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/13-Table6-1.png) table 6](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/10)
*   [![Image 34: table 7](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/14-Table7-1.png) table 7](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/11)
*   [![Image 35: table 8](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/14-Table8-1.png) table 8](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/12)
*   [![Image 36: table 9](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/15-Table9-1.png) table 9](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/13)
*   [![Image 37: table 10](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/18-Table10-1.png) table 10](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/14)
*   [![Image 38: table 11](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/19-Table11-1.png) table 11](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/15)
*   [![Image 39: table 12](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/19-Table12-1.png) table 12](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/16)
*   [![Image 40: table 13](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/37-Table13-1.png) table 13](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/17)
*   [![Image 41: table 14](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/37-Table14-1.png) table 14](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/18)
*   [![Image 42: table 15](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/38-Table15-1.png) table 15](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/19)
*   [![Image 43: table 16](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/39-Table16-1.png) table 16](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/20)
*   [![Image 44: table 17](https://figures.semanticscholar.org/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/39-Table17-1.png) table 17](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0/figure/21)

View All 22 Figures & Tables

Topics
------

AI-Generated

[Qwen (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/10525945675?corpusId=263134555)[Qwen-Chat (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/54376707975?corpusId=263134555)[Generative Pre-trained Transformer 4 (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/19815052166?corpusId=263134555)[QWEN-14B (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/25007815808?corpusId=263134555)[CMMLU (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/65089997334?corpusId=263134555)[InternLM (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/48968107050?corpusId=263134555)[C-Eval (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/52550769488?corpusId=263134555)[Baichuan2 (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/12652441293?corpusId=263134555)[Baichuan (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/63845980605?corpusId=263134555)[Physical Interaction Question Answering (opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/66124007403?corpusId=263134555)

1,080 Citations
---------------

Citation Type

Has PDF

Author

More Filters

More Filters

Filters

[### Tele-FLM Technical Report](https://www.semanticscholar.org/paper/Tele-FLM-Technical-Report-Li-Yao/47cda129fc742647739591351fb3f40676018cf6)

[Xiang Li](https://www.semanticscholar.org/author/Xiang-Li/2290237093)[Yiqun Yao](https://www.semanticscholar.org/author/Yiqun-Yao/2238398612)+17 authors [Tiejun Huang](https://www.semanticscholar.org/author/Tiejun-Huang/2254807348)

Computer Science, Linguistics

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

This report introduces Tele-FLM (aka FLM-2), a 52B open-sourced multilingual large language model that features a stable, efficient pre-training paradigm and enhanced factual judgment capabilities and demonstrates superior multilingual language modeling abilities, measured by BPB on textual corpus.Expand

*   [3](https://www.semanticscholar.org/paper/47cda129fc742647739591351fb3f40676018cf6#citing-papers)
*   [Highly Influenced](https://www.semanticscholar.org/paper/47cda129fc742647739591351fb3f40676018cf6?sort=is-influential#citing-papers)
    
[](https://www.semanticscholar.org/reader/47cda129fc742647739591351fb3f40676018cf6)\[PDF\]

*   4 Excerpts

Save

[### A Critical Evaluation of AI Feedback for Aligning Large Language Models](https://www.semanticscholar.org/paper/A-Critical-Evaluation-of-AI-Feedback-for-Aligning-Sharma-Keh/087699924e3dc468a486e0763f1cc097824a60d2)

[Archit Sharma](https://www.semanticscholar.org/author/Archit-Sharma/50465276)[Sedrick Scott Keh](https://www.semanticscholar.org/author/Sedrick-Scott-Keh/150299584)[Eric Mitchell](https://www.semanticscholar.org/author/Eric-Mitchell/2260106796)[Chelsea Finn](https://www.semanticscholar.org/author/Chelsea-Finn/2260130955)[Kushal Arora](https://www.semanticscholar.org/author/Kushal-Arora/2284685268)[T. Kollar](https://www.semanticscholar.org/author/T.-Kollar/2836353)

Computer Science, Linguistics

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

It is shown that simple supervised fine-tuning with GPT-4 as the teacher outperforms existing RLAIF pipelines, and it is found that the gains from RLAIF vary substantially across base model families, test-time evaluation protocols, and critic models.Expand

*   [16](https://www.semanticscholar.org/paper/087699924e3dc468a486e0763f1cc097824a60d2#citing-papers)
[](https://www.semanticscholar.org/reader/087699924e3dc468a486e0763f1cc097824a60d2)\[PDF\]

*   2 Excerpts

Save

[### UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions](https://www.semanticscholar.org/paper/UniverSLU%3A-Universal-Spoken-Language-Understanding-Arora-Futami/90b3d99afa310548d6a2d9c9ab1cacd09097404c)

[Siddhant Arora](https://www.semanticscholar.org/author/Siddhant-Arora/72401599)[Hayato Futami](https://www.semanticscholar.org/author/Hayato-Futami/1866674954)+6 authors [Shinji Watanabe](https://www.semanticscholar.org/author/Shinji-Watanabe/2253473275)

Computer Science, Linguistics

[NAACL](https://www.semanticscholar.org/venue?name=NAACL)

*   2024

TLDR

This work starts by adapting a pre-trained automatic speech recognition model to additional tasks using single-token task specifiers, and enhances this approach through instruction tuning, finding that the model generalizes to new datasets and languages for seen task types.Expand

*   [5](https://www.semanticscholar.org/paper/90b3d99afa310548d6a2d9c9ab1cacd09097404c#citing-papers)
[](https://www.semanticscholar.org/reader/90b3d99afa310548d6a2d9c9ab1cacd09097404c)\[PDF\]

*   2 Excerpts

Save

[### Super Tiny Language Models](https://www.semanticscholar.org/paper/Super-Tiny-Language-Models-Hillier-Guertler/4b28c3e9ac9d3ee326760ffa17a1c6952be8049a)

[Dylan Hillier](https://www.semanticscholar.org/author/Dylan-Hillier/2302793720)[Leon Guertler](https://www.semanticscholar.org/author/Leon-Guertler/2302797460)[Cheston Tan](https://www.semanticscholar.org/author/Cheston-Tan/2239059415)[Palaash Agrawal](https://www.semanticscholar.org/author/Palaash-Agrawal/2172415501)[Ruirui Chen](https://www.semanticscholar.org/author/Ruirui-Chen/2302854692)[Bobby Cheng](https://www.semanticscholar.org/author/Bobby-Cheng/2302782322)

Computer Science

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

A series of research efforts focused on Super Tiny Language Models (STLMs), which aim to deliver high performance with significantly reduced parameter counts, and explores innovative techniques such as byte-level tokenization with a pooling mechanism, weight tying, and efficient training strategies.Expand

*   [2](https://www.semanticscholar.org/paper/4b28c3e9ac9d3ee326760ffa17a1c6952be8049a#citing-papers)
[](https://www.semanticscholar.org/reader/4b28c3e9ac9d3ee326760ffa17a1c6952be8049a)\[PDF\]

Save

[### Are Large Language Models Good Statisticians?](https://www.semanticscholar.org/paper/Are-Large-Language-Models-Good-Statisticians-Zhu-Du/727580d0354aa30094d5d1234fc23ca2b57cb228)

[Yizhang Zhu](https://www.semanticscholar.org/author/Yizhang-Zhu/2307554961)[Shiyin Du](https://www.semanticscholar.org/author/Shiyin-Du/2306762754)[Boyan Li](https://www.semanticscholar.org/author/Boyan-Li/2304516904)[Yuyu Luo](https://www.semanticscholar.org/author/Yuyu-Luo/3462170)[Nan Tang](https://www.semanticscholar.org/author/Nan-Tang/2301154561)

Computer Science, Chemistry

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

StatQA, a new benchmark designed for statistical analysis tasks, is introduced and a striking contrast in error types between LLMs and humans is highlighted, suggesting that combining LLM and human expertise could lead to complementary strengths, inviting further investigation into their collaborative potential.Expand

*   [8](https://www.semanticscholar.org/paper/727580d0354aa30094d5d1234fc23ca2b57cb228#citing-papers)
[](https://www.semanticscholar.org/reader/727580d0354aa30094d5d1234fc23ca2b57cb228)\[PDF\]

Save

[### ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback](https://www.semanticscholar.org/paper/ChatGLM-RLHF%3A-Practices-of-Aligning-Large-Language-Hou-Niu/8115ffbbadd1055424d18369dba66ce32a572800)

[Zhenyu Hou](https://www.semanticscholar.org/author/Zhenyu-Hou/2068251467)[Yiin Niu](https://www.semanticscholar.org/author/Yiin-Niu/2294714678)+8 authors [Yuxiao Dong](https://www.semanticscholar.org/author/Yuxiao-Dong/2243402027)

Computer Science

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

This paper presents the ChatGLM-RLHF pipeline -- a reinforcement learning from human feedback (RLHF) system -- designed to enhance ChatGLM's alignment with human preferences, and presents the practices of aligning LLMs with human preferences.Expand

*   [12](https://www.semanticscholar.org/paper/8115ffbbadd1055424d18369dba66ce32a572800#citing-papers)
[](https://www.semanticscholar.org/reader/8115ffbbadd1055424d18369dba66ce32a572800)\[PDF\]

*   3 Excerpts

Save

[### KwaiYiiMath: Technical Report](https://www.semanticscholar.org/paper/KwaiYiiMath%3A-Technical-Report-Fu-Lin/34ca51ce10e8d1d6c950ba519329714a0184d004)

[Jia-Yi Fu](https://www.semanticscholar.org/author/Jia-Yi-Fu/47741053)[Lei Lin](https://www.semanticscholar.org/author/Lei-Lin/2257102249)+18 authors [Kun Gai](https://www.semanticscholar.org/author/Kun-Gai/2238953242)

Mathematics, Computer Science

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2023

TLDR

The KwaiyiiMath is introduced, which enhances the mathematical reasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT) and Reinforced Learning from Human Feedback (RLHF), including on both English and Chinese mathematical tasks.Expand

*   [1](https://www.semanticscholar.org/paper/34ca51ce10e8d1d6c950ba519329714a0184d004#citing-papers)
*   [Highly Influenced](https://www.semanticscholar.org/paper/34ca51ce10e8d1d6c950ba519329714a0184d004?sort=is-influential#citing-papers)
    
[](https://www.semanticscholar.org/reader/34ca51ce10e8d1d6c950ba519329714a0184d004)\[PDF\]

*   8 Excerpts

Save

[### Qwen2 Technical Report](https://www.semanticscholar.org/paper/Qwen2-Technical-Report-Yang-Yang/54fb839f621e3fe787437ab8ca5f37e7e4726bfe)

[An Yang](https://www.semanticscholar.org/author/An-Yang/2311633047)[Baosong Yang](https://www.semanticscholar.org/author/Baosong-Yang/2257101724)+55 authors [Zhi-Wei Fan](https://www.semanticscholar.org/author/Zhi-Wei-Fan/2232106310)

Computer Science, Linguistics

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

A comprehensive suite of foundational and instruction-tuned language models, encompassing a parameter range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts model, which surpasses most prior open-weight models and demonstrates robust multilingual capabilities.Expand

*   [442](https://www.semanticscholar.org/paper/54fb839f621e3fe787437ab8ca5f37e7e4726bfe#citing-papers)
[](https://www.semanticscholar.org/reader/54fb839f621e3fe787437ab8ca5f37e7e4726bfe)\[PDF\]

*   2 Excerpts

Save

[### Autonomous Data Selection with Language Models for Mathematical Texts](https://www.semanticscholar.org/paper/Autonomous-Data-Selection-with-Language-Models-for-Zhang-Luo/574568e9403ca38d7b3e3c243e2a55ceeecc2ba8)

[Yifan Zhang](https://www.semanticscholar.org/author/Yifan-Zhang/2281903182)[Yifan Luo](https://www.semanticscholar.org/author/Yifan-Luo/2281837494)[Yang Yuan](https://www.semanticscholar.org/author/Yang-Yuan/2116944866)[Andrew Chi-Chih Yao](https://www.semanticscholar.org/author/Andrew-Chi-Chih-Yao/2279754345)

Mathematics, Computer Science

*   2024

TLDR

This work continuously pretrained a 7B-parameter language model on the authors' curated dataset, achieving substantial improvements in downstream performance on the MATH, GSM8K, and BIG-Bench Hard (BBH) tasks with a token amount reduced by orders of magnitude compared to previous continual pretraining works.Expand

*   [17](https://www.semanticscholar.org/paper/574568e9403ca38d7b3e3c243e2a55ceeecc2ba8#citing-papers)
*   [Highly Influenced](https://www.semanticscholar.org/paper/574568e9403ca38d7b3e3c243e2a55ceeecc2ba8?sort=is-influential#citing-papers)
    
[](https://www.semanticscholar.org/reader/574568e9403ca38d7b3e3c243e2a55ceeecc2ba8)\[PDF\]

*   1 Excerpt

Save

[### Mixture-of-Agents Enhances Large Language Model Capabilities](https://www.semanticscholar.org/paper/Mixture-of-Agents-Enhances-Large-Language-Model-Wang-Wang/2b3ad2fdd9d2013119232ee49e6d21eb08474b74)

[Junlin Wang](https://www.semanticscholar.org/author/Junlin-Wang/49606614)[Jue Wang](https://www.semanticscholar.org/author/Jue-Wang/2252087284)[Ben Athiwaratkun](https://www.semanticscholar.org/author/Ben-Athiwaratkun/2304481349)[Ce Zhang](https://www.semanticscholar.org/author/Ce-Zhang/2305565297)[James Zou](https://www.semanticscholar.org/author/James-Zou/2304494549)

Computer Science

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2024

TLDR

This work proposes a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology that achieves state-of-art performance on AlpacaEval 2.0, MT-Bench and FLASK, surpassing GPT-4 Omni.Expand

*   [39](https://www.semanticscholar.org/paper/2b3ad2fdd9d2013119232ee49e6d21eb08474b74#citing-papers)
[](https://www.semanticscholar.org/reader/2b3ad2fdd9d2013119232ee49e6d21eb08474b74)\[PDF\]

*   1 Excerpt

Save

...

1

2

3

4

5

...

163 References
--------------

Citation Type

Has PDF

Author

More Filters

More Filters

Filters

[### GLaM: Efficient Scaling of Language Models with Mixture-of-Experts](https://www.semanticscholar.org/paper/GLaM%3A-Efficient-Scaling-of-Language-Models-with-Du-Huang/80d0116d77beeded0c23cf48946d9d10d4faee14)

[Nan Du](https://www.semanticscholar.org/author/Nan-Du/2140321952)[Yanping Huang](https://www.semanticscholar.org/author/Yanping-Huang/2145438541)+24 authors [Claire Cui](https://www.semanticscholar.org/author/Claire-Cui/2052275005)

Computer Science

[ICML](https://www.semanticscholar.org/venue?name=ICML)

*   2022

TLDR

This paper proposes and develops a family of language models named GLaM (Generalist Language Model), which uses a sparsely activated mixture-of-experts architecture to scale the model capacity while also incurring substantially less training cost compared to dense variants.Expand

*   [644](https://www.semanticscholar.org/paper/80d0116d77beeded0c23cf48946d9d10d4faee14#citing-papers)
[](https://www.semanticscholar.org/reader/80d0116d77beeded0c23cf48946d9d10d4faee14)\[PDF\]

*   1 Excerpt

Save

[### Toolformer: Language Models Can Teach Themselves to Use Tools](https://www.semanticscholar.org/paper/Toolformer%3A-Language-Models-Can-Teach-Themselves-to-Schick-Dwivedi-Yu/53d128ea815bcc0526856eb5a9c42cc977cb36a7)

[Timo Schick](https://www.semanticscholar.org/author/Timo-Schick/32246932)[Jane Dwivedi-Yu](https://www.semanticscholar.org/author/Jane-Dwivedi-Yu/2173509991)+5 authors [Thomas Scialom](https://www.semanticscholar.org/author/Thomas-Scialom/90745780)

Computer Science

[NeurIPS](https://www.semanticscholar.org/venue?name=NeurIPS)

*   2023

TLDR

This paper introduces Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction, which achieves substantially improved zero-shot performance across a variety of downstream tasks.Expand

*   [1,297](https://www.semanticscholar.org/paper/53d128ea815bcc0526856eb5a9c42cc977cb36a7#citing-papers)
[](https://www.semanticscholar.org/reader/53d128ea815bcc0526856eb5a9c42cc977cb36a7)\[PDF\]

Save

[### BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://www.semanticscholar.org/paper/BLOOM%3A-A-176B-Parameter-Open-Access-Multilingual-Scao-Fan/964bd39b546f0f6625ff3b9ef1083f797807ef2e)

[Teven Le Scao](https://www.semanticscholar.org/author/Teven-Le-Scao/1379806208)[Angela Fan](https://www.semanticscholar.org/author/Angela-Fan/144270981)+388 authors [Thomas Wolf](https://www.semanticscholar.org/author/Thomas-Wolf/50335211)

Computer Science, Linguistics

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2022

TLDR

BLOOM is a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers and achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning.Expand

*   [2,082](https://www.semanticscholar.org/paper/964bd39b546f0f6625ff3b9ef1083f797807ef2e#citing-papers)
[](https://www.semanticscholar.org/reader/964bd39b546f0f6625ff3b9ef1083f797807ef2e)\[PDF\]

*   1 Excerpt

Save

[### WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct](https://www.semanticscholar.org/paper/WizardMath%3A-Empowering-Mathematical-Reasoning-for-Luo-Sun/dd18782960f9ee4c66b79e1518b342ad3f8d19e7)

[Haipeng Luo](https://www.semanticscholar.org/author/Haipeng-Luo/2131127)[Qingfeng Sun](https://www.semanticscholar.org/author/Qingfeng-Sun/2112549330)+7 authors [Dongmei Zhang](https://www.semanticscholar.org/author/Dongmei-Zhang/2109581369)

Mathematics, Computer Science

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2023

TLDR

WizardMath is presented, which enhances the mathematical CoT reasoning abilities of LLMs without using external python tools, by applying the proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method to the domain of math.Expand

*   [326](https://www.semanticscholar.org/paper/dd18782960f9ee4c66b79e1518b342ad3f8d19e7#citing-papers)
*   [PDF](https://www.semanticscholar.org/paper/dd18782960f9ee4c66b79e1518b342ad3f8d19e7)
    

Save

[### Training language models to follow instructions with human feedback](https://www.semanticscholar.org/paper/Training-language-models-to-follow-instructions-Ouyang-Wu/d766bffc357127e0dc86dd69561d5aeb520d6f4c)

[Long Ouyang](https://www.semanticscholar.org/author/Long-Ouyang/31793034)[Jeff Wu](https://www.semanticscholar.org/author/Jeff-Wu/49387725)+17 authors [Ryan J. Lowe](https://www.semanticscholar.org/author/Ryan-J.-Lowe/49407415)

Computer Science

[NeurIPS](https://www.semanticscholar.org/venue?name=NeurIPS)

*   2022

TLDR

The results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent and showing improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets.Expand

*   [9,899](https://www.semanticscholar.org/paper/d766bffc357127e0dc86dd69561d5aeb520d6f4c#citing-papers)
*   [Highly Influential](https://www.semanticscholar.org/paper/d766bffc357127e0dc86dd69561d5aeb520d6f4c?sort=is-influential#citing-papers)
    
[](https://www.semanticscholar.org/reader/d766bffc357127e0dc86dd69561d5aeb520d6f4c)\[PDF\]

*   25 Excerpts

Save

[### PaLM: Scaling Language Modeling with Pathways](https://www.semanticscholar.org/paper/PaLM%3A-Scaling-Language-Modeling-with-Pathways-Chowdhery-Narang/094ff971d6a8b8ff870946c9b3ce5aa173617bfb)

[Aakanksha Chowdhery](https://www.semanticscholar.org/author/Aakanksha-Chowdhery/2841893)[Sharan Narang](https://www.semanticscholar.org/author/Sharan-Narang/46617804)+64 authors [Noah Fiedel](https://www.semanticscholar.org/author/Noah-Fiedel/22640071)

Computer Science

[J. Mach. Learn. Res.](https://www.semanticscholar.org/venue?name=J.%20Mach.%20Learn.%20Res.)

*   2023

TLDR

A 540-billion parameter, densely activated, Transformer language model, which is called PaLM achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark.Expand

*   [5,354](https://www.semanticscholar.org/paper/094ff971d6a8b8ff870946c9b3ce5aa173617bfb#citing-papers)
[](https://www.semanticscholar.org/reader/094ff971d6a8b8ff870946c9b3ce5aa173617bfb)\[PDF\]

*   3 Excerpts

Save

[### Baichuan 2: Open Large-scale Language Models](https://www.semanticscholar.org/paper/Baichuan-2%3A-Open-Large-scale-Language-Models-Yang-Xiao/c96297261467b5daa2d01227496a70d444602434)

[Ai Ming Yang](https://www.semanticscholar.org/author/Ai-Ming-Yang/2208290330)[Bin Xiao](https://www.semanticscholar.org/author/Bin-Xiao/2264098855)+52 authors [Zhiying Wu](https://www.semanticscholar.org/author/Zhiying-Wu/2242279152)

Computer Science, Linguistics

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2023

TLDR

Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens, matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMML U, GSM8K, and HumanEval.Expand

*   [597](https://www.semanticscholar.org/paper/c96297261467b5daa2d01227496a70d444602434#citing-papers)
[](https://www.semanticscholar.org/reader/c96297261467b5daa2d01227496a70d444602434)\[PDF\]

Save

[### Solving Quantitative Reasoning Problems with Language Models](https://www.semanticscholar.org/paper/Solving-Quantitative-Reasoning-Problems-with-Models-Lewkowycz-Andreassen/ab0e3d3e4d42369de5933a3b4c237780b41c0d77)

[Aitor Lewkowycz](https://www.semanticscholar.org/author/Aitor-Lewkowycz/102549875)[Anders Andreassen](https://www.semanticscholar.org/author/Anders-Andreassen/39552848)+11 authors [Vedant Misra](https://www.semanticscholar.org/author/Vedant-Misra/40055795)

Computer Science, Mathematics

[NeurIPS](https://www.semanticscholar.org/venue?name=NeurIPS)

*   2022

Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks… Expand

*   [609](https://www.semanticscholar.org/paper/ab0e3d3e4d42369de5933a3b4c237780b41c0d77#citing-papers)
*   [Highly Influential](https://www.semanticscholar.org/paper/ab0e3d3e4d42369de5933a3b4c237780b41c0d77?sort=is-influential#citing-papers)
    
[](https://www.semanticscholar.org/reader/ab0e3d3e4d42369de5933a3b4c237780b41c0d77)\[PDF\]

*   5 Excerpts

Save

[### Self-Instruct: Aligning Language Models with Self-Generated Instructions](https://www.semanticscholar.org/paper/Self-Instruct%3A-Aligning-Language-Models-with-Wang-Kordi/e65b346d442e9962a4276dc1c1af2956d9d5f1eb)

[Yizhong Wang](https://www.semanticscholar.org/author/Yizhong-Wang/1705260)[Yeganeh Kordi](https://www.semanticscholar.org/author/Yeganeh-Kordi/2156538832)+4 authors [Hannaneh Hajishirzi](https://www.semanticscholar.org/author/Hannaneh-Hajishirzi/2548384)

Computer Science

[ACL](https://www.semanticscholar.org/venue?name=ACL)

*   2023

TLDR

Self-Instruct is introduced, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations by generating instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model.Expand

*   [1,734](https://www.semanticscholar.org/paper/e65b346d442e9962a4276dc1c1af2956d9d5f1eb#citing-papers)
[](https://www.semanticscholar.org/reader/e65b346d442e9962a4276dc1c1af2956d9d5f1eb)\[PDF\]

Save

[### LaMDA: Language Models for Dialog Applications](https://www.semanticscholar.org/paper/LaMDA%3A-Language-Models-for-Dialog-Applications-Thoppilan-Freitas/b3848d32f7294ec708627897833c4097eb4d8778)

[R. Thoppilan](https://www.semanticscholar.org/author/R.-Thoppilan/9501591)[Daniel De Freitas](https://www.semanticscholar.org/author/Daniel-De-Freitas/1490889580)+54 authors [Quoc Le](https://www.semanticscholar.org/author/Quoc-Le/1998340269)

Computer Science

[ArXiv](https://www.semanticscholar.org/venue?name=ArXiv)

*   2022

TLDR

It is demonstrated that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding.Expand

*   [1,429](https://www.semanticscholar.org/paper/b3848d32f7294ec708627897833c4097eb4d8778#citing-papers)
[](https://www.semanticscholar.org/reader/b3848d32f7294ec708627897833c4097eb4d8778)\[PDF\]

Save

...

1

2

3

4

5

...

Related Papers
--------------

Showing 1 through 3 of 0 Related Papers

*   [Figures and Tables](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#extracted)
*   [Topics](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#paper-topics)
*   [1,080 Citations](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#citing-papers)
*   [163 References](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#cited-papers)
*   [Related Papers](https://www.semanticscholar.org/paper/Qwen-Technical-Report-Bai-Bai/5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0#related-papers)

Stay Connected With Semantic Scholar

Sign Up

What Is Semantic Scholar?
-------------------------

Semantic Scholar is a free, AI-powered research tool for scientific literature, based at Ai2.

[Learn More](https://www.semanticscholar.org/about)

### About

[About Us](https://www.semanticscholar.org/about)[Meet the Team](https://www.semanticscholar.org/about/team)[Publishers](https://www.semanticscholar.org/about/publishers)[Blog (opens in a new tab)](https://medium.com/ai2-blog/semantic-scholar/home)[Ai2 Careers (opens in a new tab)](https://allenai.org/careers?team=semantic+scholar#current-openings)

### Product

[Product Overview](https://www.semanticscholar.org/product)[Semantic Reader](https://www.semanticscholar.org/product/semantic-reader)[Scholar's Hub](https://www.semanticscholar.org/product/scholars-hub)[Beta Program](https://www.semanticscholar.org/product/beta-program)[Release Notes](https://www.semanticscholar.org/product/release-notes)

### API

[API Overview](https://www.semanticscholar.org/product/api)[API Tutorials](https://www.semanticscholar.org/product/api%2Ftutorial)[API Documentation (opens in a new tab)](https://api.semanticscholar.org/api-docs/)[API Gallery](https://www.semanticscholar.org/product/api%2Fgallery)

### Research

[Publications](https://www.semanticscholar.org/research/publications)[Researchers](https://www.semanticscholar.org/research/research-team)[Research Careers](https://www.semanticscholar.org/research/careers)[Prototypes](https://www.semanticscholar.org/research/prototypes)[Resources](https://www.semanticscholar.org/resources)

### Help

[FAQ](https://www.semanticscholar.org/faq)[Librarians](https://www.semanticscholar.org/about/librarians)[Tutorials](https://www.semanticscholar.org/product/tutorials)Contact

Proudly built by [Ai2 (opens in a new tab)](http://allenai.org/)

Collaborators & Attributions •[Terms of Service (opens in a new tab)](https://allenai.org/terms)•[Privacy Policy (opens in a new tab)](https://allenai.org/privacy-policy.html)•[API License Agreement](https://www.semanticscholar.org/product/api/license)

[The Allen Institute for AI (opens in a new tab)](http://allenai.org/)

By clicking accept or continuing to use the site, you agree to the terms outlined in our [Privacy Policy (opens in a new tab)](https://allenai.org/privacy-policy.html), [Terms of Service (opens in a new tab)](https://allenai.org/terms), and [Dataset License (opens in a new tab)](http://api.semanticscholar.org/corpus/legal)

ACCEPT & CONTINUE