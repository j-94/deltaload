---
title: Fixing Large Language Models' Specification Misunderstanding for Better Code Generation
description: Abstract page for arXiv paper 2309.16120: Fixing Large Language Models' Specification Misunderstanding for Better Code Generation
url: https://arxiv.org/abs/2309.16120
timestamp: 2025-01-20T15:46:00.702Z
domain: arxiv.org
path: abs_2309.16120
---

# Fixing Large Language Models' Specification Misunderstanding for Better Code Generation


Abstract page for arXiv paper 2309.16120: Fixing Large Language Models' Specification Misunderstanding for Better Code Generation


## Content

Skip to main content

In just 3 minutes help us improve arXiv:

Annual Global Survey
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
cs
>
arXiv:2309.16120

Help | Advanced Search

All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
Computer Science > Software Engineering
[Submitted on 28 Sep 2023 (v1), last revised 19 Dec 2024 (this version, v3)]
Fixing Large Language Models' Specification Misunderstanding for Better Code Generation
Zhao Tian, Junjie Chen, Xiangyu Zhang
Code generation is to automatically generate source code conforming to a given programming specification, which has received extensive attention especially with the development of large language models (LLMs). Due to the inherent difficulty of code generation, the code generated by LLMs may not be aligned with the specification. Although thought-eliciting prompting techniques have been proposed to enhance the code generation performance of LLMs, producing correct understanding for complicated programming problems remains challenging, resulting in unsatisfactory performance. Also, some feedback-based prompting techniques have been proposed to fix incorrect code using error messages produced by test execution. However, when the generated code deviates significantly from the ground truth, they encounter difficulties in improving performance based on such coarse-grained information. In this work, we propose a novel prompting technique, called {\mu}FiX, to improve the code generation performance of LLMs by devising both sophisticated thought-eliciting prompting and feedback-based prompting and making the first exploration on their synergy. It first exploits test case analysis to obtain specification understanding and enables a self-improvement process to identify and refine the misunderstanding in the thought-eliciting prompting phase. {\mu}FiX further fixes the specification understanding towards the direction reducing the gap between the provided understanding (from the first phase) and the actual understanding implicitly utilized by LLMs for code generation in the feedback-based prompting phase. By improving the understanding with {\mu}FiX, the code generation performance of LLMs can be largely improved. Our evaluation on two advanced LLMs (ChatGPT and DeepSeek-Coder) with six widely-used benchmarks by comparing with 15 baselines, demonstrates the effectiveness of {\mu}FiX ...
Comments:	Accepted by ICSE 2025
Subjects:	Software Engineering (cs.SE)
Cite as:	arXiv:2309.16120 [cs.SE]
 	(or arXiv:2309.16120v3 [cs.SE] for this version)
 	
https://doi.org/10.48550/arXiv.2309.16120
Focus to learn more
Submission history
From: Zhao Tian [view email]
[v1] Thu, 28 Sep 2023 02:58:07 UTC (634 KB)
[v2] Wed, 28 Feb 2024 07:18:02 UTC (1,136 KB)
[v3] Thu, 19 Dec 2024 05:18:33 UTC (1,121 KB)

Access Paper:
View PDF
HTML (experimental)
TeX Source
Other Formats
view license
Current browse context:
cs.SE
< prev   |   next >

new | recent | 2023-09
Change to browse by:
cs

References & Citations
NASA ADS
Google Scholar
Semantic Scholar
Export BibTeX Citation
Bookmark
 
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer (What is the Explorer?)
Connected Papers Toggle
Connected Papers (What is Connected Papers?)
Litmaps Toggle
Litmaps (What is Litmaps?)
scite.ai Toggle
scite Smart Citations (What are Smart Citations?)
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)
About
Help
Contact
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance

arXiv Operational Status 
Get status notifications via email or slack

## Metadata

```json
{
  "title": "Fixing Large Language Models' Specification Misunderstanding for Better Code Generation",
  "description": "Abstract page for arXiv paper 2309.16120: Fixing Large Language Models' Specification Misunderstanding for Better Code Generation",
  "url": "https://arxiv.org/abs/2309.16120",
  "content": "Skip to main content\n\nIn just 3 minutes help us improve arXiv:\n\nAnnual Global Survey\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\nDonate\n>\ncs\n>\narXiv:2309.16120\n\nHelp | Advanced Search\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\nSearch\nComputer Science > Software Engineering\n[Submitted on 28 Sep 2023 (v1), last revised 19 Dec 2024 (this version, v3)]\nFixing Large Language Models' Specification Misunderstanding for Better Code Generation\nZhao Tian, Junjie Chen, Xiangyu Zhang\nCode generation is to automatically generate source code conforming to a given programming specification, which has received extensive attention especially with the development of large language models (LLMs). Due to the inherent difficulty of code generation, the code generated by LLMs may not be aligned with the specification. Although thought-eliciting prompting techniques have been proposed to enhance the code generation performance of LLMs, producing correct understanding for complicated programming problems remains challenging, resulting in unsatisfactory performance. Also, some feedback-based prompting techniques have been proposed to fix incorrect code using error messages produced by test execution. However, when the generated code deviates significantly from the ground truth, they encounter difficulties in improving performance based on such coarse-grained information. In this work, we propose a novel prompting technique, called {\\mu}FiX, to improve the code generation performance of LLMs by devising both sophisticated thought-eliciting prompting and feedback-based prompting and making the first exploration on their synergy. It first exploits test case analysis to obtain specification understanding and enables a self-improvement process to identify and refine the misunderstanding in the thought-eliciting prompting phase. {\\mu}FiX further fixes the specification understanding towards the direction reducing the gap between the provided understanding (from the first phase) and the actual understanding implicitly utilized by LLMs for code generation in the feedback-based prompting phase. By improving the understanding with {\\mu}FiX, the code generation performance of LLMs can be largely improved. Our evaluation on two advanced LLMs (ChatGPT and DeepSeek-Coder) with six widely-used benchmarks by comparing with 15 baselines, demonstrates the effectiveness of {\\mu}FiX ...\nComments:\tAccepted by ICSE 2025\nSubjects:\tSoftware Engineering (cs.SE)\nCite as:\tarXiv:2309.16120 [cs.SE]\n \t(or arXiv:2309.16120v3 [cs.SE] for this version)\n \t\nhttps://doi.org/10.48550/arXiv.2309.16120\nFocus to learn more\nSubmission history\nFrom: Zhao Tian [view email]\n[v1] Thu, 28 Sep 2023 02:58:07 UTC (634 KB)\n[v2] Wed, 28 Feb 2024 07:18:02 UTC (1,136 KB)\n[v3] Thu, 19 Dec 2024 05:18:33 UTC (1,121 KB)\n\nAccess Paper:\nView PDF\nHTML (experimental)\nTeX Source\nOther Formats\nview license\nCurrent browse context:\ncs.SE\n< prev   |   next >\n\nnew | recent | 2023-09\nChange to browse by:\ncs\n\nReferences & Citations\nNASA ADS\nGoogle Scholar\nSemantic Scholar\nExport BibTeX Citation\nBookmark\n \nBibliographic Tools\nBibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer (What is the Explorer?)\nConnected Papers Toggle\nConnected Papers (What is Connected Papers?)\nLitmaps Toggle\nLitmaps (What is Litmaps?)\nscite.ai Toggle\nscite Smart Citations (What are Smart Citations?)\nCode, Data, Media\nDemos\nRelated Papers\nAbout arXivLabs\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\nAbout\nHelp\nContact\nSubscribe\nCopyright\nPrivacy Policy\nWeb Accessibility Assistance\n\narXiv Operational Status \nGet status notifications via email or slack",
  "usage": {
    "tokens": 888
  }
}
```
