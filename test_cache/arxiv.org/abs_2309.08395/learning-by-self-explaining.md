---
title: Learning by Self-Explaining
description: Abstract page for arXiv paper 2309.08395: Learning by Self-Explaining
url: https://arxiv.org/abs/2309.08395
timestamp: 2025-01-20T15:46:22.976Z
domain: arxiv.org
path: abs_2309.08395
---

# Learning by Self-Explaining


Abstract page for arXiv paper 2309.08395: Learning by Self-Explaining


## Content

Skip to main content

In just 3 minutes help us improve arXiv:

Annual Global Survey
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
cs
>
arXiv:2309.08395

Help | Advanced Search

All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
Computer Science > Artificial Intelligence
[Submitted on 15 Sep 2023 (v1), last revised 17 Sep 2024 (this version, v3)]
Learning by Self-Explaining
Wolfgang Stammer, Felix Friedrich, David Steinmann, Manuel Brack, Hikaru Shindo, Kristian Kersting
Much of explainable AI research treats explanations as a means for model inspection. Yet, this neglects findings from human psychology that describe the benefit of self-explanations in an agent's learning process. Motivated by this, we introduce a novel workflow in the context of image classification, termed Learning by Self-Explaining (LSX). LSX utilizes aspects of self-refining AI and human-guided explanatory machine learning. The underlying idea is that a learner model, in addition to optimizing for the original predictive task, is further optimized based on explanatory feedback from an internal critic model. Intuitively, a learner's explanations are considered "useful" if the internal critic can perform the same task given these explanations. We provide an overview of important components of LSX and, based on this, perform extensive experimental evaluations via three different example instantiations. Our results indicate improvements via Learning by Self-Explaining on several levels: in terms of model generalization, reducing the influence of confounding factors, and providing more task-relevant and faithful model explanations. Overall, our work provides evidence for the potential of self-explaining within the learning phase of an AI model.
Subjects:	Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
Cite as:	arXiv:2309.08395 [cs.AI]
 	(or arXiv:2309.08395v3 [cs.AI] for this version)
 	
https://doi.org/10.48550/arXiv.2309.08395
Focus to learn more

Journal reference:	Transactions on Machine Learning Research 2024
Submission history
From: Wolfgang Stammer [view email]
[v1] Fri, 15 Sep 2023 13:41:57 UTC (1,006 KB)
[v2] Fri, 5 Apr 2024 12:59:31 UTC (1,566 KB)
[v3] Tue, 17 Sep 2024 16:24:49 UTC (11,566 KB)

Access Paper:
View PDF
HTML (experimental)
TeX Source
Other Formats
view license
Current browse context:
cs.AI
< prev   |   next >

new | recent | 2023-09
Change to browse by:
cs
cs.LG

References & Citations
NASA ADS
Google Scholar
Semantic Scholar
Export BibTeX Citation
Bookmark
 
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer (What is the Explorer?)
Connected Papers Toggle
Connected Papers (What is Connected Papers?)
Litmaps Toggle
Litmaps (What is Litmaps?)
scite.ai Toggle
scite Smart Citations (What are Smart Citations?)
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)
About
Help
Contact
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance

arXiv Operational Status 
Get status notifications via email or slack

## Metadata

```json
{
  "title": "Learning by Self-Explaining",
  "description": "Abstract page for arXiv paper 2309.08395: Learning by Self-Explaining",
  "url": "https://arxiv.org/abs/2309.08395",
  "content": "Skip to main content\n\nIn just 3 minutes help us improve arXiv:\n\nAnnual Global Survey\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\nDonate\n>\ncs\n>\narXiv:2309.08395\n\nHelp | Advanced Search\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\nSearch\nComputer Science > Artificial Intelligence\n[Submitted on 15 Sep 2023 (v1), last revised 17 Sep 2024 (this version, v3)]\nLearning by Self-Explaining\nWolfgang Stammer, Felix Friedrich, David Steinmann, Manuel Brack, Hikaru Shindo, Kristian Kersting\nMuch of explainable AI research treats explanations as a means for model inspection. Yet, this neglects findings from human psychology that describe the benefit of self-explanations in an agent's learning process. Motivated by this, we introduce a novel workflow in the context of image classification, termed Learning by Self-Explaining (LSX). LSX utilizes aspects of self-refining AI and human-guided explanatory machine learning. The underlying idea is that a learner model, in addition to optimizing for the original predictive task, is further optimized based on explanatory feedback from an internal critic model. Intuitively, a learner's explanations are considered \"useful\" if the internal critic can perform the same task given these explanations. We provide an overview of important components of LSX and, based on this, perform extensive experimental evaluations via three different example instantiations. Our results indicate improvements via Learning by Self-Explaining on several levels: in terms of model generalization, reducing the influence of confounding factors, and providing more task-relevant and faithful model explanations. Overall, our work provides evidence for the potential of self-explaining within the learning phase of an AI model.\nSubjects:\tArtificial Intelligence (cs.AI); Machine Learning (cs.LG)\nCite as:\tarXiv:2309.08395 [cs.AI]\n \t(or arXiv:2309.08395v3 [cs.AI] for this version)\n \t\nhttps://doi.org/10.48550/arXiv.2309.08395\nFocus to learn more\n\nJournal reference:\tTransactions on Machine Learning Research 2024\nSubmission history\nFrom: Wolfgang Stammer [view email]\n[v1] Fri, 15 Sep 2023 13:41:57 UTC (1,006 KB)\n[v2] Fri, 5 Apr 2024 12:59:31 UTC (1,566 KB)\n[v3] Tue, 17 Sep 2024 16:24:49 UTC (11,566 KB)\n\nAccess Paper:\nView PDF\nHTML (experimental)\nTeX Source\nOther Formats\nview license\nCurrent browse context:\ncs.AI\n< prev   |   next >\n\nnew | recent | 2023-09\nChange to browse by:\ncs\ncs.LG\n\nReferences & Citations\nNASA ADS\nGoogle Scholar\nSemantic Scholar\nExport BibTeX Citation\nBookmark\n \nBibliographic Tools\nBibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer (What is the Explorer?)\nConnected Papers Toggle\nConnected Papers (What is Connected Papers?)\nLitmaps Toggle\nLitmaps (What is Litmaps?)\nscite.ai Toggle\nscite Smart Citations (What are Smart Citations?)\nCode, Data, Media\nDemos\nRelated Papers\nAbout arXivLabs\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\nAbout\nHelp\nContact\nSubscribe\nCopyright\nPrivacy Policy\nWeb Accessibility Assistance\n\narXiv Operational Status \nGet status notifications via email or slack",
  "usage": {
    "tokens": 809
  }
}
```
